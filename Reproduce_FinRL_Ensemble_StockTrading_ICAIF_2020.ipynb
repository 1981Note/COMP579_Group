{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lb9q2_QZgdNk"
      },
      "source": [
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/AI4Finance-Foundation/FinRL-Tutorials/blob/master/2-Advance/FinRL_Ensemble_StockTrading_ICAIF_2020.ipynb\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gXaoZs2lh1hi"
      },
      "source": [
        "# Deep Reinforcement Learning for Stock Trading from Scratch: Multiple Stock Trading Using Ensemble Strategy\n",
        "\n",
        "Tutorials to use OpenAI DRL to trade multiple stocks using ensemble strategy in one Jupyter Notebook | Presented at ICAIF 2020\n",
        "\n",
        "* This notebook is the reimplementation of our paper: Deep Reinforcement Learning for Automated Stock Trading: An Ensemble Strategy, using FinRL.\n",
        "* Check out medium blog for detailed explanations: https://medium.com/@ai4finance/deep-reinforcement-learning-for-automated-stock-trading-f1dad0126a02\n",
        "* Please report any issues to our Github: https://github.com/AI4Finance-LLC/FinRL-Library/issues\n",
        "* **Pytorch Version**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGunVt8oLCVS"
      },
      "source": [
        "# Content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HOzAKQ-SLGX6"
      },
      "source": [
        "* [1. Problem Definition](#0)\n",
        "* [2. Getting Started - Load Python packages](#1)\n",
        "    * [2.1. Install Packages](#1.1)    \n",
        "    * [2.2. Check Additional Packages](#1.2)\n",
        "    * [2.3. Import Packages](#1.3)\n",
        "    * [2.4. Create Folders](#1.4)\n",
        "* [3. Download Data](#2)\n",
        "* [4. Preprocess Data](#3)        \n",
        "    * [4.1. Technical Indicators](#3.1)\n",
        "    * [4.2. Perform Feature Engineering](#3.2)\n",
        "* [5.Build Environment](#4)  \n",
        "    * [5.1. Training & Trade Data Split](#4.1)\n",
        "    * [5.2. User-defined Environment](#4.2)   \n",
        "    * [5.3. Initialize Environment](#4.3)    \n",
        "* [6.Implement DRL Algorithms](#5)  \n",
        "* [7.Backtesting Performance](#6)  \n",
        "    * [7.1. BackTestStats](#6.1)\n",
        "    * [7.2. BackTestPlot](#6.2)   \n",
        "    * [7.3. Baseline Stats](#6.3)   \n",
        "    * [7.3. Compare to Stock Market Index](#6.4)             "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sApkDlD9LIZv"
      },
      "source": [
        "<a id='0'></a>\n",
        "# Part 1. Problem Definition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HjLD2TZSLKZ-"
      },
      "source": [
        "This problem is to design an automated trading solution for single stock trading. We model the stock trading process as a Markov Decision Process (MDP). We then formulate our trading goal as a maximization problem.\n",
        "\n",
        "The algorithm is trained using Deep Reinforcement Learning (DRL) algorithms and the components of the reinforcement learning environment are:\n",
        "\n",
        "\n",
        "* Action: The action space describes the allowed actions that the agent interacts with the\n",
        "environment. Normally, a ∈ A includes three actions: a ∈ {−1, 0, 1}, where −1, 0, 1 represent\n",
        "selling, holding, and buying one stock. Also, an action can be carried upon multiple shares. We use\n",
        "an action space {−k, ..., −1, 0, 1, ..., k}, where k denotes the number of shares. For example, \"Buy\n",
        "10 shares of AAPL\" or \"Sell 10 shares of AAPL\" are 10 or −10, respectively\n",
        "\n",
        "* Reward function: r(s, a, s′) is the incentive mechanism for an agent to learn a better action. The change of the portfolio value when action a is taken at state s and arriving at new state s',  i.e., r(s, a, s′) = v′ − v, where v′ and v represent the portfolio\n",
        "values at state s′ and s, respectively\n",
        "\n",
        "* State: The state space describes the observations that the agent receives from the environment. Just as a human trader needs to analyze various information before executing a trade, so\n",
        "our trading agent observes many different features to better learn in an interactive environment.\n",
        "\n",
        "* Environment: Dow 30 consituents\n",
        "\n",
        "\n",
        "The data of the single stock that we will be using for this case study is obtained from Yahoo Finance API. The data contains Open-High-Low-Close price and volume.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ffsre789LY08"
      },
      "source": [
        "<a id='1'></a>\n",
        "# Part 2. Getting Started- Load Python Packages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uy5_PTmOh1hj"
      },
      "source": [
        "<a id='1.1'></a>\n",
        "## 2.1. Install all the packages through FinRL library\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mPT0ipYE28wL"
      },
      "outputs": [],
      "source": [
        "# ## install finrl library\n",
        "!pip install wrds\n",
        "!pip install swig\n",
        "!pip install -q condacolab\n",
        "import condacolab\n",
        "condacolab.install()\n",
        "!apt-get update -y -qq && apt-get install -y -qq cmake libopenmpi-dev python3-dev zlib1g-dev libgl1-mesa-glx swig\n",
        "!pip install git+https://github.com/AI4Finance-Foundation/FinRL.git\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "osBHhVysOEzi"
      },
      "source": [
        "\n",
        "<a id='1.2'></a>\n",
        "## 2.2. Check if the additional packages needed are present, if not install them.\n",
        "* Yahoo Finance API\n",
        "* pandas\n",
        "* numpy\n",
        "* matplotlib\n",
        "* stockstats\n",
        "* OpenAI gym\n",
        "* stable-baselines\n",
        "* tensorflow\n",
        "* pyfolio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nGv01K8Sh1hn"
      },
      "source": [
        "<a id='1.3'></a>\n",
        "## 2.3. Import Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "EeMK7Uentj1V"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "lPqeTTwoh1hn"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "# matplotlib.use('Agg')\n",
        "import datetime\n",
        "\n",
        "%matplotlib inline\n",
        "from finrl.config_tickers import DOW_30_TICKER\n",
        "from finrl.meta.preprocessor.yahoodownloader import YahooDownloader\n",
        "from finrl.meta.preprocessor.preprocessors import FeatureEngineer, data_split\n",
        "from finrl.meta.env_stock_trading.env_stocktrading import StockTradingEnv\n",
        "from finrl.agents.stablebaselines3.models import DRLAgent,DRLEnsembleAgent\n",
        "from finrl.plot import backtest_stats, backtest_plot, get_daily_return, get_baseline\n",
        "\n",
        "from pprint import pprint\n",
        "\n",
        "import sys\n",
        "sys.path.append(\"../FinRL-Library\")\n",
        "\n",
        "import itertools"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T2owTj985RW4"
      },
      "source": [
        "<a id='1.4'></a>\n",
        "## 2.4. Create Folders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "w9A8CN5R5PuZ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from finrl.main import check_and_make_directories\n",
        "from finrl.config import (\n",
        "    DATA_SAVE_DIR,\n",
        "    TRAINED_MODEL_DIR,\n",
        "    TENSORBOARD_LOG_DIR,\n",
        "    RESULTS_DIR,\n",
        "    INDICATORS,\n",
        ")\n",
        "\n",
        "check_and_make_directories([DATA_SAVE_DIR, TRAINED_MODEL_DIR, TENSORBOARD_LOG_DIR, RESULTS_DIR])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A289rQWMh1hq"
      },
      "source": [
        "<a id='2'></a>\n",
        "# Part 3. Download Data\n",
        "Yahoo Finance is a website that provides stock data, financial news, financial reports, etc. All the data provided by Yahoo Finance is free.\n",
        "* FinRL uses a class **YahooDownloader** to fetch data from Yahoo Finance API\n",
        "* Call Limit: Using the Public API (without authentication), you are limited to 2,000 requests per hour per IP (or up to a total of 48,000 requests a day).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NPeQ7iS-LoMm"
      },
      "source": [
        "\n",
        "\n",
        "-----\n",
        "class YahooDownloader:\n",
        "    Provides methods for retrieving daily stock data from\n",
        "    Yahoo Finance API\n",
        "\n",
        "    Attributes\n",
        "    ----------\n",
        "        start_date : str\n",
        "            start date of the data (modified from config.py)\n",
        "        end_date : str\n",
        "            end date of the data (modified from config.py)\n",
        "        ticker_list : list\n",
        "            a list of stock tickers (modified from config.py)\n",
        "\n",
        "    Methods\n",
        "    -------\n",
        "    fetch_data()\n",
        "        Fetches data from yahoo API\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yCKm4om-s9kE"
      },
      "outputs": [],
      "source": [
        "TRAIN_START_DATE = '2009-01-01'\n",
        "TRAIN_END_DATE = '2015-09-30'\n",
        "\n",
        "TRADE_START_DATE = '2015-10-01'\n",
        "TRADE_END_DATE = '2021-01-01'\n",
        "\n",
        "df = YahooDownloader(start_date = TRAIN_START_DATE,\n",
        "                     end_date = TRADE_END_DATE,\n",
        "                     ticker_list = DOW_30_TICKER).fetch_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "GiRuFOTOtj1Y",
        "outputId": "9b47336b-58f0-4979-8474-fd9b8cbb93b1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         date       open       high        low      close     volume   tic  \\\n",
              "0  2009-01-02   3.067143   3.251429   3.041429   2.743889  746015200  AAPL   \n",
              "1  2009-01-02  58.590000  59.080002  57.750000  42.406391    6547900  AMGN   \n",
              "2  2009-01-02  18.570000  19.520000  18.400000  15.098143   10955700   AXP   \n",
              "3  2009-01-02  42.799999  45.560001  42.779999  33.941093    7010200    BA   \n",
              "4  2009-01-02  44.910000  46.980000  44.709999  30.950016    7117200   CAT   \n",
              "\n",
              "   day  \n",
              "0    4  \n",
              "1    4  \n",
              "2    4  \n",
              "3    4  \n",
              "4    4  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b63650c5-a005-4081-b65b-b1474c27cb6e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>open</th>\n",
              "      <th>high</th>\n",
              "      <th>low</th>\n",
              "      <th>close</th>\n",
              "      <th>volume</th>\n",
              "      <th>tic</th>\n",
              "      <th>day</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2009-01-02</td>\n",
              "      <td>3.067143</td>\n",
              "      <td>3.251429</td>\n",
              "      <td>3.041429</td>\n",
              "      <td>2.743889</td>\n",
              "      <td>746015200</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2009-01-02</td>\n",
              "      <td>58.590000</td>\n",
              "      <td>59.080002</td>\n",
              "      <td>57.750000</td>\n",
              "      <td>42.406391</td>\n",
              "      <td>6547900</td>\n",
              "      <td>AMGN</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2009-01-02</td>\n",
              "      <td>18.570000</td>\n",
              "      <td>19.520000</td>\n",
              "      <td>18.400000</td>\n",
              "      <td>15.098143</td>\n",
              "      <td>10955700</td>\n",
              "      <td>AXP</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2009-01-02</td>\n",
              "      <td>42.799999</td>\n",
              "      <td>45.560001</td>\n",
              "      <td>42.779999</td>\n",
              "      <td>33.941093</td>\n",
              "      <td>7010200</td>\n",
              "      <td>BA</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2009-01-02</td>\n",
              "      <td>44.910000</td>\n",
              "      <td>46.980000</td>\n",
              "      <td>44.709999</td>\n",
              "      <td>30.950016</td>\n",
              "      <td>7117200</td>\n",
              "      <td>CAT</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b63650c5-a005-4081-b65b-b1474c27cb6e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b63650c5-a005-4081-b65b-b1474c27cb6e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b63650c5-a005-4081-b65b-b1474c27cb6e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c19dc962-300f-45da-bbe5-e19b4fe1da78\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c19dc962-300f-45da-bbe5-e19b4fe1da78')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c19dc962-300f-45da-bbe5-e19b4fe1da78 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 88061,\n  \"fields\": [\n    {\n      \"column\": \"date\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 3021,\n        \"samples\": [\n          \"2014-08-14\",\n          \"2011-06-08\",\n          \"2010-04-28\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"open\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 58.771271533961624,\n        \"min\": 2.8353569507598877,\n        \"max\": 446.010009765625,\n        \"num_unique_values\": 35819,\n        \"samples\": [\n          115.70999908447266,\n          100.72000122070312,\n          171.52174377441406\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"high\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 59.325109546183405,\n        \"min\": 2.9285709857940674,\n        \"max\": 446.010009765625,\n        \"num_unique_values\": 35860,\n        \"samples\": [\n          219.17999267578125,\n          123.06999969482422,\n          43.76499938964844\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"low\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 58.19000329246773,\n        \"min\": 2.7928569316864014,\n        \"max\": 440.19000244140625,\n        \"num_unique_values\": 35721,\n        \"samples\": [\n          104.0,\n          129.2391357421875,\n          38.11571502685547\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"close\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 53.91096562385568,\n        \"min\": 2.364431619644165,\n        \"max\": 430.2999572753906,\n        \"num_unique_values\": 83733,\n        \"samples\": [\n          41.75313186645508,\n          159.27674865722656,\n          134.73497009277344\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"volume\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 71788670,\n        \"min\": 305400,\n        \"max\": 1880998000,\n        \"num_unique_values\": 76583,\n        \"samples\": [\n          8413200,\n          22266000,\n          3360115\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tic\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 30,\n        \"samples\": [\n          \"WBA\",\n          \"JPM\",\n          \"TRV\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"day\",\n      \"properties\": {\n        \"dtype\": \"int32\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0,\n          3,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "DSw4ZEzVtj1Z",
        "outputId": "b87e1d04-45a3-43a2-c393-1133a7f5c719"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             date        open        high         low       close    volume  \\\n",
              "88056  2020-12-31  345.040009  351.089996  344.049988  335.059814   1969000   \n",
              "88057  2020-12-31  218.399994  219.820007  216.199997  213.664185   5922200   \n",
              "88058  2020-12-31   58.060001   58.799999   58.020000   48.038689  12906300   \n",
              "88059  2020-12-31   39.330002   40.000000   39.029999   33.866371   7696000   \n",
              "88060  2020-12-31   48.066666   48.090000   47.616669   45.710590  17814000   \n",
              "\n",
              "       tic  day  \n",
              "88056  UNH    3  \n",
              "88057    V    3  \n",
              "88058   VZ    3  \n",
              "88059  WBA    3  \n",
              "88060  WMT    3  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-57b8d678-3390-4fb5-9cc7-e3560c0848b9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>open</th>\n",
              "      <th>high</th>\n",
              "      <th>low</th>\n",
              "      <th>close</th>\n",
              "      <th>volume</th>\n",
              "      <th>tic</th>\n",
              "      <th>day</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>88056</th>\n",
              "      <td>2020-12-31</td>\n",
              "      <td>345.040009</td>\n",
              "      <td>351.089996</td>\n",
              "      <td>344.049988</td>\n",
              "      <td>335.059814</td>\n",
              "      <td>1969000</td>\n",
              "      <td>UNH</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88057</th>\n",
              "      <td>2020-12-31</td>\n",
              "      <td>218.399994</td>\n",
              "      <td>219.820007</td>\n",
              "      <td>216.199997</td>\n",
              "      <td>213.664185</td>\n",
              "      <td>5922200</td>\n",
              "      <td>V</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88058</th>\n",
              "      <td>2020-12-31</td>\n",
              "      <td>58.060001</td>\n",
              "      <td>58.799999</td>\n",
              "      <td>58.020000</td>\n",
              "      <td>48.038689</td>\n",
              "      <td>12906300</td>\n",
              "      <td>VZ</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88059</th>\n",
              "      <td>2020-12-31</td>\n",
              "      <td>39.330002</td>\n",
              "      <td>40.000000</td>\n",
              "      <td>39.029999</td>\n",
              "      <td>33.866371</td>\n",
              "      <td>7696000</td>\n",
              "      <td>WBA</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88060</th>\n",
              "      <td>2020-12-31</td>\n",
              "      <td>48.066666</td>\n",
              "      <td>48.090000</td>\n",
              "      <td>47.616669</td>\n",
              "      <td>45.710590</td>\n",
              "      <td>17814000</td>\n",
              "      <td>WMT</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-57b8d678-3390-4fb5-9cc7-e3560c0848b9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-57b8d678-3390-4fb5-9cc7-e3560c0848b9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-57b8d678-3390-4fb5-9cc7-e3560c0848b9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-8c8b8631-d1c8-4181-ac50-9799f7e3202b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8c8b8631-d1c8-4181-ac50-9799f7e3202b')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-8c8b8631-d1c8-4181-ac50-9799f7e3202b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "repr_error": "0"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "df.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CV3HrZHLh1hy",
        "outputId": "d1540757-c3e7-4232-e127-711750cbb7f2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(88061, 8)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "4hYkeaPiICHS",
        "outputId": "b6a8dced-4c1d-4bdf-b538-1f44b389ef90"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         date       open       high        low      close     volume   tic  \\\n",
              "0  2009-01-02   3.067143   3.251429   3.041429   2.743889  746015200  AAPL   \n",
              "1  2009-01-02  58.590000  59.080002  57.750000  42.406391    6547900  AMGN   \n",
              "2  2009-01-02  18.570000  19.520000  18.400000  15.098143   10955700   AXP   \n",
              "3  2009-01-02  42.799999  45.560001  42.779999  33.941093    7010200    BA   \n",
              "4  2009-01-02  44.910000  46.980000  44.709999  30.950016    7117200   CAT   \n",
              "\n",
              "   day  \n",
              "0    4  \n",
              "1    4  \n",
              "2    4  \n",
              "3    4  \n",
              "4    4  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8182d6c3-4a8e-431d-9497-c300ee68a073\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>open</th>\n",
              "      <th>high</th>\n",
              "      <th>low</th>\n",
              "      <th>close</th>\n",
              "      <th>volume</th>\n",
              "      <th>tic</th>\n",
              "      <th>day</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2009-01-02</td>\n",
              "      <td>3.067143</td>\n",
              "      <td>3.251429</td>\n",
              "      <td>3.041429</td>\n",
              "      <td>2.743889</td>\n",
              "      <td>746015200</td>\n",
              "      <td>AAPL</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2009-01-02</td>\n",
              "      <td>58.590000</td>\n",
              "      <td>59.080002</td>\n",
              "      <td>57.750000</td>\n",
              "      <td>42.406391</td>\n",
              "      <td>6547900</td>\n",
              "      <td>AMGN</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2009-01-02</td>\n",
              "      <td>18.570000</td>\n",
              "      <td>19.520000</td>\n",
              "      <td>18.400000</td>\n",
              "      <td>15.098143</td>\n",
              "      <td>10955700</td>\n",
              "      <td>AXP</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2009-01-02</td>\n",
              "      <td>42.799999</td>\n",
              "      <td>45.560001</td>\n",
              "      <td>42.779999</td>\n",
              "      <td>33.941093</td>\n",
              "      <td>7010200</td>\n",
              "      <td>BA</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2009-01-02</td>\n",
              "      <td>44.910000</td>\n",
              "      <td>46.980000</td>\n",
              "      <td>44.709999</td>\n",
              "      <td>30.950016</td>\n",
              "      <td>7117200</td>\n",
              "      <td>CAT</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8182d6c3-4a8e-431d-9497-c300ee68a073')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8182d6c3-4a8e-431d-9497-c300ee68a073 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8182d6c3-4a8e-431d-9497-c300ee68a073');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-77092ab4-0e10-4ca7-9330-159607963dd0\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-77092ab4-0e10-4ca7-9330-159607963dd0')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-77092ab4-0e10-4ca7-9330-159607963dd0 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"date\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"2009-01-02\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"open\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 22.333896144083976,\n        \"min\": 3.067142963409424,\n        \"max\": 58.59000015258789,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          58.59000015258789\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"high\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 22.81670756548568,\n        \"min\": 3.2514290809631348,\n        \"max\": 59.08000183105469,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          59.08000183105469\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"low\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 22.11020974903371,\n        \"min\": 3.041429042816162,\n        \"max\": 57.75,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          57.75\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"close\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 15.90366046114934,\n        \"min\": 2.7438888549804688,\n        \"max\": 42.40639114379883,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          42.40639114379883\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"volume\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 330096446,\n        \"min\": 6547900,\n        \"max\": 746015200,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          6547900\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tic\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"AMGN\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"day\",\n      \"properties\": {\n        \"dtype\": \"int32\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "df.sort_values(['date','tic']).head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a2vryMsdNL9H",
        "outputId": "959277a7-9e0d-4057-e839-8744f46f8a20"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "len(df.tic.unique())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uqC6c40Zh1iH"
      },
      "source": [
        "# Part 4: Preprocess Data\n",
        "Data preprocessing is a crucial step for training a high quality machine learning model. We need to check for missing data and do feature engineering in order to convert the data into a model-ready state.\n",
        "* Add technical indicators. In practical trading, various information needs to be taken into account, for example the historical stock prices, current holding shares, technical indicators, etc. In this article, we demonstrate two trend-following technical indicators: MACD and RSI.\n",
        "* Add turbulence index. Risk-aversion reflects whether an investor will choose to preserve the capital. It also influences one's trading strategy when facing different market volatility level. To control the risk in a worst-case scenario, such as financial crisis of 2007–2008, FinRL employs the financial turbulence index that measures extreme asset price fluctuation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jgXfBcjxtj1a",
        "outputId": "784d657b-1805-431a-86e5-0f219e344cb9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully added technical indicators\n",
            "Successfully added turbulence index\n"
          ]
        }
      ],
      "source": [
        "fe = FeatureEngineer(use_technical_indicator=True,\n",
        "                     tech_indicator_list = INDICATORS,\n",
        "                     use_turbulence=True,\n",
        "                     user_defined_feature = False)\n",
        "\n",
        "processed = fe.preprocess_data(df)\n",
        "processed = processed.copy()\n",
        "processed = processed.fillna(0)\n",
        "processed = processed.replace(np.inf,0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-QsYaY0Dh1iw"
      },
      "source": [
        "<a id='4'></a>\n",
        "# Part 5. Design Environment\n",
        "Considering the stochastic and interactive nature of the automated stock trading tasks, a financial task is modeled as a **Markov Decision Process (MDP)** problem. The training process involves observing stock price change, taking an action and reward's calculation to have the agent adjusting its strategy accordingly. By interacting with the environment, the trading agent will derive a trading strategy with the maximized rewards as time proceeds.\n",
        "\n",
        "Our trading environments, based on OpenAI Gym framework, simulate live stock markets with real market data according to the principle of time-driven simulation.\n",
        "\n",
        "The action space describes the allowed actions that the agent interacts with the environment. Normally, action a includes three actions: {-1, 0, 1}, where -1, 0, 1 represent selling, holding, and buying one share. Also, an action can be carried upon multiple shares. We use an action space {-k,…,-1, 0, 1, …, k}, where k denotes the number of shares to buy and -k denotes the number of shares to sell. For example, \"Buy 10 shares of AAPL\" or \"Sell 10 shares of AAPL\" are 10 or -10, respectively. The continuous action space needs to be normalized to [-1, 1], since the policy is defined on a Gaussian distribution, which needs to be normalized and symmetric."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q2zqII8rMIqn",
        "outputId": "902f43af-711c-4ff8-a2cd-1e0429b016d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stock Dimension: 29, State Space: 291\n"
          ]
        }
      ],
      "source": [
        "stock_dimension = len(processed.tic.unique())\n",
        "state_space = 1 + 2*stock_dimension + len(INDICATORS)*stock_dimension\n",
        "print(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "AWyp84Ltto19"
      },
      "outputs": [],
      "source": [
        "env_kwargs = {\n",
        "    \"hmax\": 100,\n",
        "    \"initial_amount\": 1000000,\n",
        "    \"buy_cost_pct\": 0.001,\n",
        "    \"sell_cost_pct\": 0.001,\n",
        "    \"state_space\": state_space,\n",
        "    \"stock_dim\": stock_dimension,\n",
        "    \"tech_indicator_list\": INDICATORS,\n",
        "    \"action_space\": stock_dimension,\n",
        "    \"reward_scaling\": 1e-4,\n",
        "    \"print_verbosity\":5\n",
        "\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HMNR5nHjh1iz"
      },
      "source": [
        "<a id='5'></a>\n",
        "# Part 6: Implement DRL Algorithms\n",
        "* The implementation of the DRL algorithms are based on **OpenAI Baselines** and **Stable Baselines**. Stable Baselines is a fork of OpenAI Baselines, with a major structural refactoring, and code cleanups.\n",
        "* FinRL library includes fine-tuned standard DRL algorithms, such as DQN, DDPG,\n",
        "Multi-Agent DDPG, PPO, SAC, A2C and TD3. We also allow users to\n",
        "design their own DRL algorithms by adapting these DRL algorithms.\n",
        "\n",
        "* In this notebook, we are training and validating 3 agents (A2C, PPO, DDPG) using Rolling-window Ensemble Method ([reference code](https://github.com/AI4Finance-LLC/Deep-Reinforcement-Learning-for-Automated-Stock-Trading-Ensemble-Strategy-ICAIF-2020/blob/80415db8fa7b2179df6bd7e81ce4fe8dbf913806/model/models.py#L92))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "v-gthCxMtj1d"
      },
      "outputs": [],
      "source": [
        "rebalance_window = 63 # rebalance_window is the number of days to retrain the model\n",
        "validation_window = 63 # validation_window is the number of days to do validation and trading (e.g. if validation_window=63, then both validation and trading period will be 63 days)\n",
        "\n",
        "ensemble_agent = DRLEnsembleAgent(df=processed,\n",
        "                 train_period=(TRAIN_START_DATE,TRAIN_END_DATE),\n",
        "                 val_test_period=(TRADE_START_DATE,TRADE_END_DATE),\n",
        "                 rebalance_window=rebalance_window,\n",
        "                 validation_window=validation_window,\n",
        "                 **env_kwargs)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "KsfEHa_Etj1d",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "A2C_model_kwargs = {\n",
        "                    'n_steps': 5,\n",
        "                    'ent_coef': 0.005,\n",
        "                    'learning_rate': 0.0007\n",
        "                    }\n",
        "\n",
        "PPO_model_kwargs = {\n",
        "                    \"ent_coef\":0.01,\n",
        "                    \"n_steps\": 2048,\n",
        "                    \"learning_rate\": 0.00025,\n",
        "                    \"batch_size\": 128\n",
        "                    }\n",
        "\n",
        "DDPG_model_kwargs = {\n",
        "                      #\"action_noise\":\"ornstein_uhlenbeck\",\n",
        "                      \"buffer_size\": 10_000,\n",
        "                      \"learning_rate\": 0.0005,\n",
        "                      \"batch_size\": 64\n",
        "                    }\n",
        "\n",
        "timesteps_dict = {'a2c' : 10_000,\n",
        "                 'ppo' : 10_000,\n",
        "                 'ddpg' : 10_000\n",
        "                 }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_1lyCECstj1e",
        "outputId": "79f7c6bc-52b6-4948-bb9c-632a6af843d1",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "|    reward          | -0.087929256 |\n",
            "-------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 113         |\n",
            "|    iterations           | 2           |\n",
            "|    time_elapsed         | 35          |\n",
            "|    total_timesteps      | 4096        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.016196746 |\n",
            "|    clip_fraction        | 0.248       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.2       |\n",
            "|    explained_variance   | -0.00694    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 6.85        |\n",
            "|    n_updates            | 10          |\n",
            "|    policy_gradient_loss | -0.0263     |\n",
            "|    reward               | 0.48113844  |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 14.3        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 114         |\n",
            "|    iterations           | 3           |\n",
            "|    time_elapsed         | 53          |\n",
            "|    total_timesteps      | 6144        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.015390315 |\n",
            "|    clip_fraction        | 0.2         |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.2       |\n",
            "|    explained_variance   | -0.0121     |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 3.68        |\n",
            "|    n_updates            | 20          |\n",
            "|    policy_gradient_loss | -0.0241     |\n",
            "|    reward               | -0.55387515 |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 8.51        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 112         |\n",
            "|    iterations           | 4           |\n",
            "|    time_elapsed         | 72          |\n",
            "|    total_timesteps      | 8192        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.019647472 |\n",
            "|    clip_fraction        | 0.202       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.3       |\n",
            "|    explained_variance   | 0.00421     |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 4.85        |\n",
            "|    n_updates            | 30          |\n",
            "|    policy_gradient_loss | -0.0197     |\n",
            "|    reward               | 2.073137    |\n",
            "|    std                  | 1.01        |\n",
            "|    value_loss           | 11.5        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 113         |\n",
            "|    iterations           | 5           |\n",
            "|    time_elapsed         | 90          |\n",
            "|    total_timesteps      | 10240       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.017486505 |\n",
            "|    clip_fraction        | 0.192       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.4       |\n",
            "|    explained_variance   | -0.00241    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 5.77        |\n",
            "|    n_updates            | 40          |\n",
            "|    policy_gradient_loss | -0.0243     |\n",
            "|    reward               | -4.3802266  |\n",
            "|    std                  | 1.01        |\n",
            "|    value_loss           | 12          |\n",
            "-----------------------------------------\n",
            "======ppo Validation from:  2017-07-05 to  2017-10-03\n",
            "ppo Sharpe Ratio:  0.3338307275493144\n",
            "======Best Model Retraining from:  2009-01-01 to  2017-10-03\n",
            "======Trading from:  2017-10-03 to  2018-01-03\n",
            "============================================\n",
            "turbulence_threshold:  160.3176626173842\n",
            "======Model training from:  2009-01-01 to  2017-10-03\n",
            "======a2c Training========\n",
            "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/a2c/a2c_630_1\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 91           |\n",
            "|    iterations         | 100          |\n",
            "|    time_elapsed       | 5            |\n",
            "|    total_timesteps    | 500          |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -41.3        |\n",
            "|    explained_variance | -0.0172      |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 99           |\n",
            "|    policy_loss        | 47.7         |\n",
            "|    reward             | -0.008053933 |\n",
            "|    std                | 1            |\n",
            "|    value_loss         | 1.95         |\n",
            "----------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 100        |\n",
            "|    iterations         | 200        |\n",
            "|    time_elapsed       | 9          |\n",
            "|    total_timesteps    | 1000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.3      |\n",
            "|    explained_variance | 1.19e-07   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 199        |\n",
            "|    policy_loss        | -31        |\n",
            "|    reward             | -1.2217487 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 1.16       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 103       |\n",
            "|    iterations         | 300       |\n",
            "|    time_elapsed       | 14        |\n",
            "|    total_timesteps    | 1500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.4     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 299       |\n",
            "|    policy_loss        | -354      |\n",
            "|    reward             | 3.8536143 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 75.5      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 101       |\n",
            "|    iterations         | 400       |\n",
            "|    time_elapsed       | 19        |\n",
            "|    total_timesteps    | 2000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.4     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 399       |\n",
            "|    policy_loss        | -102      |\n",
            "|    reward             | 2.2289686 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 10.7      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 103       |\n",
            "|    iterations         | 500       |\n",
            "|    time_elapsed       | 24        |\n",
            "|    total_timesteps    | 2500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.4     |\n",
            "|    explained_variance | 5.96e-08  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 499       |\n",
            "|    policy_loss        | 15.3      |\n",
            "|    reward             | 0.5004026 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 0.528     |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 102        |\n",
            "|    iterations         | 600        |\n",
            "|    time_elapsed       | 29         |\n",
            "|    total_timesteps    | 3000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.4      |\n",
            "|    explained_variance | 0.0181     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 599        |\n",
            "|    policy_loss        | -6.11      |\n",
            "|    reward             | 0.19762632 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 0.4        |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 103        |\n",
            "|    iterations         | 700        |\n",
            "|    time_elapsed       | 33         |\n",
            "|    total_timesteps    | 3500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.4      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 699        |\n",
            "|    policy_loss        | 58         |\n",
            "|    reward             | 0.62739927 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 9.28       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 105       |\n",
            "|    iterations         | 800       |\n",
            "|    time_elapsed       | 38        |\n",
            "|    total_timesteps    | 4000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.4     |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 799       |\n",
            "|    policy_loss        | 108       |\n",
            "|    reward             | 1.0557996 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 10.5      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 103        |\n",
            "|    iterations         | 900        |\n",
            "|    time_elapsed       | 43         |\n",
            "|    total_timesteps    | 4500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.5      |\n",
            "|    explained_variance | -0.185     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 899        |\n",
            "|    policy_loss        | -24.6      |\n",
            "|    reward             | -1.0172209 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 2.69       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 104        |\n",
            "|    iterations         | 1000       |\n",
            "|    time_elapsed       | 47         |\n",
            "|    total_timesteps    | 5000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.4      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 999        |\n",
            "|    policy_loss        | -76.9      |\n",
            "|    reward             | -0.6978056 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 3.44       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 105        |\n",
            "|    iterations         | 1100       |\n",
            "|    time_elapsed       | 52         |\n",
            "|    total_timesteps    | 5500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.4      |\n",
            "|    explained_variance | 0.0152     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1099       |\n",
            "|    policy_loss        | -82.1      |\n",
            "|    reward             | -2.1278014 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 7.06       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 104        |\n",
            "|    iterations         | 1200       |\n",
            "|    time_elapsed       | 57         |\n",
            "|    total_timesteps    | 6000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.4      |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1199       |\n",
            "|    policy_loss        | 65.1       |\n",
            "|    reward             | -1.8855741 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 5.28       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 105        |\n",
            "|    iterations         | 1300       |\n",
            "|    time_elapsed       | 61         |\n",
            "|    total_timesteps    | 6500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.4      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1299       |\n",
            "|    policy_loss        | -229       |\n",
            "|    reward             | -3.5430925 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 32.7       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 104       |\n",
            "|    iterations         | 1400      |\n",
            "|    time_elapsed       | 66        |\n",
            "|    total_timesteps    | 7000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.5     |\n",
            "|    explained_variance | -0.0021   |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1399      |\n",
            "|    policy_loss        | 92.2      |\n",
            "|    reward             | 0.9095902 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 7.08      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 105        |\n",
            "|    iterations         | 1500       |\n",
            "|    time_elapsed       | 71         |\n",
            "|    total_timesteps    | 7500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.5      |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1499       |\n",
            "|    policy_loss        | -15.5      |\n",
            "|    reward             | 0.92137235 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 0.348      |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 105       |\n",
            "|    iterations         | 1600      |\n",
            "|    time_elapsed       | 75        |\n",
            "|    total_timesteps    | 8000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.5     |\n",
            "|    explained_variance | 1.79e-07  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1599      |\n",
            "|    policy_loss        | -81.4     |\n",
            "|    reward             | 1.2323014 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 4.63      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 104       |\n",
            "|    iterations         | 1700      |\n",
            "|    time_elapsed       | 81        |\n",
            "|    total_timesteps    | 8500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.5     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1699      |\n",
            "|    policy_loss        | 181       |\n",
            "|    reward             | 2.8821414 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 29.2      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 105        |\n",
            "|    iterations         | 1800       |\n",
            "|    time_elapsed       | 85         |\n",
            "|    total_timesteps    | 9000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.5      |\n",
            "|    explained_variance | 0.0512     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1799       |\n",
            "|    policy_loss        | -11.8      |\n",
            "|    reward             | -3.0556517 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 0.379      |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 105       |\n",
            "|    iterations         | 1900      |\n",
            "|    time_elapsed       | 90        |\n",
            "|    total_timesteps    | 9500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.6     |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1899      |\n",
            "|    policy_loss        | 56.5      |\n",
            "|    reward             | 3.8084915 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 5.25      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 105        |\n",
            "|    iterations         | 2000       |\n",
            "|    time_elapsed       | 94         |\n",
            "|    total_timesteps    | 10000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.6      |\n",
            "|    explained_variance | -6.32e-06  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1999       |\n",
            "|    policy_loss        | 129        |\n",
            "|    reward             | -1.8274016 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 14         |\n",
            "--------------------------------------\n",
            "======a2c Validation from:  2017-10-03 to  2018-01-03\n",
            "a2c Sharpe Ratio:  0.36737818073727985\n",
            "======ddpg Training========\n",
            "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/ddpg/ddpg_630_1\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    episodes        | 4         |\n",
            "|    fps             | 69        |\n",
            "|    time_elapsed    | 125       |\n",
            "|    total_timesteps | 8812      |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 99.3      |\n",
            "|    critic_loss     | 140       |\n",
            "|    learning_rate   | 0.0005    |\n",
            "|    n_updates       | 8711      |\n",
            "|    reward          | 1.5270052 |\n",
            "----------------------------------\n",
            "======ddpg Validation from:  2017-10-03 to  2018-01-03\n",
            "ddpg Sharpe Ratio:  0.4081059852852937\n",
            "======ppo Training========\n",
            "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/ppo/ppo_630_1\n",
            "-----------------------------------\n",
            "| time/              |            |\n",
            "|    fps             | 119        |\n",
            "|    iterations      | 1          |\n",
            "|    time_elapsed    | 17         |\n",
            "|    total_timesteps | 2048       |\n",
            "| train/             |            |\n",
            "|    reward          | 0.50070393 |\n",
            "-----------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 117         |\n",
            "|    iterations           | 2           |\n",
            "|    time_elapsed         | 34          |\n",
            "|    total_timesteps      | 4096        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.016762981 |\n",
            "|    clip_fraction        | 0.216       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.2       |\n",
            "|    explained_variance   | -0.0808     |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 7.51        |\n",
            "|    n_updates            | 10          |\n",
            "|    policy_gradient_loss | -0.0265     |\n",
            "|    reward               | 1.0789944   |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 13.6        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 114         |\n",
            "|    iterations           | 3           |\n",
            "|    time_elapsed         | 53          |\n",
            "|    total_timesteps      | 6144        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.014527058 |\n",
            "|    clip_fraction        | 0.197       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.2       |\n",
            "|    explained_variance   | -0.0135     |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 6.94        |\n",
            "|    n_updates            | 20          |\n",
            "|    policy_gradient_loss | -0.0258     |\n",
            "|    reward               | -0.11410734 |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 12.6        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 114         |\n",
            "|    iterations           | 4           |\n",
            "|    time_elapsed         | 71          |\n",
            "|    total_timesteps      | 8192        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.021296782 |\n",
            "|    clip_fraction        | 0.228       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.3       |\n",
            "|    explained_variance   | -0.00749    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 4.26        |\n",
            "|    n_updates            | 30          |\n",
            "|    policy_gradient_loss | -0.0239     |\n",
            "|    reward               | 1.7768148   |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 9.71        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 113         |\n",
            "|    iterations           | 5           |\n",
            "|    time_elapsed         | 90          |\n",
            "|    total_timesteps      | 10240       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.018940467 |\n",
            "|    clip_fraction        | 0.204       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.3       |\n",
            "|    explained_variance   | -0.0163     |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 4.89        |\n",
            "|    n_updates            | 40          |\n",
            "|    policy_gradient_loss | -0.0251     |\n",
            "|    reward               | 1.5430284   |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 10.6        |\n",
            "-----------------------------------------\n",
            "======ppo Validation from:  2017-10-03 to  2018-01-03\n",
            "ppo Sharpe Ratio:  0.47392165648447726\n",
            "======Best Model Retraining from:  2009-01-01 to  2018-01-03\n",
            "======Trading from:  2018-01-03 to  2018-04-05\n",
            "============================================\n",
            "turbulence_threshold:  160.3176626173842\n",
            "======Model training from:  2009-01-01 to  2018-01-03\n",
            "======a2c Training========\n",
            "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/a2c/a2c_693_1\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 108         |\n",
            "|    iterations         | 100         |\n",
            "|    time_elapsed       | 4           |\n",
            "|    total_timesteps    | 500         |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -41         |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 99          |\n",
            "|    policy_loss        | -92.3       |\n",
            "|    reward             | -0.44097304 |\n",
            "|    std                | 0.997       |\n",
            "|    value_loss         | 9.77        |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 100        |\n",
            "|    iterations         | 200        |\n",
            "|    time_elapsed       | 9          |\n",
            "|    total_timesteps    | 1000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41        |\n",
            "|    explained_variance | 5.96e-08   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 199        |\n",
            "|    policy_loss        | 4.12       |\n",
            "|    reward             | -1.6190319 |\n",
            "|    std                | 0.995      |\n",
            "|    value_loss         | 0.187      |\n",
            "--------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 97       |\n",
            "|    iterations         | 300      |\n",
            "|    time_elapsed       | 15       |\n",
            "|    total_timesteps    | 1500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -40.9    |\n",
            "|    explained_variance | -0.667   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 299      |\n",
            "|    policy_loss        | -121     |\n",
            "|    reward             | 4.0638   |\n",
            "|    std                | 0.992    |\n",
            "|    value_loss         | 9.29     |\n",
            "------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 95          |\n",
            "|    iterations         | 400         |\n",
            "|    time_elapsed       | 20          |\n",
            "|    total_timesteps    | 2000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -40.8       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 399         |\n",
            "|    policy_loss        | 111         |\n",
            "|    reward             | -0.21605639 |\n",
            "|    std                | 0.99        |\n",
            "|    value_loss         | 9.27        |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 97         |\n",
            "|    iterations         | 500        |\n",
            "|    time_elapsed       | 25         |\n",
            "|    total_timesteps    | 2500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -40.8      |\n",
            "|    explained_variance | -0.171     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 499        |\n",
            "|    policy_loss        | 5.81       |\n",
            "|    reward             | -1.1793795 |\n",
            "|    std                | 0.989      |\n",
            "|    value_loss         | 1.92       |\n",
            "--------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 99       |\n",
            "|    iterations         | 600      |\n",
            "|    time_elapsed       | 30       |\n",
            "|    total_timesteps    | 3000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -40.8    |\n",
            "|    explained_variance | 5.96e-08 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 599      |\n",
            "|    policy_loss        | -211     |\n",
            "|    reward             | 8.683347 |\n",
            "|    std                | 0.99     |\n",
            "|    value_loss         | 41.8     |\n",
            "------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 98          |\n",
            "|    iterations         | 700         |\n",
            "|    time_elapsed       | 35          |\n",
            "|    total_timesteps    | 3500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -40.9       |\n",
            "|    explained_variance | -0.00137    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 699         |\n",
            "|    policy_loss        | 2.83        |\n",
            "|    reward             | -0.14378272 |\n",
            "|    std                | 0.991       |\n",
            "|    value_loss         | 1.79        |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 99        |\n",
            "|    iterations         | 800       |\n",
            "|    time_elapsed       | 40        |\n",
            "|    total_timesteps    | 4000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -40.8     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 799       |\n",
            "|    policy_loss        | -323      |\n",
            "|    reward             | 1.8595579 |\n",
            "|    std                | 0.989     |\n",
            "|    value_loss         | 71.4      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 98        |\n",
            "|    iterations         | 900       |\n",
            "|    time_elapsed       | 45        |\n",
            "|    total_timesteps    | 4500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -40.8     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 899       |\n",
            "|    policy_loss        | 109       |\n",
            "|    reward             | -6.811916 |\n",
            "|    std                | 0.989     |\n",
            "|    value_loss         | 7.87      |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 99       |\n",
            "|    iterations         | 1000     |\n",
            "|    time_elapsed       | 50       |\n",
            "|    total_timesteps    | 5000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -40.8    |\n",
            "|    explained_variance | 0.0914   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 999      |\n",
            "|    policy_loss        | 27.8     |\n",
            "|    reward             | 1.060748 |\n",
            "|    std                | 0.989    |\n",
            "|    value_loss         | 0.816    |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 100      |\n",
            "|    iterations         | 1100     |\n",
            "|    time_elapsed       | 54       |\n",
            "|    total_timesteps    | 5500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -40.8    |\n",
            "|    explained_variance | -0.249   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1099     |\n",
            "|    policy_loss        | -18.1    |\n",
            "|    reward             | 2.45881  |\n",
            "|    std                | 0.99     |\n",
            "|    value_loss         | 8.51     |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 99        |\n",
            "|    iterations         | 1200      |\n",
            "|    time_elapsed       | 60        |\n",
            "|    total_timesteps    | 6000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -40.8     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1199      |\n",
            "|    policy_loss        | 283       |\n",
            "|    reward             | 5.3855996 |\n",
            "|    std                | 0.989     |\n",
            "|    value_loss         | 67.8      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 100        |\n",
            "|    iterations         | 1300       |\n",
            "|    time_elapsed       | 64         |\n",
            "|    total_timesteps    | 6500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -40.7      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1299       |\n",
            "|    policy_loss        | 80.9       |\n",
            "|    reward             | 0.07345797 |\n",
            "|    std                | 0.987      |\n",
            "|    value_loss         | 4.82       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 100        |\n",
            "|    iterations         | 1400       |\n",
            "|    time_elapsed       | 69         |\n",
            "|    total_timesteps    | 7000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -40.8      |\n",
            "|    explained_variance | 0.0158     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1399       |\n",
            "|    policy_loss        | 121        |\n",
            "|    reward             | -1.4665976 |\n",
            "|    std                | 0.987      |\n",
            "|    value_loss         | 8.72       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 100       |\n",
            "|    iterations         | 1500      |\n",
            "|    time_elapsed       | 74        |\n",
            "|    total_timesteps    | 7500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -40.8     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1499      |\n",
            "|    policy_loss        | 149       |\n",
            "|    reward             | 3.4686093 |\n",
            "|    std                | 0.987     |\n",
            "|    value_loss         | 22.9      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 101       |\n",
            "|    iterations         | 1600      |\n",
            "|    time_elapsed       | 78        |\n",
            "|    total_timesteps    | 8000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -40.7     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1599      |\n",
            "|    policy_loss        | -149      |\n",
            "|    reward             | 2.7222698 |\n",
            "|    std                | 0.986     |\n",
            "|    value_loss         | 22.3      |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 100      |\n",
            "|    iterations         | 1700     |\n",
            "|    time_elapsed       | 84       |\n",
            "|    total_timesteps    | 8500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -40.7    |\n",
            "|    explained_variance | 2.98e-07 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1699     |\n",
            "|    policy_loss        | 282      |\n",
            "|    reward             | 1.794313 |\n",
            "|    std                | 0.985    |\n",
            "|    value_loss         | 75.2     |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 101       |\n",
            "|    iterations         | 1800      |\n",
            "|    time_elapsed       | 88        |\n",
            "|    total_timesteps    | 9000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -40.7     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1799      |\n",
            "|    policy_loss        | -50.8     |\n",
            "|    reward             | 0.6272349 |\n",
            "|    std                | 0.987     |\n",
            "|    value_loss         | 2.11      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 101        |\n",
            "|    iterations         | 1900       |\n",
            "|    time_elapsed       | 93         |\n",
            "|    total_timesteps    | 9500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -40.8      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1899       |\n",
            "|    policy_loss        | 123        |\n",
            "|    reward             | -0.4013819 |\n",
            "|    std                | 0.988      |\n",
            "|    value_loss         | 9.32       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 101        |\n",
            "|    iterations         | 2000       |\n",
            "|    time_elapsed       | 98         |\n",
            "|    total_timesteps    | 10000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -40.8      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1999       |\n",
            "|    policy_loss        | 25.4       |\n",
            "|    reward             | 0.29821917 |\n",
            "|    std                | 0.988      |\n",
            "|    value_loss         | 2.61       |\n",
            "--------------------------------------\n",
            "======a2c Validation from:  2018-01-03 to  2018-04-05\n",
            "a2c Sharpe Ratio:  -0.16025295465351833\n",
            "======ddpg Training========\n",
            "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/ddpg/ddpg_693_1\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    episodes        | 4         |\n",
            "|    fps             | 68        |\n",
            "|    time_elapsed    | 133       |\n",
            "|    total_timesteps | 9064      |\n",
            "| train/             |           |\n",
            "|    actor_loss      | 14.6      |\n",
            "|    critic_loss     | 5.49      |\n",
            "|    learning_rate   | 0.0005    |\n",
            "|    n_updates       | 8963      |\n",
            "|    reward          | 0.6409498 |\n",
            "----------------------------------\n",
            "======ddpg Validation from:  2018-01-03 to  2018-04-05\n",
            "ddpg Sharpe Ratio:  -0.08205862725225936\n",
            "======ppo Training========\n",
            "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/ppo/ppo_693_1\n",
            "-----------------------------------\n",
            "| time/              |            |\n",
            "|    fps             | 116        |\n",
            "|    iterations      | 1          |\n",
            "|    time_elapsed    | 17         |\n",
            "|    total_timesteps | 2048       |\n",
            "| train/             |            |\n",
            "|    reward          | 0.34369332 |\n",
            "-----------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 112         |\n",
            "|    iterations           | 2           |\n",
            "|    time_elapsed         | 36          |\n",
            "|    total_timesteps      | 4096        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.015079834 |\n",
            "|    clip_fraction        | 0.191       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.2       |\n",
            "|    explained_variance   | -0.0158     |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 5.05        |\n",
            "|    n_updates            | 10          |\n",
            "|    policy_gradient_loss | -0.0313     |\n",
            "|    reward               | 1.7724155   |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 12.6        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 112         |\n",
            "|    iterations           | 3           |\n",
            "|    time_elapsed         | 54          |\n",
            "|    total_timesteps      | 6144        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.017538477 |\n",
            "|    clip_fraction        | 0.206       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.2       |\n",
            "|    explained_variance   | -0.0232     |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 6.03        |\n",
            "|    n_updates            | 20          |\n",
            "|    policy_gradient_loss | -0.0231     |\n",
            "|    reward               | 0.2834468   |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 12.6        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 111         |\n",
            "|    iterations           | 4           |\n",
            "|    time_elapsed         | 73          |\n",
            "|    total_timesteps      | 8192        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.014987973 |\n",
            "|    clip_fraction        | 0.166       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.3       |\n",
            "|    explained_variance   | -0.0176     |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 4.62        |\n",
            "|    n_updates            | 30          |\n",
            "|    policy_gradient_loss | -0.0233     |\n",
            "|    reward               | 1.8827556   |\n",
            "|    std                  | 1.01        |\n",
            "|    value_loss           | 9.77        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 111         |\n",
            "|    iterations           | 5           |\n",
            "|    time_elapsed         | 91          |\n",
            "|    total_timesteps      | 10240       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.019959532 |\n",
            "|    clip_fraction        | 0.201       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.3       |\n",
            "|    explained_variance   | -0.0493     |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 4.21        |\n",
            "|    n_updates            | 40          |\n",
            "|    policy_gradient_loss | -0.0221     |\n",
            "|    reward               | 0.5641267   |\n",
            "|    std                  | 1.01        |\n",
            "|    value_loss           | 13.6        |\n",
            "-----------------------------------------\n",
            "======ppo Validation from:  2018-01-03 to  2018-04-05\n",
            "ppo Sharpe Ratio:  -0.11333924886444977\n",
            "======Best Model Retraining from:  2009-01-01 to  2018-04-05\n",
            "======Trading from:  2018-04-05 to  2018-07-05\n",
            "============================================\n",
            "turbulence_threshold:  160.3176626173842\n",
            "======Model training from:  2009-01-01 to  2018-04-05\n",
            "======a2c Training========\n",
            "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/a2c/a2c_756_1\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 96         |\n",
            "|    iterations         | 100        |\n",
            "|    time_elapsed       | 5          |\n",
            "|    total_timesteps    | 500        |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.3      |\n",
            "|    explained_variance | 0.0522     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 99         |\n",
            "|    policy_loss        | 34.9       |\n",
            "|    reward             | 0.78996253 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 0.939      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 103        |\n",
            "|    iterations         | 200        |\n",
            "|    time_elapsed       | 9          |\n",
            "|    total_timesteps    | 1000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.2      |\n",
            "|    explained_variance | -0.302     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 199        |\n",
            "|    policy_loss        | -40.9      |\n",
            "|    reward             | -1.4237739 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 1.5        |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 98        |\n",
            "|    iterations         | 300       |\n",
            "|    time_elapsed       | 15        |\n",
            "|    total_timesteps    | 1500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.2     |\n",
            "|    explained_variance | 0.327     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 299       |\n",
            "|    policy_loss        | -190      |\n",
            "|    reward             | 3.9566152 |\n",
            "|    std                | 1         |\n",
            "|    value_loss         | 23.2      |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 100      |\n",
            "|    iterations         | 400      |\n",
            "|    time_elapsed       | 19       |\n",
            "|    total_timesteps    | 2000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -41.2    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 399      |\n",
            "|    policy_loss        | -7.79    |\n",
            "|    reward             | 4.560357 |\n",
            "|    std                | 1        |\n",
            "|    value_loss         | 0.397    |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 101       |\n",
            "|    iterations         | 500       |\n",
            "|    time_elapsed       | 24        |\n",
            "|    total_timesteps    | 2500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.1     |\n",
            "|    explained_variance | -7.89     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 499       |\n",
            "|    policy_loss        | 75.3      |\n",
            "|    reward             | 1.1897352 |\n",
            "|    std                | 1         |\n",
            "|    value_loss         | 5.06      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 100        |\n",
            "|    iterations         | 600        |\n",
            "|    time_elapsed       | 29         |\n",
            "|    total_timesteps    | 3000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.2      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 599        |\n",
            "|    policy_loss        | 49.6       |\n",
            "|    reward             | 0.57485574 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 8.41       |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 101         |\n",
            "|    iterations         | 700         |\n",
            "|    time_elapsed       | 34          |\n",
            "|    total_timesteps    | 3500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -41.2       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 699         |\n",
            "|    policy_loss        | -189        |\n",
            "|    reward             | -0.07383065 |\n",
            "|    std                | 1           |\n",
            "|    value_loss         | 27          |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 100       |\n",
            "|    iterations         | 800       |\n",
            "|    time_elapsed       | 39        |\n",
            "|    total_timesteps    | 4000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.2     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 799       |\n",
            "|    policy_loss        | 117       |\n",
            "|    reward             | -12.12846 |\n",
            "|    std                | 1         |\n",
            "|    value_loss         | 11.8      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 101        |\n",
            "|    iterations         | 900        |\n",
            "|    time_elapsed       | 44         |\n",
            "|    total_timesteps    | 4500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.2      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 899        |\n",
            "|    policy_loss        | -26.5      |\n",
            "|    reward             | -4.4991245 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 1.82       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 101        |\n",
            "|    iterations         | 1000       |\n",
            "|    time_elapsed       | 49         |\n",
            "|    total_timesteps    | 5000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.2      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 999        |\n",
            "|    policy_loss        | -234       |\n",
            "|    reward             | -1.3206222 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 39         |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 100         |\n",
            "|    iterations         | 1100        |\n",
            "|    time_elapsed       | 54          |\n",
            "|    total_timesteps    | 5500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -41.2       |\n",
            "|    explained_variance | 1.19e-07    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1099        |\n",
            "|    policy_loss        | 70          |\n",
            "|    reward             | 0.101266205 |\n",
            "|    std                | 1           |\n",
            "|    value_loss         | 7.38        |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 101        |\n",
            "|    iterations         | 1200       |\n",
            "|    time_elapsed       | 59         |\n",
            "|    total_timesteps    | 6000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.2      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1199       |\n",
            "|    policy_loss        | 57.6       |\n",
            "|    reward             | -0.8703138 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 4.56       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 100        |\n",
            "|    iterations         | 1300       |\n",
            "|    time_elapsed       | 64         |\n",
            "|    total_timesteps    | 6500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.3      |\n",
            "|    explained_variance | 1.19e-07   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1299       |\n",
            "|    policy_loss        | -437       |\n",
            "|    reward             | -3.0184968 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 96.6       |\n",
            "--------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 100           |\n",
            "|    iterations         | 1400          |\n",
            "|    time_elapsed       | 69            |\n",
            "|    total_timesteps    | 7000          |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -41.2         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 1399          |\n",
            "|    policy_loss        | -29           |\n",
            "|    reward             | -0.0027338914 |\n",
            "|    std                | 1             |\n",
            "|    value_loss         | 0.509         |\n",
            "-----------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 100       |\n",
            "|    iterations         | 1500      |\n",
            "|    time_elapsed       | 74        |\n",
            "|    total_timesteps    | 7500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.2     |\n",
            "|    explained_variance | 0.0211    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1499      |\n",
            "|    policy_loss        | -27.3     |\n",
            "|    reward             | 0.9069477 |\n",
            "|    std                | 1         |\n",
            "|    value_loss         | 0.643     |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 100       |\n",
            "|    iterations         | 1600      |\n",
            "|    time_elapsed       | 79        |\n",
            "|    total_timesteps    | 8000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.2     |\n",
            "|    explained_variance | -0.00499  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1599      |\n",
            "|    policy_loss        | 120       |\n",
            "|    reward             | 1.1944638 |\n",
            "|    std                | 1         |\n",
            "|    value_loss         | 15.8      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 100       |\n",
            "|    iterations         | 1700      |\n",
            "|    time_elapsed       | 84        |\n",
            "|    total_timesteps    | 8500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.2     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1699      |\n",
            "|    policy_loss        | -67.7     |\n",
            "|    reward             | 1.0266932 |\n",
            "|    std                | 1         |\n",
            "|    value_loss         | 3.12      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 99         |\n",
            "|    iterations         | 1800       |\n",
            "|    time_elapsed       | 90         |\n",
            "|    total_timesteps    | 9000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.3      |\n",
            "|    explained_variance | -2.38e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1799       |\n",
            "|    policy_loss        | -30.1      |\n",
            "|    reward             | -0.8274133 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 1.09       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 100        |\n",
            "|    iterations         | 1900       |\n",
            "|    time_elapsed       | 94         |\n",
            "|    total_timesteps    | 9500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.3      |\n",
            "|    explained_variance | -0.119     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1899       |\n",
            "|    policy_loss        | 48.4       |\n",
            "|    reward             | -1.0190544 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 3.22       |\n",
            "--------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 99       |\n",
            "|    iterations         | 2000     |\n",
            "|    time_elapsed       | 100      |\n",
            "|    total_timesteps    | 10000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -41.3    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1999     |\n",
            "|    policy_loss        | -27.2    |\n",
            "|    reward             | 1.44794  |\n",
            "|    std                | 1.01     |\n",
            "|    value_loss         | 7.98     |\n",
            "------------------------------------\n",
            "======a2c Validation from:  2018-04-05 to  2018-07-05\n",
            "a2c Sharpe Ratio:  -0.17176967402300136\n",
            "======ddpg Training========\n",
            "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/ddpg/ddpg_756_1\n",
            "---------------------------------\n",
            "| time/              |          |\n",
            "|    episodes        | 4        |\n",
            "|    fps             | 67       |\n",
            "|    time_elapsed    | 137      |\n",
            "|    total_timesteps | 9316     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -0.181   |\n",
            "|    critic_loss     | 178      |\n",
            "|    learning_rate   | 0.0005   |\n",
            "|    n_updates       | 9215     |\n",
            "|    reward          | 5.100875 |\n",
            "---------------------------------\n",
            "======ddpg Validation from:  2018-04-05 to  2018-07-05\n",
            "ddpg Sharpe Ratio:  0.09395963078853962\n",
            "======ppo Training========\n",
            "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/ppo/ppo_756_1\n",
            "-----------------------------------\n",
            "| time/              |            |\n",
            "|    fps             | 114        |\n",
            "|    iterations      | 1          |\n",
            "|    time_elapsed    | 17         |\n",
            "|    total_timesteps | 2048       |\n",
            "| train/             |            |\n",
            "|    reward          | 0.19393958 |\n",
            "-----------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 108         |\n",
            "|    iterations           | 2           |\n",
            "|    time_elapsed         | 37          |\n",
            "|    total_timesteps      | 4096        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.019346695 |\n",
            "|    clip_fraction        | 0.251       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.2       |\n",
            "|    explained_variance   | 0.000226    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 7.38        |\n",
            "|    n_updates            | 10          |\n",
            "|    policy_gradient_loss | -0.022      |\n",
            "|    reward               | 0.65395516  |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 16.5        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 108         |\n",
            "|    iterations           | 3           |\n",
            "|    time_elapsed         | 56          |\n",
            "|    total_timesteps      | 6144        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.016858768 |\n",
            "|    clip_fraction        | 0.188       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.2       |\n",
            "|    explained_variance   | -0.00618    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 9.34        |\n",
            "|    n_updates            | 20          |\n",
            "|    policy_gradient_loss | -0.0191     |\n",
            "|    reward               | 1.1978259   |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 21          |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 107         |\n",
            "|    iterations           | 4           |\n",
            "|    time_elapsed         | 76          |\n",
            "|    total_timesteps      | 8192        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.020925095 |\n",
            "|    clip_fraction        | 0.187       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.3       |\n",
            "|    explained_variance   | -0.0417     |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 9.44        |\n",
            "|    n_updates            | 30          |\n",
            "|    policy_gradient_loss | -0.0189     |\n",
            "|    reward               | 2.3949506   |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 17.8        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 108         |\n",
            "|    iterations           | 5           |\n",
            "|    time_elapsed         | 94          |\n",
            "|    total_timesteps      | 10240       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.015014063 |\n",
            "|    clip_fraction        | 0.107       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.3       |\n",
            "|    explained_variance   | -0.02       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 9.28        |\n",
            "|    n_updates            | 40          |\n",
            "|    policy_gradient_loss | -0.0194     |\n",
            "|    reward               | 1.2777423   |\n",
            "|    std                  | 1.01        |\n",
            "|    value_loss           | 21.5        |\n",
            "-----------------------------------------\n",
            "======ppo Validation from:  2018-04-05 to  2018-07-05\n",
            "ppo Sharpe Ratio:  -0.08921806831858621\n",
            "======Best Model Retraining from:  2009-01-01 to  2018-07-05\n",
            "======Trading from:  2018-07-05 to  2018-10-03\n",
            "============================================\n",
            "turbulence_threshold:  160.3176626173842\n",
            "======Model training from:  2009-01-01 to  2018-07-05\n",
            "======a2c Training========\n",
            "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/a2c/a2c_819_1\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 88          |\n",
            "|    iterations         | 100         |\n",
            "|    time_elapsed       | 5           |\n",
            "|    total_timesteps    | 500         |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -41.1       |\n",
            "|    explained_variance | 0.152       |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 99          |\n",
            "|    policy_loss        | -56.6       |\n",
            "|    reward             | -0.14477296 |\n",
            "|    std                | 0.998       |\n",
            "|    value_loss         | 3.49        |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 96        |\n",
            "|    iterations         | 200       |\n",
            "|    time_elapsed       | 10        |\n",
            "|    total_timesteps    | 1000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.1     |\n",
            "|    explained_variance | -0.113    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 199       |\n",
            "|    policy_loss        | -4.83     |\n",
            "|    reward             | -2.956882 |\n",
            "|    std                | 0.998     |\n",
            "|    value_loss         | 0.25      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 93        |\n",
            "|    iterations         | 300       |\n",
            "|    time_elapsed       | 16        |\n",
            "|    total_timesteps    | 1500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.1     |\n",
            "|    explained_variance | 0.201     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 299       |\n",
            "|    policy_loss        | -150      |\n",
            "|    reward             | 3.8176622 |\n",
            "|    std                | 1         |\n",
            "|    value_loss         | 11.7      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 96         |\n",
            "|    iterations         | 400        |\n",
            "|    time_elapsed       | 20         |\n",
            "|    total_timesteps    | 2000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.1      |\n",
            "|    explained_variance | -0.0683    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 399        |\n",
            "|    policy_loss        | 32.8       |\n",
            "|    reward             | 0.60199267 |\n",
            "|    std                | 0.998      |\n",
            "|    value_loss         | 9.65       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 95         |\n",
            "|    iterations         | 500        |\n",
            "|    time_elapsed       | 26         |\n",
            "|    total_timesteps    | 2500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.1      |\n",
            "|    explained_variance | -0.00208   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 499        |\n",
            "|    policy_loss        | 119        |\n",
            "|    reward             | 0.33094817 |\n",
            "|    std                | 0.998      |\n",
            "|    value_loss         | 9.71       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 96         |\n",
            "|    iterations         | 600        |\n",
            "|    time_elapsed       | 31         |\n",
            "|    total_timesteps    | 3000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.1      |\n",
            "|    explained_variance | -0.0959    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 599        |\n",
            "|    policy_loss        | -86.9      |\n",
            "|    reward             | -0.6861569 |\n",
            "|    std                | 0.999      |\n",
            "|    value_loss         | 4.86       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 98        |\n",
            "|    iterations         | 700       |\n",
            "|    time_elapsed       | 35        |\n",
            "|    total_timesteps    | 3500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.1     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 699       |\n",
            "|    policy_loss        | -103      |\n",
            "|    reward             | -0.318794 |\n",
            "|    std                | 1         |\n",
            "|    value_loss         | 10        |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 97         |\n",
            "|    iterations         | 800        |\n",
            "|    time_elapsed       | 41         |\n",
            "|    total_timesteps    | 4000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.1      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 799        |\n",
            "|    policy_loss        | 65.9       |\n",
            "|    reward             | -2.4549305 |\n",
            "|    std                | 0.998      |\n",
            "|    value_loss         | 4.31       |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 98          |\n",
            "|    iterations         | 900         |\n",
            "|    time_elapsed       | 45          |\n",
            "|    total_timesteps    | 4500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -41.1       |\n",
            "|    explained_variance | -1.86       |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 899         |\n",
            "|    policy_loss        | -14.2       |\n",
            "|    reward             | -0.15371473 |\n",
            "|    std                | 0.999       |\n",
            "|    value_loss         | 0.983       |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 97         |\n",
            "|    iterations         | 1000       |\n",
            "|    time_elapsed       | 51         |\n",
            "|    total_timesteps    | 5000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.1      |\n",
            "|    explained_variance | -0.00204   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 999        |\n",
            "|    policy_loss        | -24.9      |\n",
            "|    reward             | 0.40709543 |\n",
            "|    std                | 0.999      |\n",
            "|    value_loss         | 1.8        |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 98        |\n",
            "|    iterations         | 1100      |\n",
            "|    time_elapsed       | 55        |\n",
            "|    total_timesteps    | 5500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.2     |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1099      |\n",
            "|    policy_loss        | 218       |\n",
            "|    reward             | 2.5987053 |\n",
            "|    std                | 1         |\n",
            "|    value_loss         | 31.8      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 99         |\n",
            "|    iterations         | 1200       |\n",
            "|    time_elapsed       | 60         |\n",
            "|    total_timesteps    | 6000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.2      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1199       |\n",
            "|    policy_loss        | 83.2       |\n",
            "|    reward             | -2.3244557 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 4.19       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 98         |\n",
            "|    iterations         | 1300       |\n",
            "|    time_elapsed       | 66         |\n",
            "|    total_timesteps    | 6500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.2      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1299       |\n",
            "|    policy_loss        | 120        |\n",
            "|    reward             | -0.6863916 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 11.5       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 99        |\n",
            "|    iterations         | 1400      |\n",
            "|    time_elapsed       | 70        |\n",
            "|    total_timesteps    | 7000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.2     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1399      |\n",
            "|    policy_loss        | -36.8     |\n",
            "|    reward             | 1.2362759 |\n",
            "|    std                | 1         |\n",
            "|    value_loss         | 1.61      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 98        |\n",
            "|    iterations         | 1500      |\n",
            "|    time_elapsed       | 76        |\n",
            "|    total_timesteps    | 7500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.2     |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1499      |\n",
            "|    policy_loss        | 7.03      |\n",
            "|    reward             | 0.7100594 |\n",
            "|    std                | 1         |\n",
            "|    value_loss         | 0.849     |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 98        |\n",
            "|    iterations         | 1600      |\n",
            "|    time_elapsed       | 80        |\n",
            "|    total_timesteps    | 8000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.2     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1599      |\n",
            "|    policy_loss        | -3.82     |\n",
            "|    reward             | 1.8534517 |\n",
            "|    std                | 1         |\n",
            "|    value_loss         | 0.502     |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 99          |\n",
            "|    iterations         | 1700        |\n",
            "|    time_elapsed       | 85          |\n",
            "|    total_timesteps    | 8500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -41.2       |\n",
            "|    explained_variance | -1.19e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1699        |\n",
            "|    policy_loss        | 67.4        |\n",
            "|    reward             | -0.94110197 |\n",
            "|    std                | 1           |\n",
            "|    value_loss         | 5.93        |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 99         |\n",
            "|    iterations         | 1800       |\n",
            "|    time_elapsed       | 90         |\n",
            "|    total_timesteps    | 9000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.2      |\n",
            "|    explained_variance | -0.0531    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1799       |\n",
            "|    policy_loss        | -33.5      |\n",
            "|    reward             | -0.6783001 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 1.28       |\n",
            "--------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 99       |\n",
            "|    iterations         | 1900     |\n",
            "|    time_elapsed       | 95       |\n",
            "|    total_timesteps    | 9500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -41.2    |\n",
            "|    explained_variance | 0.0608   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1899     |\n",
            "|    policy_loss        | -131     |\n",
            "|    reward             | 2.414979 |\n",
            "|    std                | 1        |\n",
            "|    value_loss         | 17.4     |\n",
            "------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 98         |\n",
            "|    iterations         | 2000       |\n",
            "|    time_elapsed       | 101        |\n",
            "|    total_timesteps    | 10000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.1      |\n",
            "|    explained_variance | -0.0561    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1999       |\n",
            "|    policy_loss        | 64.4       |\n",
            "|    reward             | -0.6072275 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 4.77       |\n",
            "--------------------------------------\n",
            "======a2c Validation from:  2018-07-05 to  2018-10-03\n",
            "a2c Sharpe Ratio:  0.29472992117032126\n",
            "======ddpg Training========\n",
            "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/ddpg/ddpg_819_1\n",
            "-----------------------------------\n",
            "| time/              |            |\n",
            "|    episodes        | 4          |\n",
            "|    fps             | 65         |\n",
            "|    time_elapsed    | 145        |\n",
            "|    total_timesteps | 9568       |\n",
            "| train/             |            |\n",
            "|    actor_loss      | -31.3      |\n",
            "|    critic_loss     | 325        |\n",
            "|    learning_rate   | 0.0005     |\n",
            "|    n_updates       | 9467       |\n",
            "|    reward          | -2.2741778 |\n",
            "-----------------------------------\n",
            "======ddpg Validation from:  2018-07-05 to  2018-10-03\n",
            "ddpg Sharpe Ratio:  0.5903977589559276\n",
            "======ppo Training========\n",
            "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/ppo/ppo_819_1\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    fps             | 111       |\n",
            "|    iterations      | 1         |\n",
            "|    time_elapsed    | 18        |\n",
            "|    total_timesteps | 2048      |\n",
            "| train/             |           |\n",
            "|    reward          | 0.6386058 |\n",
            "----------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 108         |\n",
            "|    iterations           | 2           |\n",
            "|    time_elapsed         | 37          |\n",
            "|    total_timesteps      | 4096        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.016384946 |\n",
            "|    clip_fraction        | 0.219       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.2       |\n",
            "|    explained_variance   | -0.0149     |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 4.55        |\n",
            "|    n_updates            | 10          |\n",
            "|    policy_gradient_loss | -0.0199     |\n",
            "|    reward               | 0.19373555  |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 10.8        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 106         |\n",
            "|    iterations           | 3           |\n",
            "|    time_elapsed         | 57          |\n",
            "|    total_timesteps      | 6144        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.019126473 |\n",
            "|    clip_fraction        | 0.205       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.3       |\n",
            "|    explained_variance   | 0.00147     |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 4.49        |\n",
            "|    n_updates            | 20          |\n",
            "|    policy_gradient_loss | -0.017      |\n",
            "|    reward               | 0.03355475  |\n",
            "|    std                  | 1.01        |\n",
            "|    value_loss           | 11.7        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 107         |\n",
            "|    iterations           | 4           |\n",
            "|    time_elapsed         | 76          |\n",
            "|    total_timesteps      | 8192        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.019269992 |\n",
            "|    clip_fraction        | 0.224       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.4       |\n",
            "|    explained_variance   | 0.0054      |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 8.02        |\n",
            "|    n_updates            | 30          |\n",
            "|    policy_gradient_loss | -0.0179     |\n",
            "|    reward               | -0.290234   |\n",
            "|    std                  | 1.01        |\n",
            "|    value_loss           | 13.8        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 106         |\n",
            "|    iterations           | 5           |\n",
            "|    time_elapsed         | 96          |\n",
            "|    total_timesteps      | 10240       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.013231226 |\n",
            "|    clip_fraction        | 0.143       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.4       |\n",
            "|    explained_variance   | 0.0156      |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 7.85        |\n",
            "|    n_updates            | 40          |\n",
            "|    policy_gradient_loss | -0.0192     |\n",
            "|    reward               | -1.5273653  |\n",
            "|    std                  | 1.01        |\n",
            "|    value_loss           | 19.4        |\n",
            "-----------------------------------------\n",
            "======ppo Validation from:  2018-07-05 to  2018-10-03\n",
            "ppo Sharpe Ratio:  0.47625812066583323\n",
            "======Best Model Retraining from:  2009-01-01 to  2018-10-03\n",
            "======Trading from:  2018-10-03 to  2019-01-04\n",
            "============================================\n",
            "turbulence_threshold:  160.3176626173842\n",
            "======Model training from:  2009-01-01 to  2018-10-03\n",
            "======a2c Training========\n",
            "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/a2c/a2c_882_1\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 105         |\n",
            "|    iterations         | 100         |\n",
            "|    time_elapsed       | 4           |\n",
            "|    total_timesteps    | 500         |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -41.1       |\n",
            "|    explained_variance | -0.0247     |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 99          |\n",
            "|    policy_loss        | -109        |\n",
            "|    reward             | -0.23676558 |\n",
            "|    std                | 0.999       |\n",
            "|    value_loss         | 9.32        |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 96         |\n",
            "|    iterations         | 200        |\n",
            "|    time_elapsed       | 10         |\n",
            "|    total_timesteps    | 1000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.1      |\n",
            "|    explained_variance | -0.00436   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 199        |\n",
            "|    policy_loss        | 0.143      |\n",
            "|    reward             | -1.0895972 |\n",
            "|    std                | 0.999      |\n",
            "|    value_loss         | 7.23       |\n",
            "--------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 99       |\n",
            "|    iterations         | 300      |\n",
            "|    time_elapsed       | 15       |\n",
            "|    total_timesteps    | 1500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -41.1    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 299      |\n",
            "|    policy_loss        | -422     |\n",
            "|    reward             | 9.125387 |\n",
            "|    std                | 0.998    |\n",
            "|    value_loss         | 118      |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 92        |\n",
            "|    iterations         | 400       |\n",
            "|    time_elapsed       | 21        |\n",
            "|    total_timesteps    | 2000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.1     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 399       |\n",
            "|    policy_loss        | -55       |\n",
            "|    reward             | 0.5975148 |\n",
            "|    std                | 0.998     |\n",
            "|    value_loss         | 10        |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 95         |\n",
            "|    iterations         | 500        |\n",
            "|    time_elapsed       | 26         |\n",
            "|    total_timesteps    | 2500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.1      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 499        |\n",
            "|    policy_loss        | -34.8      |\n",
            "|    reward             | 0.83215016 |\n",
            "|    std                | 0.997      |\n",
            "|    value_loss         | 0.962      |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 96        |\n",
            "|    iterations         | 600       |\n",
            "|    time_elapsed       | 31        |\n",
            "|    total_timesteps    | 3000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.1     |\n",
            "|    explained_variance | -0.15     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 599       |\n",
            "|    policy_loss        | -114      |\n",
            "|    reward             | 2.7568545 |\n",
            "|    std                | 0.999     |\n",
            "|    value_loss         | 9.66      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 95         |\n",
            "|    iterations         | 700        |\n",
            "|    time_elapsed       | 36         |\n",
            "|    total_timesteps    | 3500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.1      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 699        |\n",
            "|    policy_loss        | -40.9      |\n",
            "|    reward             | 0.14841603 |\n",
            "|    std                | 0.999      |\n",
            "|    value_loss         | 1.22       |\n",
            "--------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 96       |\n",
            "|    iterations         | 800      |\n",
            "|    time_elapsed       | 41       |\n",
            "|    total_timesteps    | 4000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -41.2    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 799      |\n",
            "|    policy_loss        | 56.6     |\n",
            "|    reward             | 1.276966 |\n",
            "|    std                | 1        |\n",
            "|    value_loss         | 6.45     |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 95        |\n",
            "|    iterations         | 900       |\n",
            "|    time_elapsed       | 47        |\n",
            "|    total_timesteps    | 4500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.2     |\n",
            "|    explained_variance | -0.508    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 899       |\n",
            "|    policy_loss        | 90.9      |\n",
            "|    reward             | 1.1046634 |\n",
            "|    std                | 1         |\n",
            "|    value_loss         | 5.44      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 96        |\n",
            "|    iterations         | 1000      |\n",
            "|    time_elapsed       | 52        |\n",
            "|    total_timesteps    | 5000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.2     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 999       |\n",
            "|    policy_loss        | 84.5      |\n",
            "|    reward             | -0.772416 |\n",
            "|    std                | 1         |\n",
            "|    value_loss         | 6.24      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 95         |\n",
            "|    iterations         | 1100       |\n",
            "|    time_elapsed       | 57         |\n",
            "|    total_timesteps    | 5500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.2      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1099       |\n",
            "|    policy_loss        | 85.9       |\n",
            "|    reward             | 0.69210666 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 6.31       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 96        |\n",
            "|    iterations         | 1200      |\n",
            "|    time_elapsed       | 62        |\n",
            "|    total_timesteps    | 6000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.2     |\n",
            "|    explained_variance | -0.0127   |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1199      |\n",
            "|    policy_loss        | -53.4     |\n",
            "|    reward             | 2.8484972 |\n",
            "|    std                | 1         |\n",
            "|    value_loss         | 3.2       |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 96         |\n",
            "|    iterations         | 1300       |\n",
            "|    time_elapsed       | 67         |\n",
            "|    total_timesteps    | 6500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.2      |\n",
            "|    explained_variance | -0.0212    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1299       |\n",
            "|    policy_loss        | -52.8      |\n",
            "|    reward             | -2.2636986 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 10.5       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 95        |\n",
            "|    iterations         | 1400      |\n",
            "|    time_elapsed       | 72        |\n",
            "|    total_timesteps    | 7000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.1     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1399      |\n",
            "|    policy_loss        | 54.6      |\n",
            "|    reward             | 4.398274  |\n",
            "|    std                | 0.999     |\n",
            "|    value_loss         | 3.21      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 96        |\n",
            "|    iterations         | 1500      |\n",
            "|    time_elapsed       | 77        |\n",
            "|    total_timesteps    | 7500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.1     |\n",
            "|    explained_variance | -5.22     |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1499      |\n",
            "|    policy_loss        | 42.8      |\n",
            "|    reward             | 0.2964501 |\n",
            "|    std                | 0.999     |\n",
            "|    value_loss         | 1.64      |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 95          |\n",
            "|    iterations         | 1600        |\n",
            "|    time_elapsed       | 83          |\n",
            "|    total_timesteps    | 8000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -41.1       |\n",
            "|    explained_variance | -0.12       |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1599        |\n",
            "|    policy_loss        | 101         |\n",
            "|    reward             | -0.74572587 |\n",
            "|    std                | 0.999       |\n",
            "|    value_loss         | 11          |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 95        |\n",
            "|    iterations         | 1700      |\n",
            "|    time_elapsed       | 88        |\n",
            "|    total_timesteps    | 8500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.1     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1699      |\n",
            "|    policy_loss        | 140       |\n",
            "|    reward             | 0.9429633 |\n",
            "|    std                | 0.998     |\n",
            "|    value_loss         | 18.4      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 96         |\n",
            "|    iterations         | 1800       |\n",
            "|    time_elapsed       | 93         |\n",
            "|    total_timesteps    | 9000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.1      |\n",
            "|    explained_variance | -0.0699    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1799       |\n",
            "|    policy_loss        | -213       |\n",
            "|    reward             | -0.3158955 |\n",
            "|    std                | 0.998      |\n",
            "|    value_loss         | 29.7       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 95         |\n",
            "|    iterations         | 1900       |\n",
            "|    time_elapsed       | 99         |\n",
            "|    total_timesteps    | 9500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.1      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1899       |\n",
            "|    policy_loss        | 152        |\n",
            "|    reward             | -1.5639611 |\n",
            "|    std                | 0.997      |\n",
            "|    value_loss         | 22.7       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 95         |\n",
            "|    iterations         | 2000       |\n",
            "|    time_elapsed       | 104        |\n",
            "|    total_timesteps    | 10000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.1      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1999       |\n",
            "|    policy_loss        | 38.3       |\n",
            "|    reward             | -0.7518492 |\n",
            "|    std                | 0.998      |\n",
            "|    value_loss         | 1.68       |\n",
            "--------------------------------------\n",
            "======a2c Validation from:  2018-10-03 to  2019-01-04\n",
            "a2c Sharpe Ratio:  -0.1900092386750164\n",
            "======ddpg Training========\n",
            "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/ddpg/ddpg_882_1\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    episodes        | 4         |\n",
            "|    fps             | 65        |\n",
            "|    time_elapsed    | 149       |\n",
            "|    total_timesteps | 9820      |\n",
            "| train/             |           |\n",
            "|    actor_loss      | -252      |\n",
            "|    critic_loss     | 256       |\n",
            "|    learning_rate   | 0.0005    |\n",
            "|    n_updates       | 9719      |\n",
            "|    reward          | -0.838547 |\n",
            "----------------------------------\n",
            "======ddpg Validation from:  2018-10-03 to  2019-01-04\n",
            "ddpg Sharpe Ratio:  -0.09821184206990641\n",
            "======ppo Training========\n",
            "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/ppo/ppo_882_1\n",
            "-----------------------------------\n",
            "| time/              |            |\n",
            "|    fps             | 108        |\n",
            "|    iterations      | 1          |\n",
            "|    time_elapsed    | 18         |\n",
            "|    total_timesteps | 2048       |\n",
            "| train/             |            |\n",
            "|    reward          | 0.22483058 |\n",
            "-----------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 103         |\n",
            "|    iterations           | 2           |\n",
            "|    time_elapsed         | 39          |\n",
            "|    total_timesteps      | 4096        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.015218064 |\n",
            "|    clip_fraction        | 0.23        |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.2       |\n",
            "|    explained_variance   | -0.00227    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 6.18        |\n",
            "|    n_updates            | 10          |\n",
            "|    policy_gradient_loss | -0.0184     |\n",
            "|    reward               | 3.400883    |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 12.7        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 103         |\n",
            "|    iterations           | 3           |\n",
            "|    time_elapsed         | 59          |\n",
            "|    total_timesteps      | 6144        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.013621608 |\n",
            "|    clip_fraction        | 0.165       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.2       |\n",
            "|    explained_variance   | -0.0525     |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 9.46        |\n",
            "|    n_updates            | 20          |\n",
            "|    policy_gradient_loss | -0.0177     |\n",
            "|    reward               | -0.08240763 |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 19.5        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 103         |\n",
            "|    iterations           | 4           |\n",
            "|    time_elapsed         | 79          |\n",
            "|    total_timesteps      | 8192        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.016183484 |\n",
            "|    clip_fraction        | 0.145       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.3       |\n",
            "|    explained_variance   | -0.00206    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 19.3        |\n",
            "|    n_updates            | 30          |\n",
            "|    policy_gradient_loss | -0.0174     |\n",
            "|    reward               | 0.030768827 |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 33.9        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 102         |\n",
            "|    iterations           | 5           |\n",
            "|    time_elapsed         | 99          |\n",
            "|    total_timesteps      | 10240       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.017536487 |\n",
            "|    clip_fraction        | 0.139       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.3       |\n",
            "|    explained_variance   | -0.0102     |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 21.4        |\n",
            "|    n_updates            | 40          |\n",
            "|    policy_gradient_loss | -0.0129     |\n",
            "|    reward               | 1.1932062   |\n",
            "|    std                  | 1.01        |\n",
            "|    value_loss           | 39.5        |\n",
            "-----------------------------------------\n",
            "======ppo Validation from:  2018-10-03 to  2019-01-04\n",
            "ppo Sharpe Ratio:  -0.2198924787926345\n",
            "======Best Model Retraining from:  2009-01-01 to  2019-01-04\n",
            "======Trading from:  2019-01-04 to  2019-04-05\n",
            "============================================\n",
            "turbulence_threshold:  160.3176626173842\n",
            "======Model training from:  2009-01-01 to  2019-01-04\n",
            "======a2c Training========\n",
            "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/a2c/a2c_945_1\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 100        |\n",
            "|    iterations         | 100        |\n",
            "|    time_elapsed       | 4          |\n",
            "|    total_timesteps    | 500        |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.2      |\n",
            "|    explained_variance | -0.626     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 99         |\n",
            "|    policy_loss        | 11.8       |\n",
            "|    reward             | 0.21394147 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 0.191      |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 91          |\n",
            "|    iterations         | 200         |\n",
            "|    time_elapsed       | 10          |\n",
            "|    total_timesteps    | 1000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -41.3       |\n",
            "|    explained_variance | 0.0344      |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 199         |\n",
            "|    policy_loss        | -23.3       |\n",
            "|    reward             | -0.43638504 |\n",
            "|    std                | 1           |\n",
            "|    value_loss         | 0.644       |\n",
            "---------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 94       |\n",
            "|    iterations         | 300      |\n",
            "|    time_elapsed       | 15       |\n",
            "|    total_timesteps    | 1500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -41.3    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 299      |\n",
            "|    policy_loss        | -181     |\n",
            "|    reward             | 4.349813 |\n",
            "|    std                | 1.01     |\n",
            "|    value_loss         | 23       |\n",
            "------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 92          |\n",
            "|    iterations         | 400         |\n",
            "|    time_elapsed       | 21          |\n",
            "|    total_timesteps    | 2000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -41.3       |\n",
            "|    explained_variance | 1.19e-07    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 399         |\n",
            "|    policy_loss        | 130         |\n",
            "|    reward             | -0.15761138 |\n",
            "|    std                | 1.01        |\n",
            "|    value_loss         | 11.3        |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 92        |\n",
            "|    iterations         | 500       |\n",
            "|    time_elapsed       | 26        |\n",
            "|    total_timesteps    | 2500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.4     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 499       |\n",
            "|    policy_loss        | 431       |\n",
            "|    reward             | -8.598996 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 117       |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 94       |\n",
            "|    iterations         | 600      |\n",
            "|    time_elapsed       | 31       |\n",
            "|    total_timesteps    | 3000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -41.3    |\n",
            "|    explained_variance | -0.00274 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 599      |\n",
            "|    policy_loss        | -30.7    |\n",
            "|    reward             | 3.29336  |\n",
            "|    std                | 1.01     |\n",
            "|    value_loss         | 3.99     |\n",
            "------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 92         |\n",
            "|    iterations         | 700        |\n",
            "|    time_elapsed       | 37         |\n",
            "|    total_timesteps    | 3500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.3      |\n",
            "|    explained_variance | 0.192      |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 699        |\n",
            "|    policy_loss        | 130        |\n",
            "|    reward             | -1.2179039 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 14.4       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 93        |\n",
            "|    iterations         | 800       |\n",
            "|    time_elapsed       | 42        |\n",
            "|    total_timesteps    | 4000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.3     |\n",
            "|    explained_variance | 0.00958   |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 799       |\n",
            "|    policy_loss        | 6         |\n",
            "|    reward             | 1.0236133 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 1.34      |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 92          |\n",
            "|    iterations         | 900         |\n",
            "|    time_elapsed       | 48          |\n",
            "|    total_timesteps    | 4500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -41.3       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 899         |\n",
            "|    policy_loss        | 243         |\n",
            "|    reward             | 0.029725226 |\n",
            "|    std                | 1.01        |\n",
            "|    value_loss         | 42.5        |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 93        |\n",
            "|    iterations         | 1000      |\n",
            "|    time_elapsed       | 53        |\n",
            "|    total_timesteps    | 5000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.4     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 999       |\n",
            "|    policy_loss        | 437       |\n",
            "|    reward             | -2.881015 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 164       |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 92        |\n",
            "|    iterations         | 1100      |\n",
            "|    time_elapsed       | 59        |\n",
            "|    total_timesteps    | 5500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.4     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1099      |\n",
            "|    policy_loss        | 31.4      |\n",
            "|    reward             | 1.0798079 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 0.787     |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 92         |\n",
            "|    iterations         | 1200       |\n",
            "|    time_elapsed       | 64         |\n",
            "|    total_timesteps    | 6000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.4      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1199       |\n",
            "|    policy_loss        | -68.9      |\n",
            "|    reward             | -2.3282993 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 7.44       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 93        |\n",
            "|    iterations         | 1300      |\n",
            "|    time_elapsed       | 69        |\n",
            "|    total_timesteps    | 6500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.4     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1299      |\n",
            "|    policy_loss        | 349       |\n",
            "|    reward             | 0.5724334 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 76.2      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 93         |\n",
            "|    iterations         | 1400       |\n",
            "|    time_elapsed       | 75         |\n",
            "|    total_timesteps    | 7000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.3      |\n",
            "|    explained_variance | 1.19e-07   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1399       |\n",
            "|    policy_loss        | -86.8      |\n",
            "|    reward             | 0.14456655 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 5.53       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 93        |\n",
            "|    iterations         | 1500      |\n",
            "|    time_elapsed       | 80        |\n",
            "|    total_timesteps    | 7500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.3     |\n",
            "|    explained_variance | 5.96e-08  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1499      |\n",
            "|    policy_loss        | -110      |\n",
            "|    reward             | 15.928825 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 55.4      |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 93          |\n",
            "|    iterations         | 1600        |\n",
            "|    time_elapsed       | 85          |\n",
            "|    total_timesteps    | 8000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -41.3       |\n",
            "|    explained_variance | -0.171      |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1599        |\n",
            "|    policy_loss        | -28         |\n",
            "|    reward             | 0.027018532 |\n",
            "|    std                | 1.01        |\n",
            "|    value_loss         | 0.651       |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 93        |\n",
            "|    iterations         | 1700      |\n",
            "|    time_elapsed       | 90        |\n",
            "|    total_timesteps    | 8500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.3     |\n",
            "|    explained_variance | 5.96e-08  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1699      |\n",
            "|    policy_loss        | -87.2     |\n",
            "|    reward             | 0.5363068 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 5.38      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 93         |\n",
            "|    iterations         | 1800       |\n",
            "|    time_elapsed       | 96         |\n",
            "|    total_timesteps    | 9000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.3      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1799       |\n",
            "|    policy_loss        | -54.5      |\n",
            "|    reward             | -5.7195334 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 9.6        |\n",
            "--------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 93       |\n",
            "|    iterations         | 1900     |\n",
            "|    time_elapsed       | 101      |\n",
            "|    total_timesteps    | 9500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -41.3    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1899     |\n",
            "|    policy_loss        | -108     |\n",
            "|    reward             | -5.60283 |\n",
            "|    std                | 1        |\n",
            "|    value_loss         | 13.1     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 94       |\n",
            "|    iterations         | 2000     |\n",
            "|    time_elapsed       | 106      |\n",
            "|    total_timesteps    | 10000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -41.2    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1999     |\n",
            "|    policy_loss        | 507      |\n",
            "|    reward             | 8.332593 |\n",
            "|    std                | 1        |\n",
            "|    value_loss         | 209      |\n",
            "------------------------------------\n",
            "======a2c Validation from:  2019-01-04 to  2019-04-05\n",
            "a2c Sharpe Ratio:  0.13031372017820128\n",
            "======ddpg Training========\n",
            "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/ddpg/ddpg_945_1\n",
            "day: 2517, episode: 5\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 3890791.52\n",
            "total_reward: 2890791.52\n",
            "total_cost: 5784.95\n",
            "total_trades: 32227\n",
            "Sharpe: 1.180\n",
            "=================================\n",
            "======ddpg Validation from:  2019-01-04 to  2019-04-05\n",
            "ddpg Sharpe Ratio:  0.38604499506616974\n",
            "======ppo Training========\n",
            "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/ppo/ppo_945_1\n",
            "---------------------------------\n",
            "| time/              |          |\n",
            "|    fps             | 101      |\n",
            "|    iterations      | 1        |\n",
            "|    time_elapsed    | 20       |\n",
            "|    total_timesteps | 2048     |\n",
            "| train/             |          |\n",
            "|    reward          | 0.432493 |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 101         |\n",
            "|    iterations           | 2           |\n",
            "|    time_elapsed         | 40          |\n",
            "|    total_timesteps      | 4096        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.015986867 |\n",
            "|    clip_fraction        | 0.202       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.2       |\n",
            "|    explained_variance   | -0.00366    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 5.5         |\n",
            "|    n_updates            | 10          |\n",
            "|    policy_gradient_loss | -0.0213     |\n",
            "|    reward               | -0.9662296  |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 13.5        |\n",
            "-----------------------------------------\n",
            "day: 2517, episode: 10\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 2898372.16\n",
            "total_reward: 1898372.16\n",
            "total_cost: 251219.22\n",
            "total_trades: 70459\n",
            "Sharpe: 0.873\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 99          |\n",
            "|    iterations           | 3           |\n",
            "|    time_elapsed         | 61          |\n",
            "|    total_timesteps      | 6144        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.014897947 |\n",
            "|    clip_fraction        | 0.151       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.3       |\n",
            "|    explained_variance   | 0.0216      |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 6.23        |\n",
            "|    n_updates            | 20          |\n",
            "|    policy_gradient_loss | -0.0194     |\n",
            "|    reward               | 0.66694653  |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 15.4        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 99          |\n",
            "|    iterations           | 4           |\n",
            "|    time_elapsed         | 82          |\n",
            "|    total_timesteps      | 8192        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.016143057 |\n",
            "|    clip_fraction        | 0.185       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.3       |\n",
            "|    explained_variance   | 0.00296     |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 11.4        |\n",
            "|    n_updates            | 30          |\n",
            "|    policy_gradient_loss | -0.0201     |\n",
            "|    reward               | 0.4585601   |\n",
            "|    std                  | 1.01        |\n",
            "|    value_loss           | 24.6        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 100         |\n",
            "|    iterations           | 5           |\n",
            "|    time_elapsed         | 102         |\n",
            "|    total_timesteps      | 10240       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.014269302 |\n",
            "|    clip_fraction        | 0.15        |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.4       |\n",
            "|    explained_variance   | -0.00562    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 14.8        |\n",
            "|    n_updates            | 40          |\n",
            "|    policy_gradient_loss | -0.0181     |\n",
            "|    reward               | -0.10769939 |\n",
            "|    std                  | 1.01        |\n",
            "|    value_loss           | 28.4        |\n",
            "-----------------------------------------\n",
            "======ppo Validation from:  2019-01-04 to  2019-04-05\n",
            "ppo Sharpe Ratio:  0.41219294307116333\n",
            "======Best Model Retraining from:  2009-01-01 to  2019-04-05\n",
            "======Trading from:  2019-04-05 to  2019-07-08\n",
            "============================================\n",
            "turbulence_threshold:  160.3176626173842\n",
            "======Model training from:  2009-01-01 to  2019-04-05\n",
            "======a2c Training========\n",
            "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/a2c/a2c_1008_1\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 83           |\n",
            "|    iterations         | 100          |\n",
            "|    time_elapsed       | 5            |\n",
            "|    total_timesteps    | 500          |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -41.2        |\n",
            "|    explained_variance | 0.369        |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 99           |\n",
            "|    policy_loss        | 11.1         |\n",
            "|    reward             | -0.063642025 |\n",
            "|    std                | 1            |\n",
            "|    value_loss         | 0.168        |\n",
            "----------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 90         |\n",
            "|    iterations         | 200        |\n",
            "|    time_elapsed       | 11         |\n",
            "|    total_timesteps    | 1000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.2      |\n",
            "|    explained_variance | -0.0134    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 199        |\n",
            "|    policy_loss        | -35        |\n",
            "|    reward             | -1.9019911 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 2.34       |\n",
            "--------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 87       |\n",
            "|    iterations         | 300      |\n",
            "|    time_elapsed       | 17       |\n",
            "|    total_timesteps    | 1500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -41.2    |\n",
            "|    explained_variance | 5.96e-08 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 299      |\n",
            "|    policy_loss        | -279     |\n",
            "|    reward             | 3.26472  |\n",
            "|    std                | 1        |\n",
            "|    value_loss         | 51.7     |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 90        |\n",
            "|    iterations         | 400       |\n",
            "|    time_elapsed       | 22        |\n",
            "|    total_timesteps    | 2000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.2     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 399       |\n",
            "|    policy_loss        | -69.7     |\n",
            "|    reward             | 2.4794602 |\n",
            "|    std                | 1         |\n",
            "|    value_loss         | 4.07      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 89         |\n",
            "|    iterations         | 500        |\n",
            "|    time_elapsed       | 27         |\n",
            "|    total_timesteps    | 2500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.3      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 499        |\n",
            "|    policy_loss        | 399        |\n",
            "|    reward             | -10.136649 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 128        |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 91        |\n",
            "|    iterations         | 600       |\n",
            "|    time_elapsed       | 32        |\n",
            "|    total_timesteps    | 3000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.3     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 599       |\n",
            "|    policy_loss        | -86.3     |\n",
            "|    reward             | 3.9711804 |\n",
            "|    std                | 1         |\n",
            "|    value_loss         | 8.08      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 91        |\n",
            "|    iterations         | 700       |\n",
            "|    time_elapsed       | 38        |\n",
            "|    total_timesteps    | 3500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.3     |\n",
            "|    explained_variance | -0.00018  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 699       |\n",
            "|    policy_loss        | 71.3      |\n",
            "|    reward             | 2.1315396 |\n",
            "|    std                | 1         |\n",
            "|    value_loss         | 3.43      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 91         |\n",
            "|    iterations         | 800        |\n",
            "|    time_elapsed       | 43         |\n",
            "|    total_timesteps    | 4000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.2      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 799        |\n",
            "|    policy_loss        | 10.6       |\n",
            "|    reward             | -0.5014957 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 1.01       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 92        |\n",
            "|    iterations         | 900       |\n",
            "|    time_elapsed       | 48        |\n",
            "|    total_timesteps    | 4500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.3     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 899       |\n",
            "|    policy_loss        | 74.7      |\n",
            "|    reward             | 2.941646  |\n",
            "|    std                | 1         |\n",
            "|    value_loss         | 3.7       |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 91         |\n",
            "|    iterations         | 1000       |\n",
            "|    time_elapsed       | 54         |\n",
            "|    total_timesteps    | 5000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.2      |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 999        |\n",
            "|    policy_loss        | 101        |\n",
            "|    reward             | -3.3842747 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 16.7       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 91         |\n",
            "|    iterations         | 1100       |\n",
            "|    time_elapsed       | 59         |\n",
            "|    total_timesteps    | 5500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.2      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1099       |\n",
            "|    policy_loss        | -77.5      |\n",
            "|    reward             | -3.5331736 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 5.67       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 90         |\n",
            "|    iterations         | 1200       |\n",
            "|    time_elapsed       | 65         |\n",
            "|    total_timesteps    | 6000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.2      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1199       |\n",
            "|    policy_loss        | -75.6      |\n",
            "|    reward             | 0.96809196 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 4.69       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 91         |\n",
            "|    iterations         | 1300       |\n",
            "|    time_elapsed       | 71         |\n",
            "|    total_timesteps    | 6500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.3      |\n",
            "|    explained_variance | 0.101      |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1299       |\n",
            "|    policy_loss        | 127        |\n",
            "|    reward             | -1.2123779 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 15         |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 90        |\n",
            "|    iterations         | 1400      |\n",
            "|    time_elapsed       | 77        |\n",
            "|    total_timesteps    | 7000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.3     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1399      |\n",
            "|    policy_loss        | 81.8      |\n",
            "|    reward             | -5.993987 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 6.21      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 90         |\n",
            "|    iterations         | 1500       |\n",
            "|    time_elapsed       | 82         |\n",
            "|    total_timesteps    | 7500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.4      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1499       |\n",
            "|    policy_loss        | -256       |\n",
            "|    reward             | -3.1711686 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 61.8       |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 90          |\n",
            "|    iterations         | 1600        |\n",
            "|    time_elapsed       | 87          |\n",
            "|    total_timesteps    | 8000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -41.4       |\n",
            "|    explained_variance | -1.85       |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1599        |\n",
            "|    policy_loss        | -8.85       |\n",
            "|    reward             | -0.59374154 |\n",
            "|    std                | 1.01        |\n",
            "|    value_loss         | 1.61        |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 90        |\n",
            "|    iterations         | 1700      |\n",
            "|    time_elapsed       | 93        |\n",
            "|    total_timesteps    | 8500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.3     |\n",
            "|    explained_variance | -3.58e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1699      |\n",
            "|    policy_loss        | 126       |\n",
            "|    reward             | 1.2522112 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 14.5      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 90        |\n",
            "|    iterations         | 1800      |\n",
            "|    time_elapsed       | 99        |\n",
            "|    total_timesteps    | 9000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.3     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1799      |\n",
            "|    policy_loss        | 176       |\n",
            "|    reward             | 1.3192186 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 25.9      |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 90          |\n",
            "|    iterations         | 1900        |\n",
            "|    time_elapsed       | 105         |\n",
            "|    total_timesteps    | 9500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -41.3       |\n",
            "|    explained_variance | 5.96e-08    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1899        |\n",
            "|    policy_loss        | -83.8       |\n",
            "|    reward             | -0.56057835 |\n",
            "|    std                | 1.01        |\n",
            "|    value_loss         | 10.5        |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 90          |\n",
            "|    iterations         | 2000        |\n",
            "|    time_elapsed       | 110         |\n",
            "|    total_timesteps    | 10000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -41.3       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1999        |\n",
            "|    policy_loss        | 127         |\n",
            "|    reward             | -0.48415092 |\n",
            "|    std                | 1.01        |\n",
            "|    value_loss         | 15          |\n",
            "---------------------------------------\n",
            "======a2c Validation from:  2019-04-05 to  2019-07-08\n",
            "a2c Sharpe Ratio:  0.1767129380340962\n",
            "======ddpg Training========\n",
            "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/ddpg/ddpg_1008_1\n",
            "day: 2580, episode: 5\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 5791731.65\n",
            "total_reward: 4791731.65\n",
            "total_cost: 5635.97\n",
            "total_trades: 35341\n",
            "Sharpe: 1.291\n",
            "=================================\n",
            "======ddpg Validation from:  2019-04-05 to  2019-07-08\n",
            "ddpg Sharpe Ratio:  0.05453718824685062\n",
            "======ppo Training========\n",
            "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/ppo/ppo_1008_1\n",
            "------------------------------------\n",
            "| time/              |             |\n",
            "|    fps             | 99          |\n",
            "|    iterations      | 1           |\n",
            "|    time_elapsed    | 20          |\n",
            "|    total_timesteps | 2048        |\n",
            "| train/             |             |\n",
            "|    reward          | 0.011352452 |\n",
            "------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 97          |\n",
            "|    iterations           | 2           |\n",
            "|    time_elapsed         | 41          |\n",
            "|    total_timesteps      | 4096        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.013109342 |\n",
            "|    clip_fraction        | 0.19        |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.2       |\n",
            "|    explained_variance   | -0.00598    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 9.74        |\n",
            "|    n_updates            | 10          |\n",
            "|    policy_gradient_loss | -0.0275     |\n",
            "|    reward               | -2.490499   |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 14          |\n",
            "-----------------------------------------\n",
            "day: 2580, episode: 10\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 4133192.57\n",
            "total_reward: 3133192.57\n",
            "total_cost: 264953.58\n",
            "total_trades: 72353\n",
            "Sharpe: 1.046\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 98          |\n",
            "|    iterations           | 3           |\n",
            "|    time_elapsed         | 62          |\n",
            "|    total_timesteps      | 6144        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.015585029 |\n",
            "|    clip_fraction        | 0.162       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.2       |\n",
            "|    explained_variance   | -0.00982    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 9.17        |\n",
            "|    n_updates            | 20          |\n",
            "|    policy_gradient_loss | -0.019      |\n",
            "|    reward               | -1.536936   |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 18          |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 97         |\n",
            "|    iterations           | 4          |\n",
            "|    time_elapsed         | 83         |\n",
            "|    total_timesteps      | 8192       |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.01605236 |\n",
            "|    clip_fraction        | 0.158      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -41.3      |\n",
            "|    explained_variance   | -0.0337    |\n",
            "|    learning_rate        | 0.00025    |\n",
            "|    loss                 | 14.2       |\n",
            "|    n_updates            | 30         |\n",
            "|    policy_gradient_loss | -0.0202    |\n",
            "|    reward               | 0.15756984 |\n",
            "|    std                  | 1.01       |\n",
            "|    value_loss           | 33.8       |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 97          |\n",
            "|    iterations           | 5           |\n",
            "|    time_elapsed         | 105         |\n",
            "|    total_timesteps      | 10240       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.016384996 |\n",
            "|    clip_fraction        | 0.186       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.3       |\n",
            "|    explained_variance   | -0.0166     |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 16.9        |\n",
            "|    n_updates            | 40          |\n",
            "|    policy_gradient_loss | -0.0158     |\n",
            "|    reward               | -0.6220216  |\n",
            "|    std                  | 1.01        |\n",
            "|    value_loss           | 31          |\n",
            "-----------------------------------------\n",
            "======ppo Validation from:  2019-04-05 to  2019-07-08\n",
            "ppo Sharpe Ratio:  0.24766866299552326\n",
            "======Best Model Retraining from:  2009-01-01 to  2019-07-08\n",
            "======Trading from:  2019-07-08 to  2019-10-04\n",
            "============================================\n",
            "turbulence_threshold:  160.3176626173842\n",
            "======Model training from:  2009-01-01 to  2019-07-08\n",
            "======a2c Training========\n",
            "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/a2c/a2c_1071_1\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 96            |\n",
            "|    iterations         | 100           |\n",
            "|    time_elapsed       | 5             |\n",
            "|    total_timesteps    | 500           |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -41           |\n",
            "|    explained_variance | -0.424        |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 99            |\n",
            "|    policy_loss        | -87.8         |\n",
            "|    reward             | -0.0065992707 |\n",
            "|    std                | 0.995         |\n",
            "|    value_loss         | 5.15          |\n",
            "-----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 87          |\n",
            "|    iterations         | 200         |\n",
            "|    time_elapsed       | 11          |\n",
            "|    total_timesteps    | 1000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -41         |\n",
            "|    explained_variance | -0.501      |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 199         |\n",
            "|    policy_loss        | -21.2       |\n",
            "|    reward             | -0.43821818 |\n",
            "|    std                | 0.994       |\n",
            "|    value_loss         | 0.918       |\n",
            "---------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 90       |\n",
            "|    iterations         | 300      |\n",
            "|    time_elapsed       | 16       |\n",
            "|    total_timesteps    | 1500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -41      |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 299      |\n",
            "|    policy_loss        | -384     |\n",
            "|    reward             | 6.304892 |\n",
            "|    std                | 0.995    |\n",
            "|    value_loss         | 82.4     |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 88        |\n",
            "|    iterations         | 400       |\n",
            "|    time_elapsed       | 22        |\n",
            "|    total_timesteps    | 2000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -40.9     |\n",
            "|    explained_variance | 5.96e-08  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 399       |\n",
            "|    policy_loss        | 101       |\n",
            "|    reward             | -0.536227 |\n",
            "|    std                | 0.992     |\n",
            "|    value_loss         | 7.54      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 90        |\n",
            "|    iterations         | 500       |\n",
            "|    time_elapsed       | 27        |\n",
            "|    total_timesteps    | 2500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -40.9     |\n",
            "|    explained_variance | -0.00156  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 499       |\n",
            "|    policy_loss        | 448       |\n",
            "|    reward             | -9.114276 |\n",
            "|    std                | 0.991     |\n",
            "|    value_loss         | 155       |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 90          |\n",
            "|    iterations         | 600         |\n",
            "|    time_elapsed       | 33          |\n",
            "|    total_timesteps    | 3000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -40.9       |\n",
            "|    explained_variance | -0.00228    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 599         |\n",
            "|    policy_loss        | -81.8       |\n",
            "|    reward             | 0.043624554 |\n",
            "|    std                | 0.991       |\n",
            "|    value_loss         | 6.46        |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 89          |\n",
            "|    iterations         | 700         |\n",
            "|    time_elapsed       | 38          |\n",
            "|    total_timesteps    | 3500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -40.8       |\n",
            "|    explained_variance | -0.0847     |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 699         |\n",
            "|    policy_loss        | -203        |\n",
            "|    reward             | -0.34793678 |\n",
            "|    std                | 0.989       |\n",
            "|    value_loss         | 26.7        |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 90         |\n",
            "|    iterations         | 800        |\n",
            "|    time_elapsed       | 44         |\n",
            "|    total_timesteps    | 4000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -40.9      |\n",
            "|    explained_variance | -0.0209    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 799        |\n",
            "|    policy_loss        | -117       |\n",
            "|    reward             | 0.79157627 |\n",
            "|    std                | 0.991      |\n",
            "|    value_loss         | 12.6       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 88        |\n",
            "|    iterations         | 900       |\n",
            "|    time_elapsed       | 51        |\n",
            "|    total_timesteps    | 4500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41       |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 899       |\n",
            "|    policy_loss        | -135      |\n",
            "|    reward             | 0.6705628 |\n",
            "|    std                | 0.993     |\n",
            "|    value_loss         | 12.3      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 88        |\n",
            "|    iterations         | 1000      |\n",
            "|    time_elapsed       | 56        |\n",
            "|    total_timesteps    | 5000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41       |\n",
            "|    explained_variance | -2.38e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 999       |\n",
            "|    policy_loss        | -83.7     |\n",
            "|    reward             | 6.4659147 |\n",
            "|    std                | 0.995     |\n",
            "|    value_loss         | 14.5      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 88         |\n",
            "|    iterations         | 1100       |\n",
            "|    time_elapsed       | 62         |\n",
            "|    total_timesteps    | 5500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41        |\n",
            "|    explained_variance | 0.00333    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1099       |\n",
            "|    policy_loss        | -128       |\n",
            "|    reward             | 0.76695603 |\n",
            "|    std                | 0.996      |\n",
            "|    value_loss         | 10.5       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 88         |\n",
            "|    iterations         | 1200       |\n",
            "|    time_elapsed       | 67         |\n",
            "|    total_timesteps    | 6000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41        |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1199       |\n",
            "|    policy_loss        | 191        |\n",
            "|    reward             | 0.48420066 |\n",
            "|    std                | 0.994      |\n",
            "|    value_loss         | 24         |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 88         |\n",
            "|    iterations         | 1300       |\n",
            "|    time_elapsed       | 73         |\n",
            "|    total_timesteps    | 6500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -40.9      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1299       |\n",
            "|    policy_loss        | -20.7      |\n",
            "|    reward             | 0.67697734 |\n",
            "|    std                | 0.993      |\n",
            "|    value_loss         | 2.71       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 88         |\n",
            "|    iterations         | 1400       |\n",
            "|    time_elapsed       | 78         |\n",
            "|    total_timesteps    | 7000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41        |\n",
            "|    explained_variance | -0.0386    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1399       |\n",
            "|    policy_loss        | -195       |\n",
            "|    reward             | -1.2289019 |\n",
            "|    std                | 0.994      |\n",
            "|    value_loss         | 25         |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 88         |\n",
            "|    iterations         | 1500       |\n",
            "|    time_elapsed       | 84         |\n",
            "|    total_timesteps    | 7500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41        |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1499       |\n",
            "|    policy_loss        | -504       |\n",
            "|    reward             | 0.17975752 |\n",
            "|    std                | 0.994      |\n",
            "|    value_loss         | 153        |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 89          |\n",
            "|    iterations         | 1600        |\n",
            "|    time_elapsed       | 89          |\n",
            "|    total_timesteps    | 8000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -41         |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1599        |\n",
            "|    policy_loss        | 123         |\n",
            "|    reward             | 0.015282386 |\n",
            "|    std                | 0.994       |\n",
            "|    value_loss         | 10.5        |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 89         |\n",
            "|    iterations         | 1700       |\n",
            "|    time_elapsed       | 95         |\n",
            "|    total_timesteps    | 8500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41        |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1699       |\n",
            "|    policy_loss        | 93.3       |\n",
            "|    reward             | 0.18112886 |\n",
            "|    std                | 0.995      |\n",
            "|    value_loss         | 6.13       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 89        |\n",
            "|    iterations         | 1800      |\n",
            "|    time_elapsed       | 101       |\n",
            "|    total_timesteps    | 9000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.1     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1799      |\n",
            "|    policy_loss        | 229       |\n",
            "|    reward             | -2.869151 |\n",
            "|    std                | 0.997     |\n",
            "|    value_loss         | 32.8      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 89        |\n",
            "|    iterations         | 1900      |\n",
            "|    time_elapsed       | 106       |\n",
            "|    total_timesteps    | 9500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.1     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1899      |\n",
            "|    policy_loss        | 312       |\n",
            "|    reward             | 2.8630195 |\n",
            "|    std                | 0.999     |\n",
            "|    value_loss         | 72.7      |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 89          |\n",
            "|    iterations         | 2000        |\n",
            "|    time_elapsed       | 112         |\n",
            "|    total_timesteps    | 10000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -41.1       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1999        |\n",
            "|    policy_loss        | 70.7        |\n",
            "|    reward             | -0.47895753 |\n",
            "|    std                | 0.998       |\n",
            "|    value_loss         | 3.61        |\n",
            "---------------------------------------\n",
            "======a2c Validation from:  2019-07-08 to  2019-10-04\n",
            "a2c Sharpe Ratio:  -0.16172599358142117\n",
            "======ddpg Training========\n",
            "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/ddpg/ddpg_1071_1\n",
            "day: 2643, episode: 5\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 5496316.81\n",
            "total_reward: 4496316.81\n",
            "total_cost: 5415.32\n",
            "total_trades: 33494\n",
            "Sharpe: 1.204\n",
            "=================================\n",
            "======ddpg Validation from:  2019-07-08 to  2019-10-04\n",
            "ddpg Sharpe Ratio:  -0.14531551202223436\n",
            "======ppo Training========\n",
            "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/ppo/ppo_1071_1\n",
            "-----------------------------------\n",
            "| time/              |            |\n",
            "|    fps             | 102        |\n",
            "|    iterations      | 1          |\n",
            "|    time_elapsed    | 19         |\n",
            "|    total_timesteps | 2048       |\n",
            "| train/             |            |\n",
            "|    reward          | 0.07018637 |\n",
            "-----------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 100         |\n",
            "|    iterations           | 2           |\n",
            "|    time_elapsed         | 40          |\n",
            "|    total_timesteps      | 4096        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.018400695 |\n",
            "|    clip_fraction        | 0.221       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.2       |\n",
            "|    explained_variance   | -0.0119     |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 5.39        |\n",
            "|    n_updates            | 10          |\n",
            "|    policy_gradient_loss | -0.0255     |\n",
            "|    reward               | -3.3739667  |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 13.2        |\n",
            "-----------------------------------------\n",
            "day: 2643, episode: 10\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 3175179.70\n",
            "total_reward: 2175179.70\n",
            "total_cost: 272209.31\n",
            "total_trades: 73484\n",
            "Sharpe: 0.849\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 98          |\n",
            "|    iterations           | 3           |\n",
            "|    time_elapsed         | 62          |\n",
            "|    total_timesteps      | 6144        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.014583677 |\n",
            "|    clip_fraction        | 0.181       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.2       |\n",
            "|    explained_variance   | -0.0115     |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 7.2         |\n",
            "|    n_updates            | 20          |\n",
            "|    policy_gradient_loss | -0.0209     |\n",
            "|    reward               | -0.8902863  |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 20.2        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 97          |\n",
            "|    iterations           | 4           |\n",
            "|    time_elapsed         | 84          |\n",
            "|    total_timesteps      | 8192        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.018620746 |\n",
            "|    clip_fraction        | 0.23        |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.3       |\n",
            "|    explained_variance   | -0.00139    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 14.4        |\n",
            "|    n_updates            | 30          |\n",
            "|    policy_gradient_loss | -0.0164     |\n",
            "|    reward               | 0.21948998  |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 21.5        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 97          |\n",
            "|    iterations           | 5           |\n",
            "|    time_elapsed         | 104         |\n",
            "|    total_timesteps      | 10240       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.017223533 |\n",
            "|    clip_fraction        | 0.193       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.3       |\n",
            "|    explained_variance   | -0.0227     |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 10.6        |\n",
            "|    n_updates            | 40          |\n",
            "|    policy_gradient_loss | -0.0158     |\n",
            "|    reward               | -2.5106993  |\n",
            "|    std                  | 1.01        |\n",
            "|    value_loss           | 18.6        |\n",
            "-----------------------------------------\n",
            "======ppo Validation from:  2019-07-08 to  2019-10-04\n",
            "ppo Sharpe Ratio:  -0.25739156241924116\n",
            "======Best Model Retraining from:  2009-01-01 to  2019-10-04\n",
            "======Trading from:  2019-10-04 to  2020-01-06\n",
            "============================================\n",
            "turbulence_threshold:  160.3176626173842\n",
            "======Model training from:  2009-01-01 to  2019-10-04\n",
            "======a2c Training========\n",
            "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/a2c/a2c_1134_1\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 84          |\n",
            "|    iterations         | 100         |\n",
            "|    time_elapsed       | 5           |\n",
            "|    total_timesteps    | 500         |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -41.2       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 99          |\n",
            "|    policy_loss        | -69.5       |\n",
            "|    reward             | -0.06315515 |\n",
            "|    std                | 1           |\n",
            "|    value_loss         | 3.86        |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 89        |\n",
            "|    iterations         | 200       |\n",
            "|    time_elapsed       | 11        |\n",
            "|    total_timesteps    | 1000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.2     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 199       |\n",
            "|    policy_loss        | -51       |\n",
            "|    reward             | -2.790684 |\n",
            "|    std                | 1         |\n",
            "|    value_loss         | 2.18      |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 85       |\n",
            "|    iterations         | 300      |\n",
            "|    time_elapsed       | 17       |\n",
            "|    total_timesteps    | 1500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -41.1    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 299      |\n",
            "|    policy_loss        | -192     |\n",
            "|    reward             | 6.510055 |\n",
            "|    std                | 1        |\n",
            "|    value_loss         | 21.5     |\n",
            "------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 87          |\n",
            "|    iterations         | 400         |\n",
            "|    time_elapsed       | 22          |\n",
            "|    total_timesteps    | 2000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -41.1       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 399         |\n",
            "|    policy_loss        | -11.8       |\n",
            "|    reward             | -0.17389981 |\n",
            "|    std                | 0.998       |\n",
            "|    value_loss         | 19.6        |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 85         |\n",
            "|    iterations         | 500        |\n",
            "|    time_elapsed       | 29         |\n",
            "|    total_timesteps    | 2500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41        |\n",
            "|    explained_variance | 1.79e-07   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 499        |\n",
            "|    policy_loss        | 1.64e+03   |\n",
            "|    reward             | -25.177023 |\n",
            "|    std                | 0.996      |\n",
            "|    value_loss         | 1.85e+03   |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 86          |\n",
            "|    iterations         | 600         |\n",
            "|    time_elapsed       | 34          |\n",
            "|    total_timesteps    | 3000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -41.1       |\n",
            "|    explained_variance | -1.79e-06   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 599         |\n",
            "|    policy_loss        | 37.5        |\n",
            "|    reward             | -0.78725964 |\n",
            "|    std                | 0.999       |\n",
            "|    value_loss         | 1.3         |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 85          |\n",
            "|    iterations         | 700         |\n",
            "|    time_elapsed       | 40          |\n",
            "|    total_timesteps    | 3500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -41.1       |\n",
            "|    explained_variance | -1.19e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 699         |\n",
            "|    policy_loss        | 104         |\n",
            "|    reward             | -0.56047213 |\n",
            "|    std                | 0.999       |\n",
            "|    value_loss         | 8.41        |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 86        |\n",
            "|    iterations         | 800       |\n",
            "|    time_elapsed       | 46        |\n",
            "|    total_timesteps    | 4000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.1     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 799       |\n",
            "|    policy_loss        | 291       |\n",
            "|    reward             | 1.1448723 |\n",
            "|    std                | 0.999     |\n",
            "|    value_loss         | 88.1      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 85         |\n",
            "|    iterations         | 900        |\n",
            "|    time_elapsed       | 52         |\n",
            "|    total_timesteps    | 4500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.1      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 899        |\n",
            "|    policy_loss        | -28.2      |\n",
            "|    reward             | -5.7139063 |\n",
            "|    std                | 0.998      |\n",
            "|    value_loss         | 67.6       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 86        |\n",
            "|    iterations         | 1000      |\n",
            "|    time_elapsed       | 57        |\n",
            "|    total_timesteps    | 5000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41       |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 999       |\n",
            "|    policy_loss        | -1.61e+03 |\n",
            "|    reward             | 4.012488  |\n",
            "|    std                | 0.996     |\n",
            "|    value_loss         | 1.74e+03  |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 85         |\n",
            "|    iterations         | 1100       |\n",
            "|    time_elapsed       | 64         |\n",
            "|    total_timesteps    | 5500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41        |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1099       |\n",
            "|    policy_loss        | 102        |\n",
            "|    reward             | -1.3514637 |\n",
            "|    std                | 0.995      |\n",
            "|    value_loss         | 6.66       |\n",
            "--------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 86           |\n",
            "|    iterations         | 1200         |\n",
            "|    time_elapsed       | 69           |\n",
            "|    total_timesteps    | 6000         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -41          |\n",
            "|    explained_variance | 0.0329       |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 1199         |\n",
            "|    policy_loss        | 174          |\n",
            "|    reward             | -0.087657355 |\n",
            "|    std                | 0.995        |\n",
            "|    value_loss         | 24.9         |\n",
            "----------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 86        |\n",
            "|    iterations         | 1300      |\n",
            "|    time_elapsed       | 75        |\n",
            "|    total_timesteps    | 6500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41       |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1299      |\n",
            "|    policy_loss        | 33.1      |\n",
            "|    reward             | 1.0302341 |\n",
            "|    std                | 0.995     |\n",
            "|    value_loss         | 3.72      |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 86          |\n",
            "|    iterations         | 1400        |\n",
            "|    time_elapsed       | 80          |\n",
            "|    total_timesteps    | 7000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -41         |\n",
            "|    explained_variance | 1.19e-07    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1399        |\n",
            "|    policy_loss        | -7.92       |\n",
            "|    reward             | -0.16049135 |\n",
            "|    std                | 0.997       |\n",
            "|    value_loss         | 2.44        |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 87        |\n",
            "|    iterations         | 1500      |\n",
            "|    time_elapsed       | 85        |\n",
            "|    total_timesteps    | 7500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.1     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1499      |\n",
            "|    policy_loss        | 66        |\n",
            "|    reward             | 1.5032254 |\n",
            "|    std                | 0.997     |\n",
            "|    value_loss         | 4.98      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 86         |\n",
            "|    iterations         | 1600       |\n",
            "|    time_elapsed       | 92         |\n",
            "|    total_timesteps    | 8000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.1      |\n",
            "|    explained_variance | 1.19e-07   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1599       |\n",
            "|    policy_loss        | -172       |\n",
            "|    reward             | -20.312046 |\n",
            "|    std                | 0.998      |\n",
            "|    value_loss         | 151        |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 87        |\n",
            "|    iterations         | 1700      |\n",
            "|    time_elapsed       | 97        |\n",
            "|    total_timesteps    | 8500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.1     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1699      |\n",
            "|    policy_loss        | -234      |\n",
            "|    reward             | 3.1928804 |\n",
            "|    std                | 1         |\n",
            "|    value_loss         | 39        |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 86         |\n",
            "|    iterations         | 1800       |\n",
            "|    time_elapsed       | 103        |\n",
            "|    total_timesteps    | 9000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.1      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1799       |\n",
            "|    policy_loss        | -261       |\n",
            "|    reward             | -0.7428414 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 44.4       |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 87          |\n",
            "|    iterations         | 1900        |\n",
            "|    time_elapsed       | 108         |\n",
            "|    total_timesteps    | 9500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -41.1       |\n",
            "|    explained_variance | 1.19e-07    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1899        |\n",
            "|    policy_loss        | 247         |\n",
            "|    reward             | -0.03689122 |\n",
            "|    std                | 0.999       |\n",
            "|    value_loss         | 52.4        |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 86         |\n",
            "|    iterations         | 2000       |\n",
            "|    time_elapsed       | 115        |\n",
            "|    total_timesteps    | 10000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.1      |\n",
            "|    explained_variance | 1.19e-07   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1999       |\n",
            "|    policy_loss        | 304        |\n",
            "|    reward             | 0.56284565 |\n",
            "|    std                | 0.999      |\n",
            "|    value_loss         | 87.4       |\n",
            "--------------------------------------\n",
            "======a2c Validation from:  2019-10-04 to  2020-01-06\n",
            "a2c Sharpe Ratio:  0.5710451230938851\n",
            "======ddpg Training========\n",
            "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/ddpg/ddpg_1134_1\n",
            "day: 2706, episode: 5\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 4784972.26\n",
            "total_reward: 3784972.26\n",
            "total_cost: 4729.19\n",
            "total_trades: 42045\n",
            "Sharpe: 0.967\n",
            "=================================\n",
            "======ddpg Validation from:  2019-10-04 to  2020-01-06\n",
            "ddpg Sharpe Ratio:  0.5781487342901017\n",
            "======ppo Training========\n",
            "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/ppo/ppo_1134_1\n",
            "-----------------------------------\n",
            "| time/              |            |\n",
            "|    fps             | 95         |\n",
            "|    iterations      | 1          |\n",
            "|    time_elapsed    | 21         |\n",
            "|    total_timesteps | 2048       |\n",
            "| train/             |            |\n",
            "|    reward          | 0.36653495 |\n",
            "-----------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 94          |\n",
            "|    iterations           | 2           |\n",
            "|    time_elapsed         | 43          |\n",
            "|    total_timesteps      | 4096        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.014444078 |\n",
            "|    clip_fraction        | 0.213       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.2       |\n",
            "|    explained_variance   | 0.0118      |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 6.25        |\n",
            "|    n_updates            | 10          |\n",
            "|    policy_gradient_loss | -0.0233     |\n",
            "|    reward               | 0.1857459   |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 14.6        |\n",
            "-----------------------------------------\n",
            "day: 2706, episode: 10\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 4129796.33\n",
            "total_reward: 3129796.33\n",
            "total_cost: 285514.17\n",
            "total_trades: 75739\n",
            "Sharpe: 1.009\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 95          |\n",
            "|    iterations           | 3           |\n",
            "|    time_elapsed         | 64          |\n",
            "|    total_timesteps      | 6144        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.015207964 |\n",
            "|    clip_fraction        | 0.175       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.2       |\n",
            "|    explained_variance   | -0.0177     |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 13          |\n",
            "|    n_updates            | 20          |\n",
            "|    policy_gradient_loss | -0.0171     |\n",
            "|    reward               | -2.1160152  |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 24.1        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 94          |\n",
            "|    iterations           | 4           |\n",
            "|    time_elapsed         | 86          |\n",
            "|    total_timesteps      | 8192        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.016016481 |\n",
            "|    clip_fraction        | 0.174       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.3       |\n",
            "|    explained_variance   | -0.0145     |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 12.5        |\n",
            "|    n_updates            | 30          |\n",
            "|    policy_gradient_loss | -0.0186     |\n",
            "|    reward               | 0.16716382  |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 26.3        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 94          |\n",
            "|    iterations           | 5           |\n",
            "|    time_elapsed         | 108         |\n",
            "|    total_timesteps      | 10240       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.02346795  |\n",
            "|    clip_fraction        | 0.196       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.3       |\n",
            "|    explained_variance   | -0.00315    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 11.7        |\n",
            "|    n_updates            | 40          |\n",
            "|    policy_gradient_loss | -0.0183     |\n",
            "|    reward               | -0.17980893 |\n",
            "|    std                  | 1.01        |\n",
            "|    value_loss           | 26.5        |\n",
            "-----------------------------------------\n",
            "======ppo Validation from:  2019-10-04 to  2020-01-06\n",
            "ppo Sharpe Ratio:  0.2631799655958448\n",
            "======Best Model Retraining from:  2009-01-01 to  2020-01-06\n",
            "======Trading from:  2020-01-06 to  2020-04-06\n",
            "============================================\n",
            "turbulence_threshold:  160.3176626173842\n",
            "======Model training from:  2009-01-01 to  2020-01-06\n",
            "======a2c Training========\n",
            "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/a2c/a2c_1197_1\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 84          |\n",
            "|    iterations         | 100         |\n",
            "|    time_elapsed       | 5           |\n",
            "|    total_timesteps    | 500         |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -41.3       |\n",
            "|    explained_variance | -0.324      |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 99          |\n",
            "|    policy_loss        | -89.7       |\n",
            "|    reward             | -0.38563344 |\n",
            "|    std                | 1           |\n",
            "|    value_loss         | 6.54        |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 86          |\n",
            "|    iterations         | 200         |\n",
            "|    time_elapsed       | 11          |\n",
            "|    total_timesteps    | 1000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -41.2       |\n",
            "|    explained_variance | 0.0838      |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 199         |\n",
            "|    policy_loss        | -56.9       |\n",
            "|    reward             | -0.52024907 |\n",
            "|    std                | 1           |\n",
            "|    value_loss         | 2.78        |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 89        |\n",
            "|    iterations         | 300       |\n",
            "|    time_elapsed       | 16        |\n",
            "|    total_timesteps    | 1500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.2     |\n",
            "|    explained_variance | -0.0548   |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 299       |\n",
            "|    policy_loss        | -406      |\n",
            "|    reward             | 5.8746576 |\n",
            "|    std                | 1         |\n",
            "|    value_loss         | 90.1      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 86        |\n",
            "|    iterations         | 400       |\n",
            "|    time_elapsed       | 23        |\n",
            "|    total_timesteps    | 2000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.2     |\n",
            "|    explained_variance | -0.0849   |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 399       |\n",
            "|    policy_loss        | -8.83     |\n",
            "|    reward             | 1.8511982 |\n",
            "|    std                | 1         |\n",
            "|    value_loss         | 11.1      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 88         |\n",
            "|    iterations         | 500        |\n",
            "|    time_elapsed       | 28         |\n",
            "|    total_timesteps    | 2500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.2      |\n",
            "|    explained_variance | 0.0152     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 499        |\n",
            "|    policy_loss        | 852        |\n",
            "|    reward             | -20.804071 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 594        |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 86        |\n",
            "|    iterations         | 600       |\n",
            "|    time_elapsed       | 34        |\n",
            "|    total_timesteps    | 3000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.1     |\n",
            "|    explained_variance | -0.167    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 599       |\n",
            "|    policy_loss        | -2.06     |\n",
            "|    reward             | 1.5243695 |\n",
            "|    std                | 1         |\n",
            "|    value_loss         | 2.02      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 87        |\n",
            "|    iterations         | 700       |\n",
            "|    time_elapsed       | 39        |\n",
            "|    total_timesteps    | 3500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.1     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 699       |\n",
            "|    policy_loss        | -121      |\n",
            "|    reward             | -2.619283 |\n",
            "|    std                | 0.999     |\n",
            "|    value_loss         | 13.6      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 86         |\n",
            "|    iterations         | 800        |\n",
            "|    time_elapsed       | 46         |\n",
            "|    total_timesteps    | 4000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.1      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 799        |\n",
            "|    policy_loss        | 182        |\n",
            "|    reward             | -1.2630095 |\n",
            "|    std                | 0.999      |\n",
            "|    value_loss         | 18         |\n",
            "--------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 87       |\n",
            "|    iterations         | 900      |\n",
            "|    time_elapsed       | 51       |\n",
            "|    total_timesteps    | 4500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -41.1    |\n",
            "|    explained_variance | 1.19e-07 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 899      |\n",
            "|    policy_loss        | -182     |\n",
            "|    reward             | 4.576115 |\n",
            "|    std                | 0.999    |\n",
            "|    value_loss         | 23.4     |\n",
            "------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 86         |\n",
            "|    iterations         | 1000       |\n",
            "|    time_elapsed       | 57         |\n",
            "|    total_timesteps    | 5000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.1      |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 999        |\n",
            "|    policy_loss        | -390       |\n",
            "|    reward             | -1.6921973 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 108        |\n",
            "--------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 87       |\n",
            "|    iterations         | 1100     |\n",
            "|    time_elapsed       | 62       |\n",
            "|    total_timesteps    | 5500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -41.2    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1099     |\n",
            "|    policy_loss        | 126      |\n",
            "|    reward             | 4.32489  |\n",
            "|    std                | 1        |\n",
            "|    value_loss         | 26       |\n",
            "------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 86          |\n",
            "|    iterations         | 1200        |\n",
            "|    time_elapsed       | 68          |\n",
            "|    total_timesteps    | 6000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -41.2       |\n",
            "|    explained_variance | -0.365      |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1199        |\n",
            "|    policy_loss        | 11.7        |\n",
            "|    reward             | 0.027840678 |\n",
            "|    std                | 1           |\n",
            "|    value_loss         | 1.81        |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 87        |\n",
            "|    iterations         | 1300      |\n",
            "|    time_elapsed       | 74        |\n",
            "|    total_timesteps    | 6500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.2     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1299      |\n",
            "|    policy_loss        | 153       |\n",
            "|    reward             | -2.245825 |\n",
            "|    std                | 1         |\n",
            "|    value_loss         | 16.3      |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 87       |\n",
            "|    iterations         | 1400     |\n",
            "|    time_elapsed       | 79       |\n",
            "|    total_timesteps    | 7000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -41.2    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1399     |\n",
            "|    policy_loss        | -389     |\n",
            "|    reward             | 8.757435 |\n",
            "|    std                | 1        |\n",
            "|    value_loss         | 115      |\n",
            "------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 87         |\n",
            "|    iterations         | 1500       |\n",
            "|    time_elapsed       | 85         |\n",
            "|    total_timesteps    | 7500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.2      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1499       |\n",
            "|    policy_loss        | -270       |\n",
            "|    reward             | 0.56117433 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 40.8       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 88         |\n",
            "|    iterations         | 1600       |\n",
            "|    time_elapsed       | 90         |\n",
            "|    total_timesteps    | 8000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.2      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1599       |\n",
            "|    policy_loss        | -477       |\n",
            "|    reward             | -15.266391 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 124        |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 87        |\n",
            "|    iterations         | 1700      |\n",
            "|    time_elapsed       | 97        |\n",
            "|    total_timesteps    | 8500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.2     |\n",
            "|    explained_variance | -0.799    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1699      |\n",
            "|    policy_loss        | -68.1     |\n",
            "|    reward             | 2.0901244 |\n",
            "|    std                | 1         |\n",
            "|    value_loss         | 7.55      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 87         |\n",
            "|    iterations         | 1800       |\n",
            "|    time_elapsed       | 102        |\n",
            "|    total_timesteps    | 9000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.2      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1799       |\n",
            "|    policy_loss        | -201       |\n",
            "|    reward             | -2.4214444 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 28.5       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 87         |\n",
            "|    iterations         | 1900       |\n",
            "|    time_elapsed       | 108        |\n",
            "|    total_timesteps    | 9500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.2      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1899       |\n",
            "|    policy_loss        | 246        |\n",
            "|    reward             | -1.4602026 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 38.7       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 87        |\n",
            "|    iterations         | 2000      |\n",
            "|    time_elapsed       | 113       |\n",
            "|    total_timesteps    | 10000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.2     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1999      |\n",
            "|    policy_loss        | -13.4     |\n",
            "|    reward             | 1.7157927 |\n",
            "|    std                | 1         |\n",
            "|    value_loss         | 11.2      |\n",
            "-------------------------------------\n",
            "======a2c Validation from:  2020-01-06 to  2020-04-06\n",
            "a2c Sharpe Ratio:  -0.4306511189667662\n",
            "======ddpg Training========\n",
            "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/ddpg/ddpg_1197_1\n",
            "day: 2769, episode: 5\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 8149959.55\n",
            "total_reward: 7149959.55\n",
            "total_cost: 8014.55\n",
            "total_trades: 34022\n",
            "Sharpe: 1.352\n",
            "=================================\n",
            "======ddpg Validation from:  2020-01-06 to  2020-04-06\n",
            "ddpg Sharpe Ratio:  -0.22137395389561967\n",
            "======ppo Training========\n",
            "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/ppo/ppo_1197_1\n",
            "-----------------------------------\n",
            "| time/              |            |\n",
            "|    fps             | 99         |\n",
            "|    iterations      | 1          |\n",
            "|    time_elapsed    | 20         |\n",
            "|    total_timesteps | 2048       |\n",
            "| train/             |            |\n",
            "|    reward          | 0.22062446 |\n",
            "-----------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 95          |\n",
            "|    iterations           | 2           |\n",
            "|    time_elapsed         | 42          |\n",
            "|    total_timesteps      | 4096        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.013653791 |\n",
            "|    clip_fraction        | 0.204       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.2       |\n",
            "|    explained_variance   | -0.00414    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 5.18        |\n",
            "|    n_updates            | 10          |\n",
            "|    policy_gradient_loss | -0.0243     |\n",
            "|    reward               | -3.2408316  |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 12.1        |\n",
            "-----------------------------------------\n",
            "day: 2769, episode: 10\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 3578215.70\n",
            "total_reward: 2578215.70\n",
            "total_cost: 298020.01\n",
            "total_trades: 77411\n",
            "Sharpe: 0.906\n",
            "=================================\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 94         |\n",
            "|    iterations           | 3          |\n",
            "|    time_elapsed         | 65         |\n",
            "|    total_timesteps      | 6144       |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.01940825 |\n",
            "|    clip_fraction        | 0.194      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -41.2      |\n",
            "|    explained_variance   | -0.0127    |\n",
            "|    learning_rate        | 0.00025    |\n",
            "|    loss                 | 7.68       |\n",
            "|    n_updates            | 20         |\n",
            "|    policy_gradient_loss | -0.0189    |\n",
            "|    reward               | 0.24953574 |\n",
            "|    std                  | 1          |\n",
            "|    value_loss           | 16.2       |\n",
            "----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 93           |\n",
            "|    iterations           | 4            |\n",
            "|    time_elapsed         | 87           |\n",
            "|    total_timesteps      | 8192         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0144746695 |\n",
            "|    clip_fraction        | 0.196        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -41.3        |\n",
            "|    explained_variance   | -0.0167      |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 9.29         |\n",
            "|    n_updates            | 30           |\n",
            "|    policy_gradient_loss | -0.016       |\n",
            "|    reward               | -1.556273    |\n",
            "|    std                  | 1.01         |\n",
            "|    value_loss           | 19.5         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 93          |\n",
            "|    iterations           | 5           |\n",
            "|    time_elapsed         | 109         |\n",
            "|    total_timesteps      | 10240       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.025219878 |\n",
            "|    clip_fraction        | 0.198       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.3       |\n",
            "|    explained_variance   | -0.0235     |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 20.4        |\n",
            "|    n_updates            | 40          |\n",
            "|    policy_gradient_loss | -0.018      |\n",
            "|    reward               | -0.86849606 |\n",
            "|    std                  | 1.01        |\n",
            "|    value_loss           | 38.1        |\n",
            "-----------------------------------------\n",
            "======ppo Validation from:  2020-01-06 to  2020-04-06\n",
            "ppo Sharpe Ratio:  -0.29251733829789145\n",
            "======Best Model Retraining from:  2009-01-01 to  2020-04-06\n",
            "======Trading from:  2020-04-06 to  2020-07-07\n",
            "============================================\n",
            "turbulence_threshold:  160.3176626173842\n",
            "======Model training from:  2009-01-01 to  2020-04-06\n",
            "======a2c Training========\n",
            "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/a2c/a2c_1260_1\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 93          |\n",
            "|    iterations         | 100         |\n",
            "|    time_elapsed       | 5           |\n",
            "|    total_timesteps    | 500         |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -41.1       |\n",
            "|    explained_variance | -0.448      |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 99          |\n",
            "|    policy_loss        | -19.7       |\n",
            "|    reward             | 0.054785106 |\n",
            "|    std                | 0.997       |\n",
            "|    value_loss         | 0.433       |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 85         |\n",
            "|    iterations         | 200        |\n",
            "|    time_elapsed       | 11         |\n",
            "|    total_timesteps    | 1000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.1      |\n",
            "|    explained_variance | -0.199     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 199        |\n",
            "|    policy_loss        | -18.2      |\n",
            "|    reward             | -1.0856526 |\n",
            "|    std                | 0.998      |\n",
            "|    value_loss         | 0.584      |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 88        |\n",
            "|    iterations         | 300       |\n",
            "|    time_elapsed       | 17        |\n",
            "|    total_timesteps    | 1500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41       |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 299       |\n",
            "|    policy_loss        | -412      |\n",
            "|    reward             | 6.399504  |\n",
            "|    std                | 0.997     |\n",
            "|    value_loss         | 121       |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 85        |\n",
            "|    iterations         | 400       |\n",
            "|    time_elapsed       | 23        |\n",
            "|    total_timesteps    | 2000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.1     |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 399       |\n",
            "|    policy_loss        | -29.6     |\n",
            "|    reward             | 1.2590371 |\n",
            "|    std                | 0.998     |\n",
            "|    value_loss         | 9.35      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 87        |\n",
            "|    iterations         | 500       |\n",
            "|    time_elapsed       | 28        |\n",
            "|    total_timesteps    | 2500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.1     |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 499       |\n",
            "|    policy_loss        | 570       |\n",
            "|    reward             | -6.880279 |\n",
            "|    std                | 0.997     |\n",
            "|    value_loss         | 210       |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 87        |\n",
            "|    iterations         | 600       |\n",
            "|    time_elapsed       | 34        |\n",
            "|    total_timesteps    | 3000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.1     |\n",
            "|    explained_variance | -0.0134   |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 599       |\n",
            "|    policy_loss        | 69.4      |\n",
            "|    reward             | -2.447334 |\n",
            "|    std                | 0.997     |\n",
            "|    value_loss         | 4.17      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 86         |\n",
            "|    iterations         | 700        |\n",
            "|    time_elapsed       | 40         |\n",
            "|    total_timesteps    | 3500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41        |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 699        |\n",
            "|    policy_loss        | -150       |\n",
            "|    reward             | -2.9572947 |\n",
            "|    std                | 0.996      |\n",
            "|    value_loss         | 11.1       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 87        |\n",
            "|    iterations         | 800       |\n",
            "|    time_elapsed       | 45        |\n",
            "|    total_timesteps    | 4000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41       |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 799       |\n",
            "|    policy_loss        | -214      |\n",
            "|    reward             | 1.0030384 |\n",
            "|    std                | 0.996     |\n",
            "|    value_loss         | 27.8      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 86        |\n",
            "|    iterations         | 900       |\n",
            "|    time_elapsed       | 51        |\n",
            "|    total_timesteps    | 4500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.1     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 899       |\n",
            "|    policy_loss        | -60.5     |\n",
            "|    reward             | 1.9714733 |\n",
            "|    std                | 0.997     |\n",
            "|    value_loss         | 5.63      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 87        |\n",
            "|    iterations         | 1000      |\n",
            "|    time_elapsed       | 57        |\n",
            "|    total_timesteps    | 5000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.1     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 999       |\n",
            "|    policy_loss        | 120       |\n",
            "|    reward             | 1.0256356 |\n",
            "|    std                | 1         |\n",
            "|    value_loss         | 14.9      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 86        |\n",
            "|    iterations         | 1100      |\n",
            "|    time_elapsed       | 63        |\n",
            "|    total_timesteps    | 5500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.1     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1099      |\n",
            "|    policy_loss        | -494      |\n",
            "|    reward             | 5.7184734 |\n",
            "|    std                | 0.998     |\n",
            "|    value_loss         | 189       |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 87       |\n",
            "|    iterations         | 1200     |\n",
            "|    time_elapsed       | 68       |\n",
            "|    total_timesteps    | 6000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -41.1    |\n",
            "|    explained_variance | 0.204    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1199     |\n",
            "|    policy_loss        | -95.6    |\n",
            "|    reward             | 2.487049 |\n",
            "|    std                | 0.999    |\n",
            "|    value_loss         | 5.41     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 86       |\n",
            "|    iterations         | 1300     |\n",
            "|    time_elapsed       | 74       |\n",
            "|    total_timesteps    | 6500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -41.2    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1299     |\n",
            "|    policy_loss        | -44.5    |\n",
            "|    reward             | 3.047842 |\n",
            "|    std                | 1        |\n",
            "|    value_loss         | 2.92     |\n",
            "------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 87         |\n",
            "|    iterations         | 1400       |\n",
            "|    time_elapsed       | 80         |\n",
            "|    total_timesteps    | 7000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.2      |\n",
            "|    explained_variance | -0.0576    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1399       |\n",
            "|    policy_loss        | -65.1      |\n",
            "|    reward             | -1.6374202 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 14.1       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 85         |\n",
            "|    iterations         | 1500       |\n",
            "|    time_elapsed       | 87         |\n",
            "|    total_timesteps    | 7500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.2      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1499       |\n",
            "|    policy_loss        | -259       |\n",
            "|    reward             | 0.20167693 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 54.4       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 86        |\n",
            "|    iterations         | 1600      |\n",
            "|    time_elapsed       | 92        |\n",
            "|    total_timesteps    | 8000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.2     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1599      |\n",
            "|    policy_loss        | 913       |\n",
            "|    reward             | 8.630207  |\n",
            "|    std                | 1         |\n",
            "|    value_loss         | 587       |\n",
            "-------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 85           |\n",
            "|    iterations         | 1700         |\n",
            "|    time_elapsed       | 99           |\n",
            "|    total_timesteps    | 8500         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -41.1        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 1699         |\n",
            "|    policy_loss        | 880          |\n",
            "|    reward             | 0.0026689055 |\n",
            "|    std                | 0.998        |\n",
            "|    value_loss         | 1.68e+03     |\n",
            "----------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 86         |\n",
            "|    iterations         | 1800       |\n",
            "|    time_elapsed       | 104        |\n",
            "|    total_timesteps    | 9000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.1      |\n",
            "|    explained_variance | 5.96e-08   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1799       |\n",
            "|    policy_loss        | 42.5       |\n",
            "|    reward             | -0.5588068 |\n",
            "|    std                | 0.999      |\n",
            "|    value_loss         | 2.11       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 85         |\n",
            "|    iterations         | 1900       |\n",
            "|    time_elapsed       | 110        |\n",
            "|    total_timesteps    | 9500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -41.1      |\n",
            "|    explained_variance | 5.96e-08   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1899       |\n",
            "|    policy_loss        | 24.8       |\n",
            "|    reward             | -0.6963837 |\n",
            "|    std                | 0.998      |\n",
            "|    value_loss         | 2.22       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 85        |\n",
            "|    iterations         | 2000      |\n",
            "|    time_elapsed       | 116       |\n",
            "|    total_timesteps    | 10000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -41.1     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1999      |\n",
            "|    policy_loss        | -141      |\n",
            "|    reward             | 10.539924 |\n",
            "|    std                | 0.998     |\n",
            "|    value_loss         | 15.4      |\n",
            "-------------------------------------\n",
            "======a2c Validation from:  2020-04-06 to  2020-07-07\n",
            "a2c Sharpe Ratio:  0.21883931041955312\n",
            "======ddpg Training========\n",
            "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/ddpg/ddpg_1260_1\n",
            "day: 2832, episode: 5\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 3337534.33\n",
            "total_reward: 2337534.33\n",
            "total_cost: 4423.28\n",
            "total_trades: 46547\n",
            "Sharpe: 0.755\n",
            "=================================\n",
            "======ddpg Validation from:  2020-04-06 to  2020-07-07\n",
            "ddpg Sharpe Ratio:  0.28535493735136525\n",
            "======ppo Training========\n",
            "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/ppo/ppo_1260_1\n",
            "------------------------------------\n",
            "| time/              |             |\n",
            "|    fps             | 92          |\n",
            "|    iterations      | 1           |\n",
            "|    time_elapsed    | 22          |\n",
            "|    total_timesteps | 2048        |\n",
            "| train/             |             |\n",
            "|    reward          | -0.30295503 |\n",
            "------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 93          |\n",
            "|    iterations           | 2           |\n",
            "|    time_elapsed         | 43          |\n",
            "|    total_timesteps      | 4096        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.014630916 |\n",
            "|    clip_fraction        | 0.2         |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.2       |\n",
            "|    explained_variance   | -0.0479     |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 5.91        |\n",
            "|    n_updates            | 10          |\n",
            "|    policy_gradient_loss | -0.0258     |\n",
            "|    reward               | -0.18834597 |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 13.6        |\n",
            "-----------------------------------------\n",
            "day: 2832, episode: 10\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 2905281.04\n",
            "total_reward: 1905281.04\n",
            "total_cost: 316958.37\n",
            "total_trades: 79245\n",
            "Sharpe: 0.672\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 93          |\n",
            "|    iterations           | 3           |\n",
            "|    time_elapsed         | 66          |\n",
            "|    total_timesteps      | 6144        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.014750276 |\n",
            "|    clip_fraction        | 0.173       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.3       |\n",
            "|    explained_variance   | 0.000512    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 15          |\n",
            "|    n_updates            | 20          |\n",
            "|    policy_gradient_loss | -0.0154     |\n",
            "|    reward               | 1.6639621   |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 59.6        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 92          |\n",
            "|    iterations           | 4           |\n",
            "|    time_elapsed         | 88          |\n",
            "|    total_timesteps      | 8192        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.014312775 |\n",
            "|    clip_fraction        | 0.145       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -41.3       |\n",
            "|    explained_variance   | -0.00439    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 63.9        |\n",
            "|    n_updates            | 30          |\n",
            "|    policy_gradient_loss | -0.0216     |\n",
            "|    reward               | 1.0964844   |\n",
            "|    std                  | 1.01        |\n",
            "|    value_loss           | 71.9        |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 91         |\n",
            "|    iterations           | 5          |\n",
            "|    time_elapsed         | 111        |\n",
            "|    total_timesteps      | 10240      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.01817922 |\n",
            "|    clip_fraction        | 0.2        |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -41.3      |\n",
            "|    explained_variance   | -0.0165    |\n",
            "|    learning_rate        | 0.00025    |\n",
            "|    loss                 | 12.6       |\n",
            "|    n_updates            | 40         |\n",
            "|    policy_gradient_loss | -0.0247    |\n",
            "|    reward               | -1.7697155 |\n",
            "|    std                  | 1.01       |\n",
            "|    value_loss           | 27.9       |\n",
            "----------------------------------------\n",
            "======ppo Validation from:  2020-04-06 to  2020-07-07\n",
            "ppo Sharpe Ratio:  0.2112455354618995\n",
            "======Best Model Retraining from:  2009-01-01 to  2020-07-07\n",
            "======Trading from:  2020-07-07 to  2020-10-05\n",
            "Ensemble Strategy took:  107.96398113568624  minutes\n"
          ]
        }
      ],
      "source": [
        "df_summary = ensemble_agent.run_ensemble_strategy(A2C_model_kwargs,\n",
        "                                                 PPO_model_kwargs,\n",
        "                                                 DDPG_model_kwargs,\n",
        "                                                 None,\n",
        "                                                 None,\n",
        "                                                 timesteps_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "-0qd8acMtj1f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        },
        "outputId": "13b7ea82-932a-42ad-8cfb-4780eac496ea"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    Iter   Val Start     Val End Model Used A2C Sharpe PPO Sharpe DDPG Sharpe  \\\n",
              "0    126  2015-10-02  2016-01-04        PPO  -0.097325  -0.017914   -0.072392   \n",
              "1    189  2016-01-04  2016-04-05       DDPG   0.198103   0.203143    0.245899   \n",
              "2    252  2016-04-05  2016-07-05       DDPG   0.010137  -0.013528    0.086385   \n",
              "3    315  2016-07-05  2016-10-03       DDPG  -0.028542  -0.027622    0.139916   \n",
              "4    378  2016-10-03  2017-01-03        A2C   0.441851   0.212846    0.300767   \n",
              "5    441  2017-01-03  2017-04-04       DDPG     0.1606   0.194283    0.422196   \n",
              "6    504  2017-04-04  2017-07-05        PPO  -0.030858   0.211874    0.167711   \n",
              "7    567  2017-07-05  2017-10-03       DDPG   0.122619   0.333831    0.433793   \n",
              "8    630  2017-10-03  2018-01-03        PPO   0.367378   0.473922    0.408106   \n",
              "9    693  2018-01-03  2018-04-05       DDPG  -0.160253  -0.113339   -0.082059   \n",
              "10   756  2018-04-05  2018-07-05       DDPG   -0.17177  -0.089218     0.09396   \n",
              "11   819  2018-07-05  2018-10-03       DDPG    0.29473   0.476258    0.590398   \n",
              "12   882  2018-10-03  2019-01-04       DDPG  -0.190009  -0.219892   -0.098212   \n",
              "13   945  2019-01-04  2019-04-05        PPO   0.130314   0.412193    0.386045   \n",
              "14  1008  2019-04-05  2019-07-08        PPO   0.176713   0.247669    0.054537   \n",
              "15  1071  2019-07-08  2019-10-04       DDPG  -0.161726  -0.257392   -0.145316   \n",
              "16  1134  2019-10-04  2020-01-06       DDPG   0.571045    0.26318    0.578149   \n",
              "17  1197  2020-01-06  2020-04-06       DDPG  -0.430651  -0.292517   -0.221374   \n",
              "18  1260  2020-04-06  2020-07-07       DDPG   0.218839   0.211246    0.285355   \n",
              "\n",
              "   SAC Sharpe TD3 Sharpe  \n",
              "0        None       None  \n",
              "1        None       None  \n",
              "2        None       None  \n",
              "3        None       None  \n",
              "4        None       None  \n",
              "5        None       None  \n",
              "6        None       None  \n",
              "7        None       None  \n",
              "8        None       None  \n",
              "9        None       None  \n",
              "10       None       None  \n",
              "11       None       None  \n",
              "12       None       None  \n",
              "13       None       None  \n",
              "14       None       None  \n",
              "15       None       None  \n",
              "16       None       None  \n",
              "17       None       None  \n",
              "18       None       None  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0e9f1c69-6d58-4d89-955b-36f15b81ce3b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Iter</th>\n",
              "      <th>Val Start</th>\n",
              "      <th>Val End</th>\n",
              "      <th>Model Used</th>\n",
              "      <th>A2C Sharpe</th>\n",
              "      <th>PPO Sharpe</th>\n",
              "      <th>DDPG Sharpe</th>\n",
              "      <th>SAC Sharpe</th>\n",
              "      <th>TD3 Sharpe</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>126</td>\n",
              "      <td>2015-10-02</td>\n",
              "      <td>2016-01-04</td>\n",
              "      <td>PPO</td>\n",
              "      <td>-0.097325</td>\n",
              "      <td>-0.017914</td>\n",
              "      <td>-0.072392</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>189</td>\n",
              "      <td>2016-01-04</td>\n",
              "      <td>2016-04-05</td>\n",
              "      <td>DDPG</td>\n",
              "      <td>0.198103</td>\n",
              "      <td>0.203143</td>\n",
              "      <td>0.245899</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>252</td>\n",
              "      <td>2016-04-05</td>\n",
              "      <td>2016-07-05</td>\n",
              "      <td>DDPG</td>\n",
              "      <td>0.010137</td>\n",
              "      <td>-0.013528</td>\n",
              "      <td>0.086385</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>315</td>\n",
              "      <td>2016-07-05</td>\n",
              "      <td>2016-10-03</td>\n",
              "      <td>DDPG</td>\n",
              "      <td>-0.028542</td>\n",
              "      <td>-0.027622</td>\n",
              "      <td>0.139916</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>378</td>\n",
              "      <td>2016-10-03</td>\n",
              "      <td>2017-01-03</td>\n",
              "      <td>A2C</td>\n",
              "      <td>0.441851</td>\n",
              "      <td>0.212846</td>\n",
              "      <td>0.300767</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>441</td>\n",
              "      <td>2017-01-03</td>\n",
              "      <td>2017-04-04</td>\n",
              "      <td>DDPG</td>\n",
              "      <td>0.1606</td>\n",
              "      <td>0.194283</td>\n",
              "      <td>0.422196</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>504</td>\n",
              "      <td>2017-04-04</td>\n",
              "      <td>2017-07-05</td>\n",
              "      <td>PPO</td>\n",
              "      <td>-0.030858</td>\n",
              "      <td>0.211874</td>\n",
              "      <td>0.167711</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>567</td>\n",
              "      <td>2017-07-05</td>\n",
              "      <td>2017-10-03</td>\n",
              "      <td>DDPG</td>\n",
              "      <td>0.122619</td>\n",
              "      <td>0.333831</td>\n",
              "      <td>0.433793</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>630</td>\n",
              "      <td>2017-10-03</td>\n",
              "      <td>2018-01-03</td>\n",
              "      <td>PPO</td>\n",
              "      <td>0.367378</td>\n",
              "      <td>0.473922</td>\n",
              "      <td>0.408106</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>693</td>\n",
              "      <td>2018-01-03</td>\n",
              "      <td>2018-04-05</td>\n",
              "      <td>DDPG</td>\n",
              "      <td>-0.160253</td>\n",
              "      <td>-0.113339</td>\n",
              "      <td>-0.082059</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>756</td>\n",
              "      <td>2018-04-05</td>\n",
              "      <td>2018-07-05</td>\n",
              "      <td>DDPG</td>\n",
              "      <td>-0.17177</td>\n",
              "      <td>-0.089218</td>\n",
              "      <td>0.09396</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>819</td>\n",
              "      <td>2018-07-05</td>\n",
              "      <td>2018-10-03</td>\n",
              "      <td>DDPG</td>\n",
              "      <td>0.29473</td>\n",
              "      <td>0.476258</td>\n",
              "      <td>0.590398</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>882</td>\n",
              "      <td>2018-10-03</td>\n",
              "      <td>2019-01-04</td>\n",
              "      <td>DDPG</td>\n",
              "      <td>-0.190009</td>\n",
              "      <td>-0.219892</td>\n",
              "      <td>-0.098212</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>945</td>\n",
              "      <td>2019-01-04</td>\n",
              "      <td>2019-04-05</td>\n",
              "      <td>PPO</td>\n",
              "      <td>0.130314</td>\n",
              "      <td>0.412193</td>\n",
              "      <td>0.386045</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>1008</td>\n",
              "      <td>2019-04-05</td>\n",
              "      <td>2019-07-08</td>\n",
              "      <td>PPO</td>\n",
              "      <td>0.176713</td>\n",
              "      <td>0.247669</td>\n",
              "      <td>0.054537</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>1071</td>\n",
              "      <td>2019-07-08</td>\n",
              "      <td>2019-10-04</td>\n",
              "      <td>DDPG</td>\n",
              "      <td>-0.161726</td>\n",
              "      <td>-0.257392</td>\n",
              "      <td>-0.145316</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>1134</td>\n",
              "      <td>2019-10-04</td>\n",
              "      <td>2020-01-06</td>\n",
              "      <td>DDPG</td>\n",
              "      <td>0.571045</td>\n",
              "      <td>0.26318</td>\n",
              "      <td>0.578149</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>1197</td>\n",
              "      <td>2020-01-06</td>\n",
              "      <td>2020-04-06</td>\n",
              "      <td>DDPG</td>\n",
              "      <td>-0.430651</td>\n",
              "      <td>-0.292517</td>\n",
              "      <td>-0.221374</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>1260</td>\n",
              "      <td>2020-04-06</td>\n",
              "      <td>2020-07-07</td>\n",
              "      <td>DDPG</td>\n",
              "      <td>0.218839</td>\n",
              "      <td>0.211246</td>\n",
              "      <td>0.285355</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0e9f1c69-6d58-4d89-955b-36f15b81ce3b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0e9f1c69-6d58-4d89-955b-36f15b81ce3b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0e9f1c69-6d58-4d89-955b-36f15b81ce3b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-89098362-9329-453b-9c3f-ec50dc63cce2\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-89098362-9329-453b-9c3f-ec50dc63cce2')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-89098362-9329-453b-9c3f-ec50dc63cce2 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_a41783e0-5cb7-4a7e-89eb-23f8765aee0d\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_summary')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_a41783e0-5cb7-4a7e-89eb-23f8765aee0d button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_summary');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_summary",
              "repr_error": "Out of range float values are not JSON compliant: nan"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "df_summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W6vvNSC6h1jZ"
      },
      "source": [
        "<a id='6'></a>\n",
        "# Part 7: Backtest Our Strategy\n",
        "Backtesting plays a key role in evaluating the performance of a trading strategy. Automated backtesting tool is preferred because it reduces the human error. We usually use the Quantopian pyfolio package to backtest our trading strategies. It is easy to use and consists of various individual plots that provide a comprehensive image of the performance of a trading strategy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "X4JKB--8tj1g"
      },
      "outputs": [],
      "source": [
        "unique_trade_date = processed[(processed.date > TRADE_START_DATE)&(processed.date <= TRADE_END_DATE)].date.unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "q9mKF7GGtj1g",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "652bfe4d-0c55-4c22-83e0-1689c5831db5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sharpe Ratio:  0.9643139543284998\n"
          ]
        }
      ],
      "source": [
        "df_trade_date = pd.DataFrame({'datadate':unique_trade_date})\n",
        "\n",
        "df_account_value=pd.DataFrame()\n",
        "for i in range(rebalance_window+validation_window, len(unique_trade_date)+1,rebalance_window):\n",
        "    temp = pd.read_csv('results/account_value_trade_{}_{}.csv'.format('ensemble',i))\n",
        "    df_account_value = pd.concat([df_account_value, temp], ignore_index=True)\n",
        "sharpe=(252**0.5)*df_account_value.account_value.pct_change(1).mean()/df_account_value.account_value.pct_change(1).std()\n",
        "print('Sharpe Ratio: ',sharpe)\n",
        "df_account_value=df_account_value.join(df_trade_date[validation_window:].reset_index(drop=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "oyosyW7_tj1g",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "7ed124ca-ccf3-4514-aa35-d07baac2ad1a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    account_value        date  daily_return    datadate\n",
              "0  1000000.000000  2016-01-04           NaN  2016-01-04\n",
              "1   999970.550393  2016-01-05     -0.000029  2016-01-05\n",
              "2   998469.714207  2016-01-06     -0.001501  2016-01-06\n",
              "3   995933.983391  2016-01-07     -0.002540  2016-01-07\n",
              "4   994483.166753  2016-01-08     -0.001457  2016-01-08"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d8d201c1-ecfc-47cd-b1bd-73f11f9e3d12\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>account_value</th>\n",
              "      <th>date</th>\n",
              "      <th>daily_return</th>\n",
              "      <th>datadate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1000000.000000</td>\n",
              "      <td>2016-01-04</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2016-01-04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>999970.550393</td>\n",
              "      <td>2016-01-05</td>\n",
              "      <td>-0.000029</td>\n",
              "      <td>2016-01-05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>998469.714207</td>\n",
              "      <td>2016-01-06</td>\n",
              "      <td>-0.001501</td>\n",
              "      <td>2016-01-06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>995933.983391</td>\n",
              "      <td>2016-01-07</td>\n",
              "      <td>-0.002540</td>\n",
              "      <td>2016-01-07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>994483.166753</td>\n",
              "      <td>2016-01-08</td>\n",
              "      <td>-0.001457</td>\n",
              "      <td>2016-01-08</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d8d201c1-ecfc-47cd-b1bd-73f11f9e3d12')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d8d201c1-ecfc-47cd-b1bd-73f11f9e3d12 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d8d201c1-ecfc-47cd-b1bd-73f11f9e3d12');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-855bed67-6a13-44d6-8ca7-3de178ed45e4\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-855bed67-6a13-44d6-8ca7-3de178ed45e4')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-855bed67-6a13-44d6-8ca7-3de178ed45e4 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_account_value",
              "summary": "{\n  \"name\": \"df_account_value\",\n  \"rows\": 1197,\n  \"fields\": [\n    {\n      \"column\": \"account_value\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 240427.87513473275,\n        \"min\": 966994.1333636997,\n        \"max\": 1785771.3944440042,\n        \"num_unique_values\": 1184,\n        \"samples\": [\n          1132251.9475375717,\n          1609754.1300464594,\n          1603261.6061029204\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"date\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 1197,\n        \"samples\": [\n          \"2019-08-30\",\n          \"2017-04-12\",\n          \"2016-05-27\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"daily_return\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.007814840703877808,\n        \"min\": -0.0590170368212598,\n        \"max\": 0.041363770494774,\n        \"num_unique_values\": 1167,\n        \"samples\": [\n          -0.0009927166588351,\n          0.0061445534979531,\n          0.0043866222637958\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"datadate\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 1197,\n        \"samples\": [\n          \"2019-08-30\",\n          \"2017-04-12\",\n          \"2016-05-27\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "df_account_value.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "wLsRdw2Ctj1h",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 463
        },
        "outputId": "52fffcdb-8c85-4879-df84-5e93c0a1c27b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: >"
            ]
          },
          "metadata": {},
          "execution_count": 35
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "%matplotlib inline\n",
        "df_account_value.account_value.plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lr2zX7ZxNyFQ"
      },
      "source": [
        "<a id='6.1'></a>\n",
        "## 7.1 BackTestStats\n",
        "pass in df_account_value, this information is stored in env class\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "Nzkr9yv-AdV_",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e579098c-7f5a-4034-f5b8-1f5d0af3775b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==============Get Backtest Results===========\n",
            "Annual return          0.118885\n",
            "Cumulative returns     0.705028\n",
            "Annual volatility      0.124700\n",
            "Sharpe ratio           0.964314\n",
            "Calmar ratio           0.644128\n",
            "Stability              0.936836\n",
            "Max drawdown          -0.184568\n",
            "Omega ratio            1.206435\n",
            "Sortino ratio          1.344245\n",
            "Skew                        NaN\n",
            "Kurtosis                    NaN\n",
            "Tail ratio             1.147677\n",
            "Daily value at risk   -0.015234\n",
            "dtype: float64\n"
          ]
        }
      ],
      "source": [
        "print(\"==============Get Backtest Results===========\")\n",
        "now = datetime.datetime.now().strftime('%Y%m%d-%Hh%M')\n",
        "\n",
        "perf_stats_all = backtest_stats(account_value=df_account_value)\n",
        "perf_stats_all = pd.DataFrame(perf_stats_all)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "DiHhM1YkoCel",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e01a0ee-4ada-4d3f-e4c2-0f09ac1ece27"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[*********************100%%**********************]  1 of 1 completed"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==============Get Baseline Stats===========\n",
            "Shape of DataFrame:  (1196, 8)\n",
            "Annual return          0.107293\n",
            "Cumulative returns     0.622077\n",
            "Annual volatility      0.203049\n",
            "Sharpe ratio           0.604684\n",
            "Calmar ratio           0.289307\n",
            "Stability              0.777365\n",
            "Max drawdown          -0.370862\n",
            "Omega ratio            1.143731\n",
            "Sortino ratio          0.828814\n",
            "Skew                        NaN\n",
            "Kurtosis                    NaN\n",
            "Tail ratio             0.849912\n",
            "Daily value at risk   -0.025095\n",
            "dtype: float64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "#baseline stats\n",
        "print(\"==============Get Baseline Stats===========\")\n",
        "df_dji_ = get_baseline(\n",
        "        ticker=\"^DJI\",\n",
        "        start = df_account_value.loc[0,'date'],\n",
        "        end = df_account_value.loc[len(df_account_value)-1,'date'])\n",
        "\n",
        "stats = backtest_stats(df_dji_, value_col_name = 'close')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "RhJ9whD75WTs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29c9fca6-941c-4708-d09e-afde29b41784"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "df_dji:              date           dji\n",
            "0     2016-01-04  1.000000e+06\n",
            "1     2016-01-05  1.000567e+06\n",
            "2     2016-01-06  9.858633e+05\n",
            "3     2016-01-07  9.629808e+05\n",
            "4     2016-01-08  9.532047e+05\n",
            "...          ...           ...\n",
            "1192  2020-09-28  1.608500e+06\n",
            "1193  2020-09-29  1.600837e+06\n",
            "1194  2020-09-30  1.620024e+06\n",
            "1195  2020-10-01  1.622077e+06\n",
            "1196  2020-10-02           NaN\n",
            "\n",
            "[1197 rows x 2 columns]\n",
            "df_dji:                       dji\n",
            "date                    \n",
            "2016-01-04  1.000000e+06\n",
            "2016-01-05  1.000567e+06\n",
            "2016-01-06  9.858633e+05\n",
            "2016-01-07  9.629808e+05\n",
            "2016-01-08  9.532047e+05\n",
            "...                  ...\n",
            "2020-09-28  1.608500e+06\n",
            "2020-09-29  1.600837e+06\n",
            "2020-09-30  1.620024e+06\n",
            "2020-10-01  1.622077e+06\n",
            "2020-10-02           NaN\n",
            "\n",
            "[1197 rows x 1 columns]\n"
          ]
        }
      ],
      "source": [
        "df_dji = pd.DataFrame()\n",
        "df_dji['date'] = df_account_value['date']\n",
        "df_dji['dji'] = df_dji_['close'] / df_dji_['close'][0] * env_kwargs[\"initial_amount\"]\n",
        "print(\"df_dji: \", df_dji)\n",
        "df_dji.to_csv(\"df_dji.csv\")\n",
        "df_dji = df_dji.set_index(df_dji.columns[0])\n",
        "print(\"df_dji: \", df_dji)\n",
        "df_dji.to_csv(\"df_dji+.csv\")\n",
        "\n",
        "df_account_value.to_csv('df_account_value.csv')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9U6Suru3h1jc"
      },
      "source": [
        "<a id='6.2'></a>\n",
        "## 7.2 BackTestPlot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "HggausPRoCem",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8835b48c-e795-4d78-d0a0-2eaed3f86fcb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "df_result_ensemble.columns:  Index(['ensemble'], dtype='object')\n",
            "df_trade_date:          datadate\n",
            "0     2015-10-02\n",
            "1     2015-10-05\n",
            "2     2015-10-06\n",
            "3     2015-10-07\n",
            "4     2015-10-08\n",
            "...          ...\n",
            "1317  2020-12-24\n",
            "1318  2020-12-28\n",
            "1319  2020-12-29\n",
            "1320  2020-12-30\n",
            "1321  2020-12-31\n",
            "\n",
            "[1322 rows x 1 columns]\n",
            "df_result_ensemble:                  ensemble\n",
            "date                    \n",
            "2016-01-04  1.000000e+06\n",
            "2016-01-05  9.999706e+05\n",
            "2016-01-06  9.984697e+05\n",
            "2016-01-07  9.959340e+05\n",
            "2016-01-08  9.944832e+05\n",
            "...                  ...\n",
            "2020-09-28  1.703000e+06\n",
            "2020-09-29  1.695198e+06\n",
            "2020-09-30  1.718356e+06\n",
            "2020-10-01  1.719019e+06\n",
            "2020-10-02  1.705028e+06\n",
            "\n",
            "[1197 rows x 1 columns]\n",
            "==============Compare to DJIA===========\n",
            "result:                  ensemble           dji\n",
            "date                                  \n",
            "2016-01-04  1.000000e+06  1.000000e+06\n",
            "2016-01-05  9.999706e+05  1.000567e+06\n",
            "2016-01-06  9.984697e+05  9.858633e+05\n",
            "2016-01-07  9.959340e+05  9.629808e+05\n",
            "2016-01-08  9.944832e+05  9.532047e+05\n",
            "...                  ...           ...\n",
            "2020-09-28  1.703000e+06  1.608500e+06\n",
            "2020-09-29  1.695198e+06  1.600837e+06\n",
            "2020-09-30  1.718356e+06  1.620024e+06\n",
            "2020-10-01  1.719019e+06  1.622077e+06\n",
            "2020-10-02  1.705028e+06           NaN\n",
            "\n",
            "[1197 rows x 2 columns]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x500 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x500 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABL4AAAHPCAYAAABdpBPPAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAEAAElEQVR4nOzdd3hb5dnH8a8kW957xU6cvfceJCGLFTZh700pq5RCW0pfCi2jlEIpsy17pMwm7BEgkEAI2XtvO957W7LG+8ejo6NlW17xyP25Li4dHR0dHSeyiX6+7/sxOJ1OJ0IIIYQQQgghhBBC9DDGzr4AIYQQQgghhBBCCCE6ggRfQgghhBBCCCGEEKJHkuBLCCGEEEIIIYQQQvRIEnwJIYQQQgghhBBCiB5Jgi8hhBBCCCGEEEII0SNJ8CWEEEIIIYQQQggheiQJvoQQQgghhBBCCCFEjyTBlxBCCCGEEEIIIYTokST4EkIIIYQQQgghhBA9kgRfQgghhBBCCCGEEKJH6lbB18qVKznrrLPIyMjAYDDw4YcftvgcTqeTv//97wwdOpSwsDB69+7Nww8/3P4XK4QQQgghhBBCCCE6VUhnX0BL1NTUMG7cOK677joWLVrUqnP86le/YtmyZfz9739nzJgxlJaWUlpa2s5XKoQQQgghhBBCCCE6m8HpdDo7+yJaw2AwsHTpUs4991z3PovFwn333cfbb79NeXk5o0eP5rHHHmPu3LkA7Nq1i7Fjx7J9+3aGDRvWORcuhBBCCCGEEEIIIY6JbtXq2JzbbruN1atX884777B161YuvPBCTjvtNPbt2wfAJ598wsCBA/n0008ZMGAA/fv354YbbpCKLyGEEEIIIYQQQogeqMcEX1lZWbz66qu8//77zJ49m0GDBnH33Xcza9YsXn31VQAOHjzIkSNHeP/993njjTd47bXX2LBhAxdccEEnX70QQgghhBBCCCGEaG/dasZXU7Zt24bdbmfo0KFe+y0WC0lJSQA4HA4sFgtvvPGG+7iXX36ZSZMmsWfPHml/FEIIIYQQQgghhOhBekzwVV1djclkYsOGDZhMJq/HoqOjAUhPTyckJMQrHBsxYgSgKsYk+BJCCCGEEEIIIYToOXpM8DVhwgTsdjuFhYXMnj074DEzZ87EZrNx4MABBg0aBMDevXsB6Nev3zG7ViGEEEIIIYQQQgjR8brVqo7V1dXs378fUEHXk08+ybx580hMTKRv375cccUVrFq1iieeeIIJEyZQVFTEt99+y9ixYznjjDNwOBxMmTKF6OhonnrqKRwOB7feeiuxsbEsW7ask786IYQQQgghhBBCCNGeulXw9f333zNv3jy//VdffTWvvfYaDQ0NPPTQQ7zxxhvk5OSQnJzM9OnTefDBBxkzZgwAubm53H777SxbtoyoqCgWLlzIE088QWJi4rH+coQQQgghhBBCCCFEB+pWwZcQQgghhBBCCCGEEMEydvYFCCGEEEIIIYQQQgjREST4EkIIIYQQQgghhBA9UrdY1dHhcJCbm0tMTAwGg6GzL0cIIYQQQgghhBBCdBKn00lVVRUZGRkYjU3XdHWL4Cs3N5fMzMzOvgwhhBBCCCGEEEII0UVkZ2fTp0+fJo/pFsFXTEwMoL6g2NjYTr4aIYQQQgghhBBCCNFZKisryczMdOdFTekWwZfW3hgbGyvBlxBCCCGEEEIIIYQIahyWDLcXQgghhBBCCCGEED2SBF9CCCGEEEIIIYQQokeS4EsIIYQQQgghhBBC9EjdYsZXMJxOJzabDbvd3tmXItooNDQUk8nU2ZchhBBCCCGEEEKIbq7FwdfKlSt5/PHH2bBhA3l5eSxdupRzzz23yecsXryYv/3tb+zbt4+4uDgWLlzI448/TlJSUmuv24vVaiUvL4/a2tp2OZ/oXAaDgT59+hAdHd3ZlyKEEEIIIYQQQohurMXBV01NDePGjeO6665j0aJFzR6/atUqrrrqKv7xj39w1llnkZOTw80338yNN97IkiVLWnXRnhwOB4cOHcJkMpGRkYHZbA5qqr/ompxOJ0VFRRw9epQhQ4ZI5ZcQQgghhBBCCCFarcXB18KFC1m4cGHQx69evZr+/ftzxx13ADBgwAB+8Ytf8Nhjj7X0pQOyWq04HA4yMzOJjIxsl3OKzpWSksLhw4dpaGiQ4EsIIYQQQgghhBCt1uHD7WfMmEF2djaff/45TqeTgoICPvjgA04//fR2fR2jUeb09xRSsSeEEEIIIYQQQoj20OFp0cyZM1m8eDEXX3wxZrOZXr16ERcXx3PPPdfocywWC5WVlV7/CSGEEEIIIYQQQgjREh0efO3cuZNf/epX3H///WzYsIEvv/ySw4cPc/PNNzf6nEcffZS4uDj3f5mZmR19mUIIIYQQQgghhBCih+nw4OvRRx9l5syZ3HPPPYwdO5ZTTz2V559/nldeeYW8vLyAz7n33nupqKhw/5ednd3RlymC9NprrxEfH9/kMQ888ADjx48/JtcjhBBCCCGEEEII0ZgWD7dvqdraWkJCvF9GG1judDoDPicsLIywsLCOvjQhhBBCCCGEEEII0YO1uOKrurqazZs3s3nzZgAOHTrE5s2bycrKAlS11lVXXeU+/qyzzmLJkiW88MILHDx4kFWrVnHHHXcwdepUMjIy2uerEEIIIYQQQgghhBDCR4uDr/Xr1zNhwgQmTJgAwF133cWECRO4//77AcjLy3OHYADXXHMNTz75JM8++yyjR4/mwgsvZNiwYSxZsqSdvgRvTqeTWqutU/5rrIKtMQ6Hg0cffZQBAwYQERHBuHHj+OCDDwD4/vvvMRgMfPvtt0yePJnIyEhOOOEE9uzZ437+li1bmDdvHjExMcTGxjJp0iTWr1/vfvzHH39k9uzZREREkJmZyR133EFNTY378f79+/PQQw9x1VVXER0dTb9+/fj4448pKirinHPOITo6mrFjx3qdU/Phhx8yZMgQwsPDOfXUU5ttR33ppZcYMWIE4eHhDB8+nOeff75Ff1ZCCCGEEEII0d19tSOfK15aw6r9xZ19KUIcNwzOlqY1naCyspK4uDgqKiqIjY31eqy+vp5Dhw4xYMAAwsPDqbXaGHn/V51ynTv/fCqR5uC7Rx9++GHeeustnnrqKYYMGcLKlSu5+eab+eqrr3A6ncybN49p06bx2GOPkZKSws0334zdbmfVqlUAjB49mgkTJnDfffdhMpnYvHkzQ4cOZdy4cRw4cIBx48bx0EMPccYZZ1BUVMRtt93GuHHjePXVVwEVfFVVVfHII48wf/58/vGPf7B48WJOOOEErrvuOsaNG8fvfvc79uzZw44dOzAYDLz22mvcdNNNjBs3jqeffhqz2cwtt9xCSEiI+7oeeOABPvzwQ3dV4OLFi7nnnnt49tlnmTBhAps2beLGG2/kySef5Oqrr/b7c/H9OxVCCCGEEEKInuCCF35i/ZEyAP7vzJFcP2tAJ1+REN1TUzmRrw6f8SUCs1gsPPLII3zzzTfMmDEDgIEDB/Ljjz/y73//m5tuuglQ4dicOXMA+P3vf88ZZ5xBfX094eHhZGVlcc899zB8+HAAhgwZ4j7/o48+yuWXX86dd97pfuzpp59mzpw5vPDCC+5A6fTTT+cXv/gFAPfffz8vvPACU6ZM4cILLwTgd7/7HTNmzKCgoIBevXoB0NDQwLPPPsu0adMAeP311xkxYgRr165l6tSpfl/rn/70J5544gkWLVoEwIABA9i5cyf//ve/AwZfQgghhBBCCNHTOJ1OtudWuO8/9NlOTh6RRt+kyE68KiF6vh4XfEWEmtj551M77bWDtX//fmprazn55JO99lutVncbKcDYsWPd2+np6QAUFhbSt29f7rrrLm644QbefPNNTjrpJC688EIGDRoEqDbIrVu3snjxYvfznU4nDoeDQ4cOMWLECL/zp6WlATBmzBi/fYWFhe7gKyQkhClTpriPGT58OPHx8ezatcsv+KqpqeHAgQNcf/313Hjjje79NpuNuLi4oP+8hBBCCCGEEKI7K6q2UN/gwGiAEemx7MitZM2hEgm+hOhgPS74MhgMLWo37CzV1dUAfPbZZ/Tu3dvrsbCwMA4cOABAaGioe7/BYADUbDBQLYWXXXYZn332GV988QV/+tOfeOeddzjvvPOorq7mF7/4BXfccYffa/ft29e9Hej8Tb1ma7/OF1980V0hptFW9xRCCCGEEEKInm5/ofps1DcxkllDktmRW8nGrDIunJzZyVcmRM/W9ROiHmrkyJGEhYWRlZXlbmX0pAVfzRk6dChDhw7l17/+NZdeeimvvvoq5513HhMnTmTnzp0MHjy4vS8dm83G+vXr3dVde/bsoby83F1F5iktLY2MjAwOHjzI5Zdf3u7XIoQQQgghhBDdgRZ8DU6NYVLfBAA2uOZ9CSE6jgRfnSQmJoa7776bX//61zgcDmbNmkVFRQWrVq0iNjaWfv36Nfn8uro67rnnHi644AIGDBjA0aNHWbduHeeffz6gZnNNnz6d2267jRtuuIGoqCh27tzJ119/zbPPPtumaw8NDeX222/n6aefJiQkhNtuu43p06cHnO8F8OCDD3LHHXcQFxfHaaedhsViYf369ZSVlXHXXXe16VqEEEIIIYQQojvYW1AFwODUaCb1S3Dtq6ak2kJSdFhnXpoQPZoEX53oL3/5CykpKTz66KMcPHiQ+Ph4Jk6cyB/+8IdmWwtNJhMlJSVcddVVFBQUkJyczKJFi3jwwQcBNbtrxYoV3HfffcyePRun08mgQYO4+OKL23zdkZGR/O53v+Oyyy4jJyeH2bNn8/LLLzd6/A033EBkZCSPP/4499xzD1FRUYwZM8Y9eF8IIYQQQggherqtR9Vg+9G9Y0mKDmNkeiw78ypZua+I8yb06eSrE6LnMjidTmdnX0Rzmlqmsr6+nkOHDjFgwAD3SoWie5O/UyGEEEIIIURPUt9gZ8wDX9Fgd/LDb+eRmRjJ41/t5rnvDnD2uAyevnRC8ycRQrg1lRP5Mh6jaxJCCCGEEEIIIY5Lu/IqabA7SYoy0ychAoA5Q1MB+PlgSWdemhA9ngRfQgghhBBCCCFEB9qcXQ7AuMx4DAYDoFZ3BCipseJwdPlGLCG6LQm+hBBCCCGEEEKIDrT+sFq9cUJmvHtffGQoAHaHk6p6W2dclhDHBQm+hBBCCCGEEEKIDuJ0OllzSLUzThuY5N4fHmoiymwCoLTW2inXJsTxQIIvIYQQQgghhBCigxwsrqG42oo5xMi4zDivxxKizACUSfAlRIeR4EsIIYQQQgghhOggy3cVAqrNMSzE5PVYQqQr+KqR4Ev4e3LZHl7+8VBnX0a3F9LZFyCEEEIIIYQQQvRETqeTd9dnA3D2+Ay/x7WKr1IJvoSPvQVVPL18PwBXz+hHiEnqllpL/uSEEEIIIYQQQog2aLA7+HZXARW1DV77t+VUsL+wmohQE2eP8w++El0D7qXVUfg6Wlbr3q6oa2jiSNEcCb6EEEIIIYQQQog2eGP1Ea5/fT03vrneve+JZXs4+9lVAMwZmkJMeKjf8/QZXy0PNnblVZJTXtfKKxad4XBxDfd/tJ38ivpmj80u1f9uJRhtGwm+upi5c+dy5513+m0D9O/fn6eeeqpTrksIIYQQQgghRGDvrssCYO2hUgCOlNTwjKtNDWDWkOSAz0tsxYyvWquNXXmVnPPsKub//XtqLLbWXrY4xn717mbeWH2EXy7e4LXfanPw+k+HyS7Vq7wOFde4t1sTjAqdzPjqwpYsWUJoqP5bgXXr1hEVFdWJVySEEEIIIYQQwldUmP7R2uFw8o1roL1mdiPBV7zHjC+n00llnY24SP/KMIA3Vh/m8a/2UFVv89l/hF/OHdSWyxcdzOFw8sKKA2zJLgdgU1Y5+wurGZwaDcCSjUf508c7+POnO9nyp1OIDgvhSIkefMkMuLaRiq8uLDExkZiYGPf9lJQUIiMjO/GKhBBCCCGEEEL4MnsMHs+vrOfbXQXu+3OGptAvKXABg1bxlVVay5Nf72Xcn5fx3Z5Cv+OcTicPfLzDL/QCWLrpaFsvX3Sw5bsLefyrPV77nvxa3d+SXc7ba1XFoN3hZMpD33Dly2v4bk+R+9hyaXVsk55X8eV0QkNt88d1hNBIMBiCPrympoZf/vKXLFmyhJiYGO6++26vx+fOncv48ePd7Y39+/fnzjvv9Gp/FEIIIYQQQgjROb7bU0hEqIkSj4qcE/663L39zV1z3FU9gYztE4c5xMju/Cp251cB8OSyvcwblsqHm3IICzFy2uheLNtZgMMZ+ByHS2pxOJwYjcF/FhXHlucstgfOGsmDn+7k8235vL02i/uWbvP6u61rsPPDvmKv55fWSKtjW/S84KuhFh7xXy3jmPhDLpiDb0W85557WLFiBR999BGpqan84Q9/YOPGjYwfP77jrlEIIYQQQgghRJv9uK+Ya19dp6q9AmROMeEhDExu+vNhZmIkf1g4nAc+2ene1zs+gqNltdz57mYAwkKMWGwOAM4Yk87sIcn8fsk29/FWm4P8ynoy4iPa/kWJDlHumtF16dS+XDNzAFuOVrB0Uw73evw9Avzvlyew+kAxh4prKa2xsDOvkoJKi1R8tVHPC766ierqal5++WXeeustFixYAMDrr79Onz59OvnKhBBCCCGEEEI0xel08qePtwNgtTsCHjO2T1xQVVhnj+/tFXylxISx2TULCnCHXhlx4dx04kASXXPBQLVYWu0OjpTUSvDVhZXXqeAq3jW/7cbZA1m6KcfvuEn9EpjUL8F9/7nv9vP4V3tkxlcb9bzgKzRSVV511msH6cCBA1itVqZNm+bel5iYyLBhwzriyoQQQgghhBBCtNGRkhreW5/NpH4JHCiq8XrMHGLk6UsmcPNbasW+XrHBBVGeQRZArdXuHoIeEWrC5nCwYHgaz18+EaPRgNPp5IZZA3A44UBRNSv2FnGkpIYZg5La/gWKDlHhqvhKcAVfIzNiuenEgaw7XMp5E3qzObucecNS/Z6XoK36Kas6tknPC74Mhha1GwohhBBCCCGEEMF46pt9ASt1ADITIjhtdC/iI0Mpr21g/nD/IKMxl0/ry+I1asB5rdVGdpmaW/3nc0Zx6uhexISFYDi6Hja9ieHkB/njmSMB+NNH21mBmvMluqaXfjjIEtd7Jj5CDzn/cPoI9/ZVMwI/NzFKBWVl0urYJrKqYycZNGgQoaGhrFmzxr2vrKyMvXv3duJVCSGEEEIIIYRozIq9RV73R/eOdW+PyogD4JPbZvH85RM5fUyvoM/7p7NGscAVlFVbbOzIqQBgXGY8seGhGAwGeP0s2Pg6fHiL+3naapFZpTX+JxWdbmduJQ99tst9P85V8RWseFfFV35FPY7GVjcQzZLgq5NER0dz/fXXc88997B8+XK2b9/ONddcg9EofyVCCCGEEEII0dXUWGzuypuFo3uxaGJv7pg/xP34L+YMBNTA+tPHpKuwKkjmECMXTs4E1AqANVY7AP2SPMbp2FwrA+753L1La5OsrLO1/AsSHW71wRKv+/ERLQu+RvSKJcpsIqe8rtFKw6ZU1DVw5ctrGPF/X/Lmz0da/Pyeoue1OnYjjz/+ONXV1Zx11lnExMTwm9/8hoqKis6+LCGEEEIIIYQQPnblVeJ0Qq/YcF64YhIAFpudk0akMjI91l3x1VrRYerj+UHX7LDEKDNhISb1oN0n2MrZAL0nER6qHq9rsLfptUXHWH3AJ/iKNDdyZGBxkaHcMm8wj3+1h/fWZ3P+pJYthrdqfzE/7CsG4JMtuVw5vV+Lnt9TSPDViaKjo3nzzTd588033fvuuece97bFYiE6Otp9//Dhw8fy8oQQQgghhBDiuPfJllySos3sya8CvNsbw0JMvHT1lHZ5ncgwk9f9jGgjfH0/9J4MvcZ4H/zmIrhjExFmV/BlleCrq7E7nKw55B18JbSw1RFgQmY8gNfKjoeKa1h7qIR+SVFM7pdAiClw51hhZb17+0BhdYtfu6eQ4KsLslgsbNu2jR07dnDHHXd09uUIIYQQQgghxHHpcHENt7+9CYDe8WqVxrF94lt/wh+egPWvwRX/g5ShXg9pFV+aq/kUVr2i7lyxRN2aY8Bogvpy+NsARgy5CDiXeqn46nJ25lZSVe9dqRfbwlZHz+fsK6zmypfXcO/CEdz29kZ3ZeCMgUm8fdP0gM8tqra4t0tqrJTVWEmIalnVWU8gA6W6oC+++IL58+dz9tlnc8EFF3T25QghhBBCCCHEcWlnXqV7O6dczdia0j+xdSfb/y18+2eoyIJNb/o9HOUVfDlZUKvP8mLti+q2/0wYo39GTN33Hr0okVbHLuhnn/legLs1tSXiPMKyH/YVc9UrazlUrC9msPpgCRV1DQGfW1hp8bp/oOj4rPqS4KsLOvfcc6msrOStt94iNLTlibAQQgghhBBCiLbT2hs9Tegb37qTbX1X385e6/dwlFkPRdIoI7EhX39w7xfqNnEgZHpX98wzbZbgqwvSBtsntbHCynclyOJqC04nmE1GMuLCATV/LhDPii+Q4EsIIYQQQgghhBAe9hV6B18JkaGtqtoBoPSgvp39M5Qc8Ho40qxXfCUbAgcZTLwKMqd67Zpv3CQzvrqY0horq/arofLPXT6RIanR7lU/WyraHIIxwAKhaXFhjOqtFlQIFHx9uCmH7/cUATAgOQqAA0U1fscdD3rMjC+n09nZlyDaifxdCiGEEEIIIboCreLrmUsnsO5wKeeM7936k3kGXwDPTIQzn4LJ1wJgDjFiNhmx2h0kGPwrzbhiCaSOAKcTZv0ajqyG7J8ZZzyIxeLA4XBiDJSQiGPu7bVZWGwOxvaJY9qARL6+a06rz2U0GoiNCKW81rudMT02gpHpsXy9s4Cdud7BV0m1hTvf3ey+f/qYXhwurmVkeizHo24ffGmtgLW1tURERHTy1Yj2YLWq1SpMplb+JkUIIYQQQggh2qjGYuNwSS2g5nqdNS6j9SerK4da18yn81+GVf+E/K3w2W9g5DkQqeaGRZhNWOscJBIg+Oo9Sd0aDHDSA2Cpgkf7kGooJ45q6m12r6ox0Xm+3VUAwOXT+mIwtCGMtFSBwURcgOCrV1w4IzNUkLUtp8LrscMl3pVdV5/Qn9SY8NZfRzfX7b8rTCYT8fHxFBYWAhAZGdm2N5boVA6Hg6KiIiIjIwkJ6fZvTyGEEEIIIUQ39d2eQuwOJ/2TIkmLDWvbycoOqdvoNDWcfvT58ORIqMqFnI0w5CQA95DygBVfEfHe98NicMb1wVBxlCGGo9Q3OIg8/hbs65K02VqDU6NbfxJrLTyaCdFpRJlf8ns4PS6cyf0SMBhgd34VhZX1pMaqcCurtNbr2KSoNr5/u7kekSz06tULwB1+ie7NaDTSt28bk3EhhBBCCCGEaIMvtqvh8qeNTm/7ZxOtzTHRNefJYICBc2DL23B0rTv40iQbXcHX6AvAUgnjLgl4WkPKcKg4ylBjjgy470JKqlUXU5sCp8KdgBOq8zHGWf0e7hUXTlJ0GGN7x7HlaAXf7y3iosmZABwp8Q6+TMd5C2yPCL4MBgPp6emkpqbS0BB4GU/RfZjNZoxGWXdBCCGEEEII0TF25VXyw74irprRP+CweqfTycq9ajD4qaPS2v6C2iqOSYP0fX0mq+ArwAqPw2MboAYVlM2/r/HzpgyH/d8wxHBUBtx3EbVWG7Wuv4uk6DaU4DXo4VWoow7wDq/SXSs6zhmWypajFfywr9gdfGkVX/2SIvnb+WNbfw09RI8IvjQmk0nmQgkhhBBCCCGEaNJd721hV14lBwpreOwC/2Agr6KeqnobIUYDozLiWvci3z0C9ZUw/4+w+W21b+R5+uPazK78be5dfzxjBG+sPsLMDAPsAyKTmn6NpMEA9DUUUi8VX12CVu1lDjESHdaGyKWu3L1pttcBkV4Pj+0TD+AeWJ9TpgdlWa6Kr3tOHca0gc28h44DUlYjhBBCCCGEEOK4kV9Rz648tQreu+uz3SGBpz0FqtVwQHIU5pBWfGyuLYUVj8GaF+Cp0WCpgIQBMGi+fkysa4XI2hJwqNDqhtkDWfnbeUTaytVjzQVfYTHqMCzS6thFlNSo4Cs5yty2FtnaYvdmqN3/PZoRrxb3S3ZVlWmvC3rFV9/ESL/nHY8k+BJCCCGEEEIIcdz4fo/3bOgtR8vd2w6HE4C9+Sr4GtorJriTVuTAe1fB4VXqfsF2/bG6MgiNhDOfBM+RLhGJqPY1pwrKqgvh539BQ526DxDVTPAVqsKPcINVWh27iBLXYPuk6DYOlK8pcW+OSvbubIsJ1yvJtNfRKs2sNgeFVeoaervCseNdj2p1FEIIIYQQQgghmvK5a2i9Zl9hNQBrD5Vy7atruWH2QLJdbWPD04IMvpbdBzs/Uv89UAEFO70fn/9H72ovAFMIRCRAXSnUFMFrZ6htS6WqAoPmK75C1JyncKwUSsVXl+AebN+W+V6g3hMuN5+QRmVSGpV1Nr7akc8r10xxP6a9TrXFRn2D3V35ZTYZSYySZT5Bgi8hhBBCCCGEEMeJo2W1/LBPBQpXTu/Hmz8f4YAr+Pp4Sw41Vjv//Haf+/hhwVZ8Fe/zvu9Z8RUeBxOvCvy8qGQVdlXmqFuAo+v14CsisenXDVWtbOFYZMbXMWJ3OMkuraVfUmTAVsbiGlfFV1tWdASvVscEUwOPLlKz6Cw2O2EhegVYTFgIZpMRq91BSY2V/Ip6AFJjw9q+GmkPIa2OQgghhBBCCCGOC59sycPphBMGJTF/RCoA+wpVW+PhYu85SsPSYjhxaEpwJzZH6dvWWijYobZPvAdu+t49i8tPlOv8H92q7wuPA7vV+/HGhLoqvgwN0up4jDyxbA9z//49H27O8XvM4XDy2dY8AJJj2lrxpQdfWGvcm56hF4DBYHBXfZVUWyisVMFXWmx4216/B5HgSwghhBBCCCHEcWGna6j9nKEpDEmNBuBQcQ02u4PdrrleF07qw5yhKTx/xUTCQ02NnstLQ52+/Ug65G5U2+MuhcSBjT9Pa2WsLtD3lbiqx8Lj3MFWo9wVX1YZbn+MPP/9AQAe+nSX32Ovrz7Mjlz1HkuNaWPwVKvP+MJa3eShWvB19rOrWHtYVQ6mxbax4qwHkVZHIYQQQgghhBDHhf2utsbBqdFkxEUQZTZRY7Wz/kgZxa6h5A+cPYqosCA+KjvssPU9iExUrYq+olKbDr1AtTr60tomo1KbvwbXjK+I43hVR6fTyb1LtlFZ38DTl0wgxNRx9T1Wm8O9nRqgokoLvQDOHpfRuhc5uAJ2LIXybI8Xrmn8eCDZY5D+q6sOA1Lx5UmCLyGEEEIIIYQQPZLT6eT3/9uG0QgPnTuGA0V68GU0GhiRHsv6I2W89MMhAPomRgYXejmd8PalsO+rxo/JnArNzVjybGUcdZ4KPLTqnui05q/DvapjA/WWhuaP74E2Z5fzzjoVEl08pYQ5wbanBsHpdGK1O9zthbvy9GArLMQ/YCtwtRk+fsFYUmJaWXH15b1QuMN7X0Nt4GNdjAHeZxJ86ST4EkIIIYQQQogu7Ls9hTz6+S4ePm8MU/o3M+xceNmeU8m761UoMn1gElabA3OIkT4JqkVwZIYKvr7ZpVoN5w8PosqqrkxVegUKvQafBPu/UdsJ/Zs/V1isvj1wrgq+NNFBXIsr+AJosNQ1cWDP9e46vTLqky257Rp83fTmBtYdLmXmoGSm9E/A5nC6H9NmaXnSBsv3imtl6FRXBoU7/fc30+pY4qpW9NRLgi83mfElhBBCCCGEEF2Uze7g2lfXsbegmhvfWI/T6Wz+ScLt61367Kwnv94LwMDkKExGVSEzKkMPnib2jefe04c3f9IlN8EXv/XfnzwUrvgfzP8jJA2B6bc0fy7PQKPXWO/Hggm+QvTgy2Ztuiqop/phnz4E/vNteeSWt18A+PXOAsprG/hsWx4PfLKThz7T53oVVlmwO5zYHU7uem8z/15xgHxXGNbq0Cl7HRDge7yZVsffLfR/30rFl06CLyGEEEIIIYTooj7blufeLq9t4KHPdvG+q4LJ6XSyYm8R5bXWzrq8Lq2wqp6PPFbeO1KigqGR6XrYNSojzr3965OH+q2Y56fsMOxbpt9PH6dv956kbk+8B25fD3G9m7/IcZeoAfUTr4KIeO/Hggm+TCHYDaqRy2E9Piu+KutVi2dCZCi1VjsPf+4/dL41GuyOgPvNrhZHm8NJSbWFzdllLNmYw6Nf7Kaq3ga0oeIra3Xg/c0EXycMSmbtHxZ47RvpEeoe76TVUQghhBBCCCG6qLfXZnndf/lHNYtqRHos6w6X8uAnOzlzbDrPXjaxMy6vS6qz2ll3uJRnlu/jSEktMWEhVFls7sfnDNNb4Yb3imH+8FSiw0KYNTjAoHlfG15XtwYjnPxnSB4G/71Q7Zt5Z8svNqE//PYQhISpNjdPwcz4AuymcEy2ahzHYcWX0+mkxvV3+6ezRnHnu5vZkl3eLucur9Vnpi255QQKKup57vv9XDWjP08s20NBpYX8ynpyy71bHqPMJmLCQ1v3olk/e9+PSYeqvGZbHcF7wH1EqIm4iFZeQw8kwZcQQgghhBBCdEHZpbX8fLAUgwE+vGUm5zy3yv3Yir1FPP7VHgA+3ZrHvoKVPHD2KGYMSuqsy+0y/vntPv614gAARgMsvfUE/vrFbr7ZVQjgNQMqxGTklWumBHfi+gpY97LavvB1GHk22Kww5kJIGw2pQbRJBhLqqg4K86nQCWZVR8BuCgNb9XFZ8VXXYEcbu5XuqrKy2dunHbiiTlVSxkWEMrFvAgALx6QDsHhNFgWVFvIq6smr8P5zb/Wr2yyQs8F7X78TYPv/mq34AjAa9QH3abGtHKzfQ0mroxBCCCGEEEJ0Qct2qvlU0wckMS4znkcXjXE/poVemj0FVVz64s8cKm7+A3JPp4VeAMN6xTI4NYbb5g/BZDSwYHgq8ZHm1p1402KwVKgqr+Fnqn0hZjj/JZh1Z9sv3BQCJo9ri88M6mkOk5rz5Ww4/oKvale1l8EAcZGqwqmxFsWW0iq+4iP9K6cGJkcBsCOnwq/iq9Zqb90L5m4GuwUik+H6r+Gsp9VKnxBU8AWQmajeCxdODu69c7yQ4EsIIYQQQgghuoD6BjtHSvQPuKv2q6Hd84arCqVLp/blm7vmNHmOl3882HEX2A1U1TfgUfjCtSf0B2B8Zjzf3z2Xpy+d0PqTa6s4Tr4WjB30UdruMa8teVhQT3GGuCrGGo6/VscaiwqZos0hhJrU34m1vYOvAC2D0weq1VV/OlDirvg6dVQaZpORewMMmm+S3Qbf/ln9B9B3OmROhUlXg1kFbMEGX/+9YTp/u2Asv5wzqGXX0MNJq6MQQgghhBBCdAF3v7+FT7fm8fB5o7lociY/HywBYKbH7KlBKVHcOHsAu/OrOH9iHwanRvN/H21n1uBknlm+n6Ubc/jdacNbP2Oom3I4nDz73X4q6xpwOCE6LIS/XziWU0f1ch+TmRjZupPXlMA3f4KD36v7gxY0eXi7iEwKOlxzais7NtQ3fWAPpM33igoLwewKvtqr1bG8TgVfcQEqBGcMVN+T64/oc9kumJTJs5dNdAdwQTuwHH54Qr8//Ax92xytbuvKgzpVZmJk69/nPZgEX0IIIYQQQgjRyRwOJ59uVSs43rd0OyFGA7VWO4lRZkb00mc/GQwG7jtjpNdzl94yE6fTydJNORwtq2NTVjknesyxOh6s2FfEk1/vdd8/ZWQap41Ob/uJrTXw8slQ6mqfjEiE5CFtP29zxl4S/LGuGWEG2/EXfGmrKEaFmdyBU2tbHVfsLSIzIYKBKSps0lZLDVTxlZkYQZ+ECI6W6e2l6XHhLQ+9ACqPet8ffb6+nTRYP6a6CKKPr+/r9iKtjkIIIYQQQgjRyQ4Uea/a9rv/bQNg7tAUr6HVjTEYDAxLiwHgSOnx1/Lmu5LftTMHNP2EhjrI3978iXd8qIdeADNuUQOlOsp1X8GM22DB/cE/x1XxZbAdfzO+tIqv6PBQQk3q78XmcOJwtKzqa+vRcq5+ZS3zn1jh3qe1OiYEmPFlMBj4x8Xj6ZMQ4d6XER/hd1xQqgv17YveVCt8aiITIdUVdGf7rPgogibBlxBCCCGEEEIcA++tz2bBE9/z4Cc7sNq8q1I2ZZUHfM4po9KCPn/fJNXilFVy/A2433a0wr197cz+jOkT1/jB9RXw0snwr5lw4LvGjzu8Cj66RW0vuB/uL4MT72mnK25E3+lw6sP6So9BMJjV37vRfnxVfC3bkc8Nb6wHIDrMRGiIHm80OFpW9bXBo2XR6VShWbm2qmMjiyFM6Z/Il3eeyPjMeOYOSwkYkAWlSlV6Muf3aqVQX32nq9sjq1t3fiHBlxBCCCGEEEIcCy+uPMiBohpeXXWYd9dnez329S61guMlUzIxuSq8wkONzB4SfGtTP9dsnyMlx1fFl9PpZIsr+Prg5hncf+bIpg6GD2+BAlVRx+b/Nn7c+9fo98de0nED7dvIaFaVRiHHWfB105sb3NtR5hBCPf5+Wjrny7NATKv0amq4vSY6LIQPb53Ja9dOxdDaSsCqfHUb0yvw45nT1G3e5tadX0jwJYQQQgghhBAdrbzWyr5CvZ3xlR8Puduxvt5ZwNc7CzAZDVwxvR//vmISvzhxIK9cPYWosODHMvdLVivAZR1nrY55FfUUV1swGQ2MyojzDiCqCqB4v35/18ew+1P9/p4vAg+Fry6AGlcL2iVvQ1zvjrn4dmDSgi+HBVs7rWjY3USHhbhbHaHlc77KavTVNK9+dS1bssupcA23j29tJVewmgu+olPVbaAB9zUlQa/4eDyT4EsIIYQQQgghOpjWSpUWG0Z0WAiHimvYnquqlF758RAAN8wawOjecZw0Mo17Tx/BCR6rOQbDs+JLa9c6Hmw9Wg7A0LQYIswm/YFDP8Czk+GFE6A8S+3b84W6nX4rRPcCaxXkuCqHKnPh7csgaw0U7lT7kobA8NOPzRfSSqYwFXiGG6zU246P4Ms34IsOD8FkNLjHr1lbGHzlV+rh59ajFVz079XklKuZaUnRYY09rX00F3yFu9p26/V2XmpL4adn4R+jVNvucfT93hoSfAkhhBBCCCFEB1t3WAVfc4amMKV/AgDrD5dxtKyW1QdLALhyRr82vUafhEiMBqhrsJNXcfy0vWltjuN853p9+XuwVILdAtveV/tyN6vbAbMhzdUSWXpQ3S5/GPZ8Bq+cAoW71L7UER178e1Aq/iKwEqd1d7JV3NseK6mCBAVFoLBYPBY2bFlQVBBpff3i8Xm4GCRqqQa27uJeXHBqiqAFxfAhte99zvsemVhdCPBV5jr9S2VoM0ue+NsWHYf2OqgcIce1IqAJPgSQgghhBBCiA72rWuG1wmDkpncPxGA9UdKWboxB4AZA5PokxDZptcwhxgZmRELwLrDpQGP2V9YzZ78qja9TlewPaeC+5Zu43Bxjbvia2yfeP0Am0UPrwC2fQDWWijeo+6nj4cE18qPZarijvpy/fhdn6jbbhB8GULV+yYCC/UNx0fwdchnAYcoV6VfqGs+XmMtn41VQuY3EhQPSokiISrwcPsW2bwYctbDJ3fA8yfoAWxNETgdYDBCVCPz/MLV9zSWSni0t3pvFuzwPmbfsrZfYw8mwZcQQgghhBBCdKADRdXsK6wmxGhg3vBUpriCrzUHS3nj5yMAnD+pT7u81vQBSQD8fNA/+GqwOzjpyRWc+tRKaq22dnm9jlJrtfHtroJGA4xnlu9j8Zos5v79e1btVxVzYz0rvkr2g9MVApnMqiJm67sqZIhOg9h0SHQFX6Wu4Mtm0Z+f5VpBL7WJQfldRair4stgpe44Cb4OF3sHX/UN6n2irewYaMZXfkU9Ux/5lkc+3+X3mG/Fl2Zyv8S2XqpSp68aSeEO+Pp+ta1VG8ZkgKmReX5hsfp2Qy28e4V6HxtDYeHjav++b9rnOnsoCb6EEEIIIYQQogN9vVNVe80YlERcRChj+8SRHG2mpMZKUZWFiFATC0c30ubUQtMHquBrjat90lNJtT7AWxvc3ZU4nU5qLDae+24/Zz+7iutfX8+/Vx4MeOzWoxVe98f1iWN4rxh9h1btlTkNhpyitj+7S92mj1e3vhVflbneL5I5DYYtbOVXcwyZ1Yyv46niyzf4Kq9T722t1dFq86/s+ue3eymqsvAfn/dUrdVGZX3gIHiSqy25zbQZc5pDK1TVllb5lT628eeGhoMpwJyx2Azod4LaLtjW9JyvnR95B7vHmeCXCBFCCCGEEEII0WKr9hcDMH+4Wp0tPNTE85dP4sqX12BzOLl5zqAWrd7YlCkDEgkxGjhYXMP+wioGp6owaGNWGf9ZoX/gr22HWVDltVa2Hq1g5uBkTEZD809oQo3FxjnPrWK/x8qXAP9ZeZBb5w322udwOClxrcJ3y9xBhIWYuPHEAYS4Qg8s1bD8IbWdOgIGzlMrOTpdVUDDTlO3iQPVrVZ1U3lU3V79iRokPuRUCGmHNreO5mp1jMRy3Mz4OlTivXLp2N7xAJhNjVd8HSkJvNrpluyKgPsBJvdrh+Brx1LY+aHavnixmje380P49s8QHq/2a2FsY8JjVVukp7hMSBoEGNT7taZIXwFS43TC93+FFX+F4WfCRW+A0cTxRoIvIYQQQgghhOggVpvDPW/rhEH6Ko1TByTy0+/nE2IyEhcR2m6vFxcRytxhKXyzq5APN+Vy96nDqG+ws+j5n7yOq7W0PiCps9p5/Ks9vL8hm6p6G/cuHE5sRChbj5ZzyshezHMFfA6HE2OQgdj3e4r8Qi/t6/FUVmPlD0u3YbU5CDUZuOvkoXrgpfn6//QqrtSRMPQ0iEjQ281GnKNuE/qr2/oKKM/WV81LH6/PVeoOzK4ZXwbLcdfq+Mh5YwBYNLE3ACEm14wvh3/wlVte57cP4Id9KlA6Z3wGJ49M4/Gv9nCkpJakKDMDkqPadqGVufD+Nfr9xAEw/48qiN37pb4/Y3zT5wmPCxB89VZtrvF9ofwIFO/zD76OrlOhl/YahuOz6e/4/KqFEEIIIYQQop2tOVjC7W9vYmduJaDaCZ9Zvo/6BgfJ0WaGpkV7HZ8UHdauoZfmnPEqBPhqRz4AH27K8Tumpg0zvj7dmssrqw5R5WoPe/SL3dy7ZBtvr83m2tfWcd7zq3jg4x0M+78veMs1w6w537iG//sqrbG6B5IfLq7hqlfW8sV29XVlJkR6h15OJ1QchS3vqPtpY2DMhapV7LL3wRwD4y+HKNUOijlSX0nvyCp1GxbbvUIvgFAVzkRSf1y0OlptDo6WqeqtBSNSuWxaX/f7wLPV8aPNOZz+zx/YnqMCzVyPAfZWmwrG1hws4fnvDwBqxdUzx2YwyVXlNbFfAgZD2yoZ/Voc4/tB8hD1PvSUPq7p84QFeE/GueYCJg9Rt8V7/Y/J36ZuBy2AE++Btn493ZRUfAkhhBBCCCG6BIfDyaoDxYztE98hgVBHe3r5PlbtL+HrnfmcO743n23Lc4dDZ47NaPuH6CANc826KnW1A36zq9DvmLYMt99wRFVODe8Vw26PFSJjw0OorLexKaucTVnlAPzxw+0sGJFKelxEo+crqba4V7187xczeGddFktcq11WW2wUVFrYU1DF1a+s9Xqeey6Tww7/ux4OLNertlJGwM0/6B/0M6fAbw+oQfeeEgdAdT78/ILri+jd0j+Ozmf2aHU8DoKvd9Zl4XBCpNlEaoz37KtQj1bHx77YTW5FPWc+8yOf3j7LHXYBVNU3kBQdxh+WbnPvmz1Erao4f3gqSzbmcP7Edngv+M6NC3OF3zNuhY2vq+2R50BMMzP+TAF+HrqDr6Gw/xu1oIPf67tCb20hh+OUVHwJIYQQQgghuoTFa7O48uW1XPvq2uYP7mLsDqd7VlB9g4N31qk2wF6x4fx+4XDuO2PEMbuWSLOa4aNVdQVasa66Da2OWqj165OHEuJqZRyYHMWm+0/hNycP9Tv+3ysOUlnf+DD9PyzdRmW9jcGp0UzsG8/D547hgbNGEh+pPuz/89u93Lp4o9/z5g5TQQV5m9UcpfoKwKCqak5+0L+6JSTMf5825ytvs7rtN6OpL71rCvVodbQGXgWzp1h9oIT7P9oBQFK02S9MNrtaHRvsDswhetxx5jM/eh334eZcaq028lxVYM9fPpEUV4h25tgMDjxyOqeNTm/7BVfl6dsn/lbfThkGc++FUYvgnOeaP0+gwfTxfdVtkmsGXqDgq8IVfMW1z6qx3ZVUfAkhhBBCCCG6hLdWq7a4ja5gpTs5WFRNtcVGRKiJ2+YP5qsd+fRJiODxC8a12+D6YEWZ1evVNziwO5zkBwi+ai2tq/iqrG9gb6Gq8prQN55nL5vI4jVHePjcMZiMBm5fMITXVx+huFr/oP7aT4d5Y/Vhfvr9AnrFhXudz2Z3sHy3qkh78qJxhJiMhJjgmpkD2FdYzeI1Wby9NhuAcZnxvHn9VGx2J4t/PsKl01wf/HNcoVj/2XD5+2ruUbASPCphUkfBqY+08E+kCzBrrY49v+JLm8cFMLV/kv5AzgZoqHO3PDbYm54v95dPd7L2UIl7kYcTh6Z4Pd7WxRrctIqvGbfB/Pu8H5v7++DPYw8QHGdOU7fRaeq2ptj78dXPw1ZX22/s8R18tbjia+XKlZx11llkZKhS3Q8//LDZ51gsFu677z769etHWFgY/fv355VXXmnN9QohhBBCCCF6qOpWhjEA6w+XklcReHi1xWanoq6Bshordoez1a/RlE3Z5QCM6RPHrfMG8/Fts3j+8knHPPQCiAzTV22rrGvwCqE0NS1c/e/FlQeZ9sg3jH1gGU4n9E+KJDUmnNNG9+LN66fRNynSfexfzhkFwIWT+tA7XoVQDidszi7zO29WaS0NdicRoSZGZ8R5PfbHM0Zy9Yx+xISF0Cchgn9dMZHY8FASo8zcvmAIydGuNrfcTeq27/SWhV7g3QI29qKWP78r0Cq+sFAS4O+6J1l/WL2HZg9J5t7Th6udDge8eR68cS7xBrVAQoPdQWWd+nlyxtjAlVtf7VDtteGhRqLMHbTSoVbxFdPG6jG71X9fmGppJjJR3daV6o9VF8FX9+r347phC287avFP4ZqaGsaNG8d1113HokWLgnrORRddREFBAS+//DKDBw8mLy8PR4BVFoQQQgghhBDHn8LKev721R5yGll1rc5q5/KXfmbKgETuXejfMrgpq4wL/rWaSLOJM8ems3B0OqN6x/LyD4f4cHMOBZV6GBAeauSCSX2oqLNxtKyW62cN4MyxGW3+Gn7cp6otJvZNaPO52spsMhJiNGBzODlSWoszQNZX04KQ0WZ38I9v9rqrY2LCQnhk0ZhGj184Jp1Pb5/FoJRo1h8p5cqXVevqkZJav2MPFKnV+QamRPlV6ESYTTx4zmgeOFsFaQFnpO1dBpsXq+2MiUF/TW7x/fTtAbNb/vyuwFXxFWawcaiwopMvpuM88+0+1rpWSH3w7FF68Flf7p7tlunIBVJU8OVqr71gYh8+26oCqNSYMAqrvMPBpKiwjpu/V+kKvmLbGnz5BJpTbtS3I1zBV61H8OXZYgnS6tjSJyxcuJCFCxcGffyXX37JihUrOHjwIImJ6i+kf//+LX1ZIYQQQgghRA9kszs485kf/T6Mevp+TyEbs8rZmFXOb08djslo4Ps9hSzfXch9Z4zgky3qQ16t1c5764/y3vqjjZ6rvsHBWz/rK63d9t9NDEmNcQ+E13y8JZeDRdXcPn9Is21P1RYby3aqlQYXjm5mSPUxYDAYiDSbqKy3cbBIVcCkx4WTHhfubiNtyaqOewuq3aHXx7fNpF9SVLOLD4zuraq3Zg9J4Y75g3l6+X4OBwy+1PUNSon2e8zz6wlo9fN6VYvBCL0nNfel+EsdDhEJYDBBr2ZW1uuqQvVqu9yikk68kI5TUdvAE1+rVQvTYsMYkBylP+jR4pfuKARSqLbY3MPsJ/VP4NZ5gzBgYGdepbu1VpPsMyC/XVW5Wh1j2hiuz7gdvrhHvccnXgXjr9Af0yq+6ivUQg9GE9T4LGjR1oqzbq7D624//vhjJk+ezN/+9jfefPNNoqKiOPvss/nLX/5CRETgMlKLxYLFov+Pr7KysqMvUwghhBBCCNEJduRWNhl6AVjterfIoeIaosNCuObVdQCkx0Xw1ho1G2zRhN5EmE18s6uAwioLTidEh4Vw8ZRMbp8/mAiziXWHynh82R5251VicX0w/usXu3jmsoms3FvEzEHJWOx27nhbtc/lV9RTbbGxO7+KW+YOYtFE/8qJr3fmU9/gYGBKFGP7xPk93hmiw9QKi4eKVUVVWmw47/5iBg9/tovXfjpMbRDD7UuqLezIrXSfY+bgJMb2iW/xtfRNUiHFkZIaquobuPv9LSRGmfnVgqHsL2w++ArIboOVj6vt4WfChCsgJq3F10ZYDNyyBowhYOqmI7BDwnAajBicDopKSmmwO9yrG/YUZbV6q9+r10z1DkNr9eArzZEPjKKkWh1vMEC0OYR7TlVtkXe+s8nv3CnRZr997aIiR5/x1daKryk3qNArbRSEes/JI0KrMnVCXTlEJUG1R/AVGhl4VcjjSId/Zx88eJAff/yR8PBwli5dSnFxMbfccgslJSW8+uqrAZ/z6KOP8uCDD3b0pQkhhBBCCCE62brDpQH32+wO96DqIo9gbHd+Jav261Utj325G4CYcNV+Fx5q4uHzxlBcbaG63kZ/z8oQYNaQZGYNScZmd/DzwVKueHkN3+0pYvSfvgLgkimZpMXqHyzfWZft3n78qz0M7xXLiPQYrw/e2tyhk0ekdUzLVHUh7P0Khp2uPtRqqvIhPN7/gzAQ6ZotdrBIC77CCDUZSXcNl2+u4mtLdjmX/Odnr2HpEzJb18bZ3zX/60hJLV/tKHDPVmqwO9mZq4ocBqVGNfr8gI78qGYaRSbBha+3LbRqTWDWlRgMEBoF1irMznqOlNQyOLWFQWIXV1Gn2hYz4sIZmRHr/aBHxVeKTVVeltSonxkxYSFeLbSBvj+Tojqo4uujW9Rsrl5jIa5v285lNEKfRioaTaEQFguWSvU94Rl8xWXClR+27bV7gA6PgR0OBwaDgcWLFzN16lROP/10nnzySV5//XXq6gL38N97771UVFS4/8vOzg54nBBCCCGEEKJ7ayz4qvGoSPKsCLvtv5t4e22W3/GvXTuV8FB9QHVydJhf6OUpxGRk5uAkbpg1gNhwPTR5Z102L6w4AMDA5CjMIUZ6uYKwvIp6Tn/6Bz7Y4N1KuS1HzRdqTTVUs0oOwPMz4OPb4Lkp6j5A0R74xyh451ICDfHShnXvylfBkhbmaYHYko05/HdNFl/vLKDaYqPWasPpcZ7Xfzrst0LgpH6tC776uSq+civq3K2XAMt3F7IzrxKjAaYNSGrs6YHt+lTdDj+z+1ZqtSODWYWLkVjc7aM9iTavKzZQi21tgODLVfHle3yg2XbJMR1Q8WWthUM/qO3zX1LBVUfSqr60OV9a8DXqPEge3LGv3Q10ePCVnp5O7969iYvTS35HjBiB0+nk6NHAvfdhYWHExsZ6/SeEEEIIIYToWZxOJxuOqGqpEwZ5Bx/VHhVJhZX1TZ7nvAm9WxXKGAwG/njmSL65aw5XTNcrMqw2BwuGp/L1XXPY9H8ns/K38zh7nD6jxzP4stjs7MpT4VKHtDluXqx/sK8tgbUvqu1dn4DDBgeWw5Gf/J4Wafau+NL+fDxXr/vD0m3c+MZ6Rv/pK0be/xVzHv+e4moLVpuDb3YV+J1z5uDkVn0JydFmwkONOJ2w9pAedJbWWN3nTWnpnKUiVelHv5mtuqYex2Nlx0pXdVRJtYXLXvyZ99Z1/0ISreIrYPBVo1eAJjWoeX/u4CvcJ/gKUOnoHpLfngq2g9MOUamQPLT9z+9Lm/P1yilQvB+qXd+/0akd/9rdQIcHXzNnziQ3N5fqaj113rt3L0ajkT59ju+VBYQQQgghhDie5VfWU1xtxWQ08NQl45k2INH9WHW9R/AVYAbYZdP0oGpcGwOn1NhwHjp3DMM9Btw/dcl4TEYDUWEhmEOM/OqkIQxLU49vzCqjylWBsie/iga7k4TIUPokBJ5h3CZFe9TtgDnqds0LquqrYLt+zM/Pg82iV4MBUWF6wDUgOYozxqS79jdeHZVVWst9S7dx9/tbqKy3kRwdRoyrGm7+8FTMIT4fH51OtWpdoGUjPRgMBnewtTm73O/x08e0Yv5RuavqL6Ff08cdL1wrO0YaLNS7Ztf97cs9/HSghN/+b2tnXlm70IKvgIsqeFR8xTcUYMThbnWMjfB+vw9L8y+q6ZDgK9c1SyxjgmpF7WgR+s9Ovr5fH24f3c3beNtJi4Ov6upqNm/ezObNmwE4dOgQmzdvJitL/eC59957ueqqq9zHX3bZZSQlJXHttdeyc+dOVq5cyT333MN1113X6HB7IYQQQgghRM+3I0dVSg1JjSY1Rg1f75uoKleqLQ3u4wpcFV//vWEaWx84hUfOG8O9C4dz5fR+jOkdx6JJ7fML9f87cyQj02N5+8bpxPhUigxKiearX5/IwOQoGuxOd0XU3gL1C/4R6bEdM9+rWK1kx/Rfgtk1t+mZibBjqX7M7k/h2clq//9uAKfTXfEFMG9YqnteWpTH/rtPGcraPyzgkfPGsGhCbwC+2lHAx1vUQO4rpvflreuncf7EPvz1/DHe12W3qdd6cjhsebvZL0MLF2wO/5BsxsAWtDk6HLDzYyhXCxoQ38bZST1FqN7qaGmwU15r5cf9eiCkrXDYXVXWqSDct4IL8JrxZcJOOiWU1ASu+Lrz5CFc6PPzIqkjhttrwVfvie1/7kDMHm3dlkq91TEq5di8fhfX4uBr/fr1TJgwgQkTJgBw1113MWHCBO6//34A8vLy3CEYQHR0NF9//TXl5eVMnjyZyy+/nLPOOounn366nb4EIYQQQgghRHe0PVfNxvIcVh3tqkiqDjDjKzU2nNjwUC6b1peY8FD+cu5oPrl9VuAPw60wc3Ayn/9qNjMGNR7EnDNeBUS/fncL76zNIqu0FtDnWLUrewOUHlTbvcbC3N83fqxWAbXtfcj62aviKyNeH34f6bF/fGYCqbHhXDatL+f7hAGDUqK4ec4gxmXG88RF40iN8Rig73TC57+B7R+o+1vfhaPrYffnjV5eU1U1/VzD74Py83Pw3pVq2xgK0b2Cf25PZvZoday3Mftv35FTrs/UPlJS01lX1i6CrfgC6GsspLw2cGtkbHgojyzyDnFTOqLiS2vFTRvd/ucOxKPak+g0PfiSii+gFas6zp0712vooa/XXnvNb9/w4cP5+uuvW/pSQgghhBBCiB5su6via3SG3qoY7Wqt01od66x2qlzbabEdtPpaC1wyNZNnlu/D5nDy+yXb3G2WWqVauyo9qOZ4maMhNgNOuF2t7PjcNHA0wNiL1XFb31W3iQPVc8qPEGke6z5N73i908bkUZXmGThO7KvPSPvbBWM5fUy612IBXg6thA2v6fcPr4KXTwanA877N4y7xO8pnsFXeKgRhwOsdlWFFHSlnKUKlv1Rvx+b0fFDw7uLUL3VMa+8zv09E08VFUSxv7CaIWkxTZ2hS9OG2wcMvrQZX8ZQcDTQx1DkfihQKB5qMmIOMbqr4Dqk1bFKDdknrnf7nzuQvtOhcIfari5QqzsCxEgwDMdgxpcQQgghhBBC+Kqoa2CVqxVrosdger3iS33Q3V+oWgnjI0Pdj3WmtNhwfnPKMPf9LUdV1VqHBF/afK/kIfqcoKRBcP0yuOpjFTLN/T2MuRBuWgGZ09UxFUe9ZnmlewRfQ9KiSY42My4znsQovcUrwmziucsm8sczRnDhpD5N/1lnr1W3oxZBZLIK4ZyuVrrPfwsN/osRpHi0k/VLjOLfV00iOTqMxTdMC+7PojIPHvVpaa0rD+65xwN3xVc95a7qqNGGg2wO/wX/Cn3K/X3UXenD7QO8L+vUAhn0UtVVmYZC90Oe1Y6etEUeTEZD4DCtLRx2fbh8TCvm17XGvPug9yS1XbhL3ZrC9NUej3Od/38OIYQQQgghxHFnycaj1DXYGZYW4zWcXgtc8irq2ZhVxu68KgDG9I7rmBlarfDLuYMoq7Xyn5UH3fta1K4XrGIt+Brmvd9zblDiQDj/JbWtVZdU5hAWpdc4eLU6mkP44bfz/QfVA2eMDfJDutbGlT4WIuJh/Ssw4zbY+p4aqp27Efqd4PWUZI9VG4enxzBvWCrr/3iS93lX/VNVytgsMP4y6DNZf2z3p/7XERYd3PUeD+JUKDjaeJhtrja/m8O/BiecalrPx/lVnXl1bVbZVKuj1RXqpY2C3E1kuiq+oswmLmhk/l9UWAhltQ0kRZkxGlv4c8XpVMFWY9VUNUUqCDYYj92MragkOPUReOVUvfUzNv3YDNbvBqTiSwghhBBCCHHMLd+tqjIunpLpFWhprY5PfbOPRc//xL9WqNk1ozLatnJjexufGe91P7M9Kr6std6zeopcg+1Thgb3/FhX8FWR4251A0iO8m7lijCbMLX0w74nLfhKGQGnPQZ3bIZTH4Z+M9T+Iz+p+WT7v1W3eM9RGpHuv7IeRXvUanQ/Pw/rX4blf/F+fP+36nbwyXDxYkgeCotebP3X0NMMORWA+cZNVNWquXMGo96quv5IaZMji7oam917GL8WfAWc52d1zS9LHQXgDr7OndCb+MjAg+u1gL1VbY4//gOeGAbb/xf48ao814ukgbGRduGO4FvdFZNx7F67i5PgSwghhBBCCHHMHXC1Xo3L9A60fFvstOHxY3p3reDLcyZWbHhI+7RLfXSrWplxnauCq7GKr8a4qn6ozKGizure3eKKlqbYbVC8T22nDIMQMyQOUPf7uqq8lv8Fnp4Iby2Cz+8Bh53kaP3PJ2DwVbjT+37+dn3bZlFzxQAW3A8jzoTb1kH/me30RfUAmVOpD00gzlBLv5ptABg9AuWCSgvZpXWNPbtL2Z1fydgHl/H0t/vc+ypdQW5cpM/3mc2qWm0BkgYDkIpqfWwqLNdagVu1ouPuz9Tt0fWBH9fmex3r+Vq+wVfsMWqz7AYk+BJCCCGEEEIcUzUWG7kVag7UoBTvdrXGKqe6WvDVKy6cJy4cx4yBSdyxYEjbT+hwwI4lavuz30Dxfu+AKRixeqvjSSPUam59EiKaeEIrlB4EuwVCIiC+n/dj/Wfp2xWuVSY3vQkvzmfiu5NJRC1mMCI9wJB1rbpt6EJ1W1usKuAAcjZCQ41qG+s1xv+5AowmyuJGABBrVfOljD7VRmsPlx7zy2qNx77YTa3VzpNf73Xvq2is4qvBY7XKiHgAQgxqRdihaY23wka6Zny1eEVHay3kbVbblbmBj9Eqvo7VfC+NX8WXBF8aCb6EEEIIIcTxqRu1/XQ19Q12vtye515prTFOp9OvZQngYJH6sJocbfZrRbpoch8GJkd57eufFElmYjsHOO3g/El9ePum6dwwe2DbT1Z60Pv+T09DQ61aqS5hQHDn0GZ81ZUxf1A07/1iBp/cNqvp57TU+lfUbZ/J/isq9hrt337osEHeZkz1ZVyYksW8YSmkxgQYOF7sCjn6TtM/wJceUBVm2nyvfjNlZlETnCHqz9XksABg8Pn72VvQPeZ8+f5kttoclNWqCka/Ci2tzdFkhlAVmoeigq8hqY2vYuludYxpJvhyOmHxRfDamaptN3ejek+DHnD56qyKL1MomD2+Zgm+3GS4vRBCCCGEOP5Ya+GNc8BuhRu+UR8YRFDqG+xc8dIa1h8p4+LJmTx2wVivx51OJxuzyjhaVsfn2/L4YV8xH982i8GpevXF/iL1AXxgin9FRliIifdvnsHSTTk89JlanWx8ZnyXGWzfYXI2eN/f+Lq6TRsJpiA/toXHQVgcWCowlGczdcDw9r3GQz+o+VsAs+8KfMzYi+CbB6Ayx++h35+YgmHKVP/nrHsJtn+gtpOHqZa1o+vgXz6hXf92DvF6GlfwFYYKpI1ewZeTOqu9Ey6q5UJ8AruCynqcTjCbjCRFNRJ8maPcP8dDXMGXX1ukh/Q4FaQ3uyhFZQ7s+0ptZ6+BrNUejzVS8aXt74zgKTIBrK6AU1od3aTiSwghhBBC9FyNVXV9+2c4ula1rBRsD3yMCOirHfmsP6Jm6Ly3Idvrw3RFbQO3LN7I+S+s5lfvbOarHQXUWu18vs27MmK3a4U53zZHTVJ0GDfMHsigFFX5denUvh3xpRx7DXVqdlWg96X2gXrsJarKSzP9lpa9RoKr/bDscKsusVE1xfDO5SosHn4mDJzX+LETr1a3KSPUsS6GqgBBgdMJy/5Pv58yDMICzAAD6D+7FRd+/DCEegdfJpP+cd+MjfqG7hJ86SG3xWYnz9UW3Ssu3D8A14Kv0CgwqoA4BHuzM/fuWDCYZy+bwPkTA6/66Fa4W98+8B1krdHvV+WpFmVf2v9TEtuhErSlyrP07aR2aMHuIaTiSwghhBBC9EwNdfDyyepD9DWf6S1S1hrY8Kp+XO5myJjQKZfYHR0t0wdkO53w+yVbOXlkGn0TI7n1vxvJLq0jxGggPNREtUW1BG3LqXA/p8Hu4KNNKgCZNiCxydd664Zp5JbXM6lfQpPHdRuf3Q2b31IfSMdfCrPuUu/L8mzY/F91zNgLYcjJaih80iAYfUHLXiNxAORvhbJD7XvtK/8Olgo1Y+v8l5tuOZz9G4hOUSswRqeqr2Xj64ErZOorVEsnQPo4SOgPQ0+FA65VHBMGwJBTVOVbajtXsPUwBlfFVzhWQrER4vF3FI4Fiy1ASNMFOT2aHUtrrORVqJ856XEBWmQDVHxFhjj4+lcnNvka8ZFmzhwbxKqHRR7B176voMwjWHLYoKYIYtK8rydvq9rOnNb8+dvbkFPVdfadAeljmz/+OCHBlxBCCCGE6Jm2vAP5anUzSg+qEAHUb+1t9fpx2qBiEZTCSvVnFxZixGJz8NHmXD7arAcamYkRPHfZRIb3iuXDzTn89oOtbMoqx+l0YjAY+HZXAfmV9SRHm1k4pukZOOlxEe6WpB5Bm1VVsk9VHQ45RQVJa/6lBsb3mwWDFqhQafT54HSAz4DyZiX0V7ftXfG1Y6m6nX8/hAYIIDyZQmDydfr9vjNcwZd/+yMVR9VtZBLctEJ97ZOugbhMGDQPQnvQ338H0yq+ogz1rAi7k4xKfZh9BNZuU/GlDbIHKKm2uiu+MuIDvBe00NQc5a6UNDkaSI1t5j0arKJd+rb2/xNztHpf1hRBVa538JWzAZx2iMnQV1k9lk75Cww40fv7T0iroxBCCCGE6KHWvaRv52zUt/d8rm5jXL/tz918zC6pJyioVIOz/3D6CB47fwwnDk1hdO9YjAbIiAvnnZtmMLZPPOYQI2ePyyDEaKC42uJub9yZq1b2O3lkGmEhLQx1Wuq9q+D5GVBT0rGvEwy7DazV3vuOrldlczs/Vven36xXUhkMLQ+9QA++Stux4stug2q1UiAZ41v+/FjX91qgiq+KbHUb10f/2kPCYPjpEnq1kNGswp4hhqNkGLxXcIwwWKjvwhVfTo/234o6m3v7QFE1eeVNVXy5vqfMUWrAPajAOFALYmsU7VG3ngtM9J2uh1q+7+nsta5jpnXOQgwpw+CE28DczOyy44wEX0IIIYTompbeDE8MV3NlhGgpS7X37K5cj+DryE/q9sS71W3hTrBZj921dXMFVar6Ii02nIun9OWN66by6e2z2frAqSy/ey69PaoywkNNzBmaAsCd72ymvsFOUbUKznrFdnCoUZkLOz9Sf79f3KP2VRfB6uc65+dK+RHVGhUSAbN+rfblboS8LVCRpVakG7Sg7a+jfUBvz4qvmkLACQYTRCa3/PmxrtUmK3JU0Kf9B3rFV1xmu1zq8czkCgq14e6eumrFl8Ph5O73tzDpoW/IcQVcFbX6z+NfvbOZ11cfASA9UMWXV6ujR0Obo+kVZ4OmBciL/gNTb4Jpv4TTH9cD5gPfQdFe/fjCneo2fXz7vL5oFxJ8CSGEEKLrcdhhy9tqcOzGNzr7akR3VHrA+762Yl5duT77aNR5EB6vhnV7trOIJhW6Kr7SYsO89keHhRAe6l+h9OiiMSRHm9lTUMUzy/e5n58SE+Z3bLvZ/y08OUK/v/1/sPFNeHo8fPUHWPG3jnvtxhTvU7dJg6HPFLV95CdY9ZTaHnJy+1RpJHoEX9batp8P1M9igJheYGzFR0it4quhRgV9j2bC166B9p4VX6JNTGa91dFXBBYsnRB8lVRbeH99dqMrSr7202E+2HCU0hor6w6pKjXPVkdP6YHaF63+rY4A2Nsh+HI6oU4t5EFcHxV4LfyrGlqvzYVc9yK8cAIc3QC1pXqFWMqwtr++aDcSfAkhhBCi6/GsVGhsuXAhmlKyX91qy8lnr1EfuLUZLfF9ITJRDdMGyN107K+xm9hwpJS/fbmb7NJaHA4nhR4VX8FIjQ3noXNHA/DSD4fcVR2pHRV8OZ3wYYCVED++TW+L2rcMCnfB7s8bX/mzvZW4gq/kwdB7kmvffn121sxftc/rxPVV1Sh2C+z6uH3OWZWvbmOansnWKHOkvlLj2v+AtQp+eka1oErFV7sJCVPBaSz+gWe4wdopw+1v++8m7vlgK7f9dyMr9xZ5tTQCrNhb5N4urrbQYHdQ00hIFnCRC+17OjTSPdweaJ+KL0uVmtcF6pcknjImer/WS/PhjXP0gDt5aNtfX7QbCb6EEEII0fUUelTfSCAhWqPYFXwNWgBjLlTb3z0Ch39U21rgpc0r+uRXsOz/jukldgcOh5Pb/7uJ578/wCn/WMnB4hoa7OqDa0sqtk4d1YuY8BAsNod71leHVHw5nbDpTajO1/dlTte3Eweq27LD8PpZ8M6lahGEjlZTAhteV9vJw1SAdOZTrgDMAGMv0cOwtjIaYfwVanvz4vY5p7viK73154hwhRbVhfq+LW/rv+iI6936cwsAQsyqFTDG4B98RWDplFbH1QfVfL1vdxdy1StrefGHg16PF1ZZ3NvF1dZGq70eO38MCVFm/wfcrY7RYPRodWyPiq/6cnVrCvOfNxdo1l3+VhU4m8L0VkjRJUjwJYQQQoiux2sVpa1gszR+rBCBaBVfSYNgzu/U9t4vYcVf1bYWfGm3AD89Dfu+OXbX2A2sPlhCrmtFtboGO19uVwFIcrSZUFPwHyUMBgMj02O99qXGtiH4yt+uVkWsr/TZ9yB8fLvrBUbCha/BSX/Sj7lumWsGllOtyAaq9dHRwYHApjdUxVdsH5h0tdo3+Vq4cTnclw/n/at9X2/IyerWc/ZQa9msba/4ArVqI0DBDn3fgW8hb6va7jW29ecWAISGqXAmUMWXmvHV+cPtH/l8N5X1eihVVKW3ZRZXWyivVY9FmU28c9N0tj5wCl/deSIXT+kb+ISeqzoaDHr41R7BV125uo2I9x9UHxajB+m+kga3bmEK0WFCmj9ECCGEEOIY86z4sltVK0zSoM67HtH9FLs+8CcPcf03DIpds1d6T4YpN6rtQfNVQKINJN6xBIacdOyvt4v6dGuuz30VfGUmtnwW1aiMONYc0leaS4pqZfBVtBf+M0cNirdZ4NSHoXA3/GumfowxBM56GjKnqCqw0/+uKjCiU6DfCfqcN4C6UjVnqiMrNLSqpglX6POuNKHBtYy2SLgrZNTawCpyVMg07jLvAeDNWfk4fP+Y/iG+TcFXorqt8nhPHViubmN7Nx4iiKAZXe+lCIP/Yh1qVcdjW/Hl29ao2Ztfxeurj3D66F6U1OjXWlxtoaJO3U+MNjN9oApLY3uFBjwP4LGqo+tnksmsfja0R6ujNt/Lt81Rc+WHsP4VfU6fJnVEoKNFJ5KKLyGEEEJ0LU4nZK/z3idzvkRLWGv1FR3T1GwpprqCrt6T4Lqv1G/wQbVf3bJaBSOgZroIt70F6kPlkNRoAHeb4tT+iS0+18gMveIrITIUc0grP4r8/Jz6YAvqQ2d9BeRt1h/PmAB/LFKhF6hKjak36lVQQ07xP2dtSeuuJVjazzDf0KujmGPUrbUaHA747DeqEu7TO4M/x4HvYPlDKkCwuapy2tLqqFV8BdJ/ln9FjWi5kMZD1PBOWNWxss4WcP/jX+3hky25/HLxRq8Re8XVFo6UqAqu9LggV331bHUEfcC9PfBrt4jW6hgRYLYYQEI/mHGb//5hC9v+2qJdSfAlhBBCiK6l9CBUZKl/vGozb7T5MkIEI2e9CkZi0vUqnsnXw8VvwZVLA1e8aB+atA9RAoCsUvUhdP7wVK/9U1oRfE3pr394LKttQzVG1hp9u6EW9n2tfm4ARKfBFUuaXnlw8AL/fbWl/vvaU6XrZ9gxC76i9O2GWtj7hdre9KaqYtFauJqSvcZ/X1tWXmwq+Op3QuvPK3QhjVdRRmDBYnM0WoXVEfIq6wLu35FbGXB/UZXFHbYPTYsO7kWqCtSt9p7Xfr47GlSL7tb3gw/Bsn6G8mz9vlbxpf2iJJDoFLjsfcicpu8bempwryeOGQm+hBBCCNG1HPxO3WZOU3MyQIIv0TJHVqvbvjP0KhKjEUacBeFxgZ+jtck0+M/GOV7VWm0UuQZPt0fw1S8pil8tGALA2eNaGAA5nWqm17qX9RmAI89Rt3mb9eBrxq16S11jwmJg3KVgMEGE69gOr/jKUbfHKvgKjQCD66OetRqiPP7+HusPfxuoZnd5Oroe1vxHX+WyIhs/ycNaf00RTfy99J7c+vMKXRMVXxFYcTrBaj92c77yyusD7q+2eAdRydEqsCuptrK3QFWVDk2Laf4FNv8Xsn5S21rw5a74aoD3roIlN8CPTzZ/rvzt8Mqp8NRofZ8WEDfW6qgZegoselH9/2XazepnjOhSZMaXEEIIIbqGujL48g+w5b/q/uD5qoUJVLWE0ymtMCI42T+r25ZUkWgfmrR5MW1lrVWzZloyT6mLyS5V1RpxEaGMy4wnPNRIfYODS6f2JS6yiZk7Tfj1yUM5eWQa/ZJaOCMsey388IR+P3EgDD4Jdn4EuZv1wDJhQHDnO+ufcNKDsOw+2PY+1BS37HpaoqFezRGDtrUKtoTBoKoYLZWqfVerXNE47Wq4v7aSYuEueMlVCdd7IvSZrOaCeTKGts+ML3CFcgZ1HQApw1t/XqFrYl6cNvervsFBWEjHDF5ftb+YIyW1XDZNDaLPcy2M0Schgium92NvQRVLNub4PW9Eegw/7LNgczhZd1h9rwxJDSI82v2Zvt1/tro1eQRfWtXiqqdhzm+bPpdnhaP27w13xVcjrY6eEvrB7440f5zoFFLxJYQQQoiuYd3LeuiVOgqm3AAxruqIja/D44PVoGUhGlNbqubDaTPi+rSgiiRUC77aodXx6/vhr5nw3NT2WVmsk2htjn0TIwkPNfHy1VP495WTeOS80c08s2mje8cRE97C4My3+mjAHEgfr7YP/wA5G9R2sAPSQ8IgJk1vv+vIii+tYjUkPLgP0O1Fa98tPxJ40LfNoxpn+UP6traCY8VR7+NDwtv2ywfP4Cs6TQ+9oFsHxF1KUxVfBlW9aemgOV9Op5M73t7EH5Zu41Cx+jmaX6HC8xOHpnDznEGkxgS+vt7xEcRFqJ8JVfWqGiyoVketIuuCVyAqWW1rwZfne97qMbsxd5N/EAzeqzBaXK2Y7hlf8c1fC6jvD/kFXZckwZcQQgghOlfxPijeDwe/V/dTR8E1n6qWgVhXdURDLdQWw9qXOu0yRSdyOGDti3B4VePH5GyAJ4bDyyepDzkms3ovBctd8dUOrY7rX1MzxkoPQNHutp+vkxwpUR9e+7qqs2YOTubUUb0wdMYHu0qPKpFeY2DB/WrlNJPPTKPEICu+NO7gq4Mqvqw1ehtmbMax/VAc5goOivcHftxaAyUH4I1zYPen+n5Lpap48Qu+zG27Hs8ZX5lT1YqqoFfqiLZrIviKNqggqL6hY1ody2sb3Cs05parwKvYdT/F1cqYGBU48B7bJ56kaP39FRMeQlJ0EKu+apWUnm20nq2ORo9AtbZUrSL6n7nw7pX+5/L8pUd1oev85eq2uVZH0eVJtC6EEEKIzmOthX/PgQaPf3Be9IZeGeDbFmRuYXuU6BlWP6OqqMLi4HeHAw8u37EU7Bb9fuLAln1QN7dTxZfDDpYK/X7+NhXUdENa1Ua/xBZ839UUqxUE+0xR87baK+jR2u5GnguL/qMP8Z75K9ixRFUp9Z/lPdQ9GO7gqx2H2zvsqpqqoR6enw41rg/Rsb3b7zWCof1ZlOwL/Li1Bj67C476rKJbX6EqYmyuweSmMPW9pQVVreUZTgw7AwbMho1vwuRr23ZeoWtiuH2cUYX69baOqfjSKkQB92zAkmp1m+wKteIj9Z/JkWYTT108ntTYcMb1ieN/G48CNa7jgwi9IHArolfFl8fPn2//DAU71PbhH/zPVVOkbx/5CcJiYeeH/ucX3ZIEX0IIIYToPBXZ3qFXbG9IGqTfj+/rfXxD4BWiRA/25R/g5+fUtqUC8rdAxgT/4w6t9L4fmdyy19FCgoaats2Tq6/wvp+/rXXn6QJ256v2oGG9WjCo+Yvfqg+LOz9U89JOuAMqcyF5cNsuRqv46j/L+8P9/PvUf639O+uIVselN6u5YXisnhcaCTPvbL/XCIbW6riukUpZreLLV32l3loalapWQt30Fpx4T9uux3M+2JCT1S845v6ubecU3pqo+Mo0qADW0kEVX0cCBl+q4ksLshI9gq/RGXGcMkp/TyR4PJYYFcQvLZxOPbD2DKa0Kq+6cu92xw2vNn0+zzl/n9zh/VhbVjMVXYK0OgohhBCi8/jO7Zn2C+8PrzG94JznYMGf1H1LFeI4Yq3VQy/N3q/UB55936gV6Bx2KDsCeVvU46f/HeL7wSl/btlracGX0+E9+6ilfGfHdNPgy+l0sscVfA3vFRvck4r3wfb/6fd//Ae8tQienaTPXWst7WdFYx9AWxtUanOB2mu4fd5W2PYeXqHX6PPh9o0w5KT2eY1gmX1mJPmuyGitUoGcr/oKKNf+vHtDr9Gw8K8QleR/bEtEJcOFr8Hl/2t+5U3ROk1UfPV15gHOjqv4KtF/iVXkqvTSWh+1tsUEj0Br1hDvX054tkEGFXw11OlVvp7vJ63iS2tXNJkhc3rz52ss/B61qGULpYguSYIvIYQQQnQezxkyw8+EGbf5HzPhCph4ldq2VqugQxwfyg6p25BwFWgBfP8oPD0eFp8PX9wDPz2jZhQBpI2GqTfCnVuh96SWvZZnANCWdkff4KtwZ+vP1YmOltVRbbERajIwMCWI9sHdn8OHv1TbfU9Q/9nqIWu12rd5cXAvXF0Ib1+mgk1PWqtje7cLahVfJfvg+7+6VohsQ/C57kV1G9dXLZhgjoGFj+vzCo+lMJ/ga8jJ3vfryqE63/95lgo1nw6CXywgWKPOO/YB4PGksYovg5EI6kmlnPoOGm5/pMS/4qvYdZvkbnXUw62Zg72DL89QLCmY4Ev7WWsM8Q55Ta7nVheo24hEFd76stu87zcWfk+7WQbW9wASfAkhhBCi82jB1+Tr4JLF3qsqeQrzaLWSqq/jh9aGlTYKxl8G/Wap+2WH9WO++ZMKyKJS4bx/t/61jCYIiVDb7RF8RbtaeGpL1XD+bkZrcxycGkOoqZmPDPnb4J1L9VlRvSfCSX/yPibQKmqe1r8Kq56Gj2+HPZ+pYFPTUK8Pn2/vlqP4vmBw/dz5/lH4zxz48cnWny9/u7o99WG49We4+Ye2V0q1lmcYMPFqmHef9+MFO9QiDBqthbhwt76QRFIbW1TFsWUK1d/PnuL7ATDAkN9hw+19Wx3rG+xUWdT7KzlKVXxlxEUQZTYRajIwrk+c1/M92yATggq+PNocPYMprdVRm60XkaD+H+LLWu19v7EFLjxbdEW3JcGXEEIIITqPFnw192E2JExfvU1bZlz0fCWu1egSB6lWxGs+has+glMfgV+uhug0/dgJVwT+rX5LtMeAe20VsIR+rh1O1VLWzezOU99nI5qb77XhdfjXLO99vSdB3+lqgLmmYHvj5ziwHD69E77+P9j7pf/j2vsgLK79h0ybo+A3e7z3rXhM3RbuUrPjGurgfzfClnebP5+2gmPSIBWqtXSVyfbkOeh/yCn+i4No7cGpI+EXP8D0W9T9nPWw7yu1nTgI0c0EqvpyBZgDjHkdVvGV7RN8lbraHEOMBmIjVBgVYTax/O65/HzvAkJ8AvVWV3xF+LTNulsdXcPqIxIgLcACI76/RKtppNVRgq8eQYIvIYQQQnQe9xyZzOaP1aq+pOKrZ6uvVLO7akv1dittwQODAQbOVasFpo2EUx7SnzfqvLa/thYMtEfFV0wvPaz1HXjflAPL4adn1RyzTrS7IMjB9tve99/Xe6K6Pf9FNaMPVHhVmRv4HF//KfB+jbYSW9qojmk5ik5R7ytN8jD15//SSfD6WfD53Wpu19Kb1Ny5xtSWQn252k7oxMBL41kpG+/6GXvSA/o+LYxMHgLpYyHcuwIHkIqv7shzztfYS+Cu3e4Atq+hEIut/Su+6hvs5FfqLcJF1Rb3YPukaDMGj+/btNhw98wvT4ktHW4faEVHAKMWfLlaHSMTIXWE/rjWCqn9W6KuDIr26Kvx+s7Ga2Jumug+JPgSQgghROf4/B448qPaDqZ9Kdw1YLteKr56tI9vU7O7PrsLSlzVM41VnYy5UK00N/tu6BXgN/otpX3g0VZ2/OA6ePfKls2V8/wwFhGvtlsSfL15Hiy7T5+N1Um0iq/h6c0Mtq9xVVVcsQRGXwDjr3C3VWGOUpV4WtvnM5PB4tNeVJ4N+VtVe1aczyquWvinBTSB2pXaizZHECA0Aqry9VaoTW/pj+3+rPFzaK25MRn+1VWdwbPlTfvlwqxfw+zfqO0GV4inrZ4bMPhq5xlfouN5Vnz1nabmy7lmGIbRwN3vb6HMVY3VXo6W1eJ0quougNIaqzsIS4oKLjjyrPgKqtUx0IqOACZXq6M23D4iXs27+8UP8IuVEJuh9mvf3+9eCc9NVdsh4fB7n0V3RI8gwZcQQgghjj2nE7a+p99PGd78c6Tiq+c78hPs/Eht71gKeZvVdsqwwMcbDDD/j7Dg/9qnEijUo+KrtlStULjrY9j3dfDn8Ay+tCAh2ODLs9JM+1DXCeob7BwqVtfSbKujFnzF9IILXoZzn/P/uzjDtTBBQw0cWuH92MHv1G2fyXqlmEb7YOpZ8dVRRi2CmXeq7foKKNwR+LhdHzV+Ds82x65Aqz4D73DA7LNYgRZUhgUIOdu7tVR0PM8KJa3q1NX+Z0KF+Mt2BljUoJV251dy5jPql1iDU6Pd3/578lV4rg22b05ia1sdfVcIdQ+3d32N2ns4fSykj9P/LfHeVWoV1sM/6M8deQ4YJSLpieRvVQghhBDHXlW+/qHsV1uCW9pe+1DWkhlfNissvhBW/r3Flyg6wernvO831EJkslqt8Vhwz/iq9R7GvuHV4M+hva/D41sefJUd0be1OTWdYF9BNQ6n+iCaEtNEtYbDrgd0USmNHzfiLJh6k9re77Fa4+FVapg9wMB5MOUG7+fVFKuFAfK3qfsd+T4wGGDcJWrbUgkFjazGqVV1BdJRKyG2lt2jqsczjPRt5dKqwTwrvqJS1Dw90f14/v9UC8Fc7X8j0tQCHpuzy9vt5f64dLt7YP6A5ChiwlTF1bKdqtVwdO8AlYQBJHis+BgTHsTPPy109/33g9bq6HS1dPpWDGv/lqjKg3/P9n5s8nVBXavofiT4EkIIIcSxp1VTJA+FhP7BPac1wdeez2DfMlj+lxZdnugE5dmw53O1fbpHUDl4wbH7Dbw7+Kr2Dr4OrQx+5lZbKr7KPYIv3xXHOkBWSS2/emcTO3O9v6cOlahqr8Ep0V6zefzUlgJOwOA/YNrX4JPU7b5vwGZRqzh++mv98RFnwoDZcONyvVVrz+dqcH5NIZhjOrbiC7z/vgpdwVeoT8ti2ZHG3wvaio6NVSgeazNuUwtAzL3Xe79fxZfW6uhR8TXvPu+5Z6L7iEnXt7Xgy9X+1ztG3W7KKg/qVKU1Vm5/exNrDzVegZpbXufeDgsxEucKsLYeVT/3ThzSRCjuITY8lAHJUfSKDadPQkQQF3dI3fr+G0JrddT0O8H7vm/wqznzH5A5TW1r1Z9zftf8dYhuIaT5Q4QQQggh2lnhLnWbOjL457RmxleD/g9y6sr1mUuic5QcgNfPhjEXqCHbnqHKtvfVb+j7z1aVP5sXQ+4mGHb6sbs+z1UdPdvEGlwVYMFUJrrnzsS3ouLrsL7dlgH7Qbr9nU1syS7nu92FbH3gVBwOFegUVVkASI1tZjZPjceqab4fNn31nwUGI1RkwTcPws8e1X1XfqjPaOs9SbU+522Gr/6gHzPuko6fm6WF6w6bqkYDOOtp9d5MGgQ/v6DaNWuK1UB8X/lb1W36+I69zmAl9FMrVvqGl37Bl6viyzMQiEru2GsTHUebYQV6iOyqgkqKUL9E2FtQxa2LNxJiarpF/JMtuTic6vbwX88IeEyEWZ8lN31gEvuLqslG/b83ymxiUr/g2mWNRgNf3XkiDqeTUFMQv+zQWot9KyyNHtVikUnqF2yewgK0b0+61rvaa/7/wahzodfYoK5ddH0SfAkhhBDi2NPaiFoSfLVmxpfnIO3yLAm+OtvGN6DyKKx6SgUJngPFty9Rt2MuVB/UL30HsteqNrljxTP48qz4Aqg42nzw5XCo1cFAVSG0pdXRdwh8B9jianeqrLfhdDq55D8/k1tRx/zhqQBNtzmCHnw11eaoMUepFQKL93qHXsZQ/8qiQKGL1irZkcxRaiC8064COmMIDDkJxl6oHt/5EVTmwN8Hw00rIGO8/tyaEqhwDcVuj4UW2kugij3PgCsiQf/ZajDAgBPVohKD5h+b6xPtz7PiS5t3ZVQf+yNMDgamRHGwqIbPtuW16LROp9OvAtTpdJJXoYbY3zxnEBdM6sMnW/XVW0ekx2IOCb5it9lj7Q2uRRucUOaq+PINvjzbxDOn+38PhAWo+PL9t4gpBDImBHXNonuQ4EsIIYQQx57WRpTWkuCrFa2O2nLmoIKvdPntbYez1sCqf6oAK3mI92OeQ+K//YtaBdAcqf5uCrapD2da0BXTC0aefeyuG/T3WH1F4OCrufdP6UGwVKgqi9SRXb7iy1N2aR1rD6tqtS+3q6HQqTHhTTxhLbzh+vsJJvgCFQgV7/XelzHe/4NppEfwlTwUrv0SopKCe422MBjU31mdq2pvwBzv4e7xfVXwBbD8IbjiA/2x/C3qNnGQd8tgV+RZ8ZXs05Z55Ucq+OvEGXOijbwqvryH2+Ow8fq1U1l9oIRaqw2bo/EW7n+vPOiu/gTIraind7x3C2J2aR21VjUw/86ThhBiMhIXob93mq0abQm7DV44QYXllyxWM+yMoRDrsyq0yWMwfkI///MYAoRrwawsLbo1Cb6EEEIIcWw57FC0W213dMVXtcfKVZ7zk0TH+eEJ9d+af8FvD+vzuXI26LPdwuLU3KbNi2HqjSr4ArW6XDDthB1FCznqy6HOZyCzFng0JXejuu01Rn3QbGnwVbxH3z4GM748nfj4d+7tQq3VsamKr6U369vBhlK9xqiVMjUpw+Gsf/of51nxNfjkYxN6acJj9eBruE9rV5VHhYxnGzVAniv46g7humfwNeYC78eMRmQMdDcXaMaXq+ILu43MxEgyE5tvG16xt8gr+NqRU+EVfH2xLY9fLlY/85KizISHqpZHz+ArJbodg6/qAj0411b/Tejv32Zt9LgfGeBnR125/z6pBu/x5KeaEEIIIY6t0kNgq4eQiOAH24M+ZNr3A2dTqgv1bS1cER1r83/VbX2FWlwAVNvefy9W28PPhJmulfyyfla3WmVeTK9jd52BaMFXXZl/xdfnd6uZY03JcQVfvSepWy34CvRBy5elSp9ZAx1e8eUMYlh/o62O1lp9BUOAytzAx/nynJcTFge3rgk8sH7IKaodr+8MmHYMWhw9hXlUa/We6P3YCXfo274/T/K0+V7jOua62pPnQgSjz++86xAdw7Piy+Rb8dUQ9Gl+Odd7NcSdeXq1dUFlvTv0ArXEhfvlPVZkbLZduiU85y5qKwAHWkHVs1oxYPAVYFB/eHxbrkx0AxJ8CSGEEOLYcTpVlQ9A6nAwmpo+3pP2m2ubpenjPPm2OoqOVbTHuyrm3Svg6Qmw4VU1Dyq2D5z7gj78WxsGrgWU0anH9HL9BAq+ojyuaUkTIUxtqapqA8hwBSa+FV8bXlerFFYGmK2jrQio6eDgq8pia/YYd5vShtfg5VNgx4fq/uEfvA8cMCe4Fx04V1+sYPCCJo6bA3/Igeu+bFk43h48g/WUEd6PTbxazZ4DNQPMcw6bu+KrGwRf8Zlw7r/giiWdW2EpOoZnxZcWdGkD3+3BB18nDErmsztmcf2sAQDku2Z5AXy9s8DrWM8gPTaig4Ivz19G1Lj+nzH0FP/jfIfb+xq1yH9feJz/PtGjSKujEEIIIY6d9S/Dj0+q7Za0OYK+OpWtvunjPHlWfGmDp31Za1Q1WaAh0KJlDq1UtyERYHMFCKUHYdkf1fawhaqVTAsHivep8KDK1ZIa3dkVX/HqtipPD0BShukfsor3qiHmvq13+7+BtzwqZ7RKIa2KoCpXhb6fuCqGfn4eTvmLfnzOBnj1NO9zdnCrY0GF//fReRN6s3ST3tLpblNa8TfV6pm9Bnpt1CvTBs6FYWfA+EuDe1GjCS75L+RvU4sbdEWePydCfWacmULUezgqVb0niveo6r76Sr0Crlc3CL4g+L8z0f2ERas5V3YrJKjQyv1LJkfzgbenURlxbMwqB2B7bgVLNx1lRHosn21V4f3JI9M4UFTNb0/VZ8V5zfhqak5gS/lWzpqjYezF/seZmml1nHCF+vfEUo9fZEirY48nwZcQQgghjo26Mlj1tH5/6GmNHxtISyu+HHbv4Ku6yP+Yylx4ZrJaue2iN1p2Pd1BwU747mH1YT6+r6q2CrSUe3s5uk7dzrhFzfnypa0UF52qQq7qfBWWHV2v7+9MWsWX55D5sRepEEprc9y3zD80WPG4vm2OVgPOQQVgJrMKija9qR9j9Pkn+DZ9SHp9ZAbhtbk4rTV0ZBSbX+kffP3j4vGsP1JKdqkK/RIizSqU9JxvlrNRr+pLHdnyVkSDoWvPwQomWNfC0CJX8JW/Te2Pyzy288iEaMw9B9R7WVtowWO4fUslRqph8dtzKvn1u1u8Hrt9/mDG9on32hd3LCq+Bpyo2nQD/f/Mc7h9oBVijSa1cIpn8BXa/Mwz0b1Jq6MQQgghOl55FjzWXw2YN4bCr7a0fMW+llZ81Zao1ck0NUUqDPOUtxUaamDPF9DQgkqy7sDphE/vhN2fqjasXZ94BSwdQgu++p0AST4rOkanqQ8rmozx6vadS+HIj/oxnclzBT9NwgC46Xs48R51f++X/seYPT40Wav1gf4RCfqA9I9v14/xnR/mcf+ZilkAVFcFORC/lbRwS3P5tL4A/O604QCkxYZhNBr0UFJTuFOv0OvsmWwd4bS/qtuFf2v8mBT1Z+RepEOrEgs0b0iIzhAe6/2LhFa0OmoSogKv8DkwJYpRGf4tgjHherDfIcHX2Evg6k9g0jWNHOjxK4NAFV+g/3vC/RSp+O7ppOJLCCGEEB3v8Cp9e/xlrZvbExpE8FWVr9qxhp6mD9yOTFLzl5x2FYZ5fhiocVWB2a2qoqffjJZfV1d18Hv1ZwGQPEy1Ze36BCZf2zGvV1Oit8D1nqRmIW35L8y8U/2dhUaqFhzNoPn+IVJMFwy+tNkvQxfCysdh/7dgs0KIR1VBmceKoTNu837+qPNgx1LvfZ6ViOBeqbT6pL+x9XPX4OUObnXccER9iLx0al8m9I3nrLFqIPaZYzOICDXRO8G1epsWZmoKd6mwGLxnCfUU026GEWdBbO/Gj0lxtXUVuVbhrHX9nTX2IVuIztaK4faahEiz1/0V98wlPNREVFgIJqN/YOTwmPeVFGX2e7zVtOCrubZEz5WfA/1MBwm6jkNS8SWEEEKIjle4U90OPxPOCNACF4zmKr4OrYQnhsF7V6kh4lrwFd9Xb3eo9h7I6w6+ALJ/bt11dVVrX1S3U38BF7+ltg98qwKx9rLuZXh+hlqpM8/VCpg4SH3YSB4MC+7XKw88Qy8I3Ora2RVfZp9rHDgPUl0DzjMmQFQKWKvgiEeQa2/QWyPn/xHm3ed9jl4B2vp834eu4fd5ljBqnOp9bmro2OH264+osObUUWlcNDmTCLO+0MSCEWkM7+VqkdIqvsa52jt7esWXwQBxfZr+YKxVfGX9DFUF+ipxMihedFVae7W9Fa2OPuFVakw4abHhRIcFrqEZma5XgYWY2jFucAdfjYRZGou++mRwC+hICHY8kOBLCCGEEB2vcJe6HTTfe6nxlmhuxteeL/Tt/K1qoDioyg0tUPELvor17ey1rbuurqgyT6+mmnI9pAyFfjPV/f9erAcXbVFbCp/dpYKQn55WbaMQ/Kp2Cf38V83r7ODLM+wwhcFVH+rvV6NRX71Qm/cFqtrLaVcVbbPv9m57BIjv5/86jQRfWbWh1KKCL6Ottg1fSOPqG+xMffgbjpSo80/s18SHSLtN/1onXKluy4+oIf/QMyu+gqEFX/Xl8I9R+oqxERJ8iS5KC75aUfEVH+n9/2zPkDyQXnHhfHPXHNbe18TKra0RbPBVX9n04758Zy6KHkmCLyGEEEJ0PC34aulKjp6aq/jSPnwClBzQK75iM/T2Rt8WM6+KrzVqLlZPcGiFCmN6T9Lbsi57D9JGqz+/dS+1/TV+ekbfztmgwkZo2eDyKz6AK5aoQHTIqaqiqqsItLy99j6q95i/VbJP3SYN8grONhwpZf3hUn3el6fqAu/3mut8h6pM1KAC3hBb+1Z8ZZfWsmxHPluPVlBYpcLjKf0TiA1vIogucrU1hsVC3xnQb5b34z2x4isYngOzHQ3q/Q/NfyAXorO0Ybh9WIgedAVqbQxkcGp0+67oCMEHX9pA/2AFVRUmujsJvoQQQgjRseoroPKo2k4d3vrzaMFXY0PovYKv/T7BV2MVXx7BV22Jel5PUOH6807x+PMOi4Y5v1Xb619Rc6pa6+h6WPVP/X7eFn2OVaDWvsbE9YHBC+DKpXD5e11r7kqg4Evb5xV8ud4zSYPduz7dmsv5L6zmspfWUF5r9a/6sltVtZDG1Zqzp8JIravVMcRe778YQxvc/vYmbnpzA3e8rSq4jAZ47vKJTT9Jq4LsPVEFeAv/6v14R64Q2pUZDPoQfNDfA9LqKLoq93D7lgdfnkJNnfgzOtjg68R71EzGi95s+jiNQYKv44EEX0IIIYToWNpw7Pi+bauIaEnFV02hXmUW4xl8+VZ8uVodtVaHrG4w52vLu/7D0n15hn6ehp2h/ixqS2D/N617/aoCeOdyVVE2ahFkTvN+PNhWx64qzFUtMGyh/2NBBl+Pfq5W+7PaHKw9VAqXLIa0MXDVRxAerw6qcoWwTqf7fPsqjdTgUSXRTgPuy2utbM4uByC/Un3/XDm9X+MVGQ47rPibamUF6HuCuu01BqbcoLaTh7XLtXVb03+pvp88Sauj6KpMrv/HVWTBZ3dDQ13TxzcitD1ndrVUXbm6be7fEZGJcNk7wa8cLa2OxwUJvoQQQgjRsQ7/qG5926RaSpvx5bT7/9a6vlKvoAmNUrd5m9WtZ8WX72wrreJrwInqNmd9266xo9WWwtKb4P1r9A8BgTQWfJlCYMyFanvrO627hjX/gup8VU121j/V6o3n/gvGXgwL/uTdBtYd3fCtGso/7w/+j2nB144l8PIpYKlWbbUASUMAcDic7nAJYM2hUhUY/fJHGDhXfy/WuEJYazU4HQAcqDRRj5lCZ7x6bPfn7fIlrT1U6rdvYEp0gCNd9n8D3z2stiOTYNpN+mOnPaYWqDj3+Xa5tm4t1mfGmVR8ia7K6NHSvO5F+Ll137/mzgy+tP/Ht1dLsfZLmwmXt8/5RJcmwZcQQgghOtZh1wp4/dsafHlUpxRs856RVJGtbiMSIGO89/Mam/HlcECtq+JLG1pevE/9NvypMd6D77sKbfVA0IO9QCpz1G1sb//Hhp+pbnM2+T/WlKI9kLsZNrlWiJz3BzVLJTIRxl8Ki/4Ds+9q2Tm7opShMPs3EBrh/5hn+2P2Gtjytl/FV1W9DbtDf2+uOVTifQ7tQ5sWXLoGMTuNoVTZQwEDr9pcK156zlFrg1X7/d/LA5KjGn+C9v0EcO4L3h80TSGq6qvP5Ha5tm7Nd7i/zPgSXZVvVVPZkRY9fVwf9bPv/El92uuKWsbeoK/W2F7fZ5e+A+e/rH5hI3o8Cb6EEEII0XFqSyF3o9ruP7Nt5/IMvv4zV1XcaC1n5a4P6nGZkDFBPy4sFhL6e8/4qimBn1+AVf/QB/32naFuj6xSvw0vz1ID4jtb9lp4/gTYu0zdL/f4sPLWBXo1na/GKr4AEge6jjka/Jwvaw08NxX+M0dVKkWlwLDTg3tuT+I796vsMFTlqe0k9edaVuv9Z7q3oBqnZ0gbEa9utXk1rvewzRwLqPk5S+yukLhwpwpo2yCnvI5316vvj9+eprcnDkxpIvjSQt9J18LQU9v0+j2ab7AsFV+iqzL5BF+GlsUAL18zhb9fOI67Th7ajhfVAp7t5YHmL7ZGZCKMuQBC23kIv+iSpKFVCCGEEO2vugj2fgmWKhUu9RqrAqi2MBrBZFaDwQGOroWsNTD0FL0SKr4vZE6F1a7n9JmsVmzynPH14c2wb5l+3pgMSB0R4Gso9N93LNlt8PLJavvL36mv03OOmaMB3r0Sfr0dzB4hhs2iV7IFqviKToWQCLDVqcqepEHNX8uR1d73M6fpq4QdT3w/cOVvU7eRSe4qBC34SowyU1pjxWpzUGO1Ex3m+me3Vq2gte24PtBZTPrfYRna0HgnWCraVOHw1s9HqG9wMLV/Ir+cM4gjxbU4nE56xweoaNNoLcBdaZXNrsiz1dFghLB2+kAuRHsz+vy8bmHwlRwdxgWdVe0F+i8KwuJkFUbRKhJ8CSGEEKL1yg6r9sDBJ6kP8uZotULS62dB0S79uPGXtc/rhYTrwRdAQ4261drNkodAn6n642mj1a3W6mipUO16nsZdolr2zNHew8S1lRHbonA3xPVu3ep3O5bo25WuqiLf9pS6UjVza/Zv1H27DV46SW0bQwIHJgaDCiGLdqkKsmCCr4Pfed/3XC3yeOIbfOW4qhk9AkYt+MqID6fWaqO+wUFptVUPvrTh9toHOVf7Tq1RzdyKMpuosUI9YYRjUS2RbQi+Dhap9/SZ49IxGAw8dkEQq25K8BWcGI+KyogEFc4L0RX5/qKihcFXp3Ov6BjfqZchuq9u9o4XQgghRJfyzuWw+AJ4dSE8ORL+OQ7evtg79DJ6DFRvK23AvabBNUS8ZJ+6TRrsXYWhzRULjwOT67k1HpVcBhNMulpt+66gp83Jaq2CHfD8NNWq2JoQbe2L+ratDv45Hg58q+7HZMCgBWp75d/1ire8zZC/VW2njlAhVyAJ/dSt58ywphxa6X0/UIXc8cA3+LJWqVuPgKispgGAhEgzSVHqPVfq2f7onvHl3epY6VQVWEN7qZC0yhDtfVwrHS1Tq7c1WeGlcdjVf9Va8NXNFyroaAn9VJUpBF4FVIiuwq/iq5H/N3RV7uBL5uiJ1pHgSwghhBCtU3EUCrar7azV0FCrwiLPNkJQK9q11wfoEJ9ZHDbXkuzulfXUgHF+8QOc9x99PpHBADFp+vMMRrj+a7jmM70Fc8IV6tbsqs7asRTeu1oP11rqyE/qtiILPr69Zc8t3K1aOT0HEpcd0oOq816Ayz9QK2U21ML6V9X+nA368Yteavz82tccTPDlcKjB9p6O1+DL3Ejlnmfw5Qq5EiLNJESpD5ulNRb9WPeMr3J16wpYj9SYAZjcT32wq8AVfGktka2UU66+R/okRPo/2FAPuz51D9jntTNVwKrNkpOKr6aFhMHtG+G3h+Cc5zr7aoRonF97oARf4vgiwZcQQgghWufg9/p2aKSavTHlBhh5Dlz4GvSfrR6b87v2e02T2ft+Q536T1uFTgu+0sfCuIu9j432CL5i0tUssH4z9H2nPAyLXoTL39P37fwQvvx96661YIe+fWC5Pg8qGFmumVr9ZsJQ30oSAyQNUW1Vw10D5g9+BxteU8PwAebeC6lNtCNqwdeB5erPrym1xWC3eO/T/pyPN421skUHCr5CSXRVfJVUN1HxtesTAFZYh5IcbebcCaptstzpCqq0gKwVqi02ymtVBVrvhAAVX8v/Au9eDh/fphZEyPpJBbVataPWIiwaZwqVofai6+sxrY4SfInWkRlfQgghhGgdLfg68R6Y+StwOtWsLE2/WaoFsd8J7feadu8V82io0wOm8Hg1ZLwxnsFXoKHvEfEw9iJ9RUTNzg/hrKdafq2ewRfAxjfh9L8F99y8zeo2Y4KqRIvvC4PmQf526DVazQ0D/WvK2wKf/Ep/fu/JTZ9/+Bnw/aMqjFv1T5jbRLinhYrRaaq9MnGAf8tpF5VfUU+N1caglOiOfSGvii8VNMVHmkmqV6uGltZ4vG+1GV/15VB6CHI24MDI5/bpnDk2g8QoFe6WOaLUr6jb0OqY42pzjIsI1WeMeVr9rLrd+RGMuajJr0sI0Y21cbh9u9jxoaqEPvUR/1Umm6P9AkCCL9FKEnwJIYQQomXqymDNv2Hb++r+wHmBh7dHp3hVwrQL3+qk+gr43w1qO3Nq03NLPKtXYjOaOC7N+76lSoV6LZmJ4nRCoWvO2ay74Mcn9TArGNoA/ozxamC/Fpj5zhHyvVZNxoSmzx/fFxb8CT67C7b/D5KHwqjzAn+N2nyy+L6qxbKbcDqdXPTv1WSV1vK/X57ApH4d+IEpSn9vlXus6lhtCRB8eVZ8uVpTsyJHUlwfR1KUmShXQOUOvrRWxx1LYd3LcP7L3m27TThaVgtAn0DVXqA+/DodanvVUz6PmfSQTgjRvflVfHVCq+P7rnma6WP10QKNqcyDJTeqhXES+quFXECCL9Fq3azGUQghhBCd7rO7VbUQqBbHPlOO3WvbfFrucjep2VdhsXD2M00/t69HW2NYExVARhPM+rXequmw+b9uc8qz1OBzY6gKlEBVgDkczT/XZoXCnWo7fXzTx8b08t8X3Quimqh80/RxVYUV74UPrlWVbYFowVdcZvPn7EKKq61klarg5zfvbcbhcHbciwUYbh8fGequ3ioJGHxVuFsKC03q7zEqLIQocwjhoUYqiHIdVw41JfD+NXD4B9i8OOjLynZ9/Y0OtvecIXd0nfdj0WmySqEQPYVv0OWwdc51gP5LoaZ895D6effhL9XiOWv/o/ZL8CVaSf5vJoQQQojgVRyF7R/o92N6QYi58ePbm82n4ksbwp3QL3AI5Gn0+fp2SjPD2U96AK76SL9vqQp8nKUaPrnTe9VDmxWy17heZzikjlQrSlqrVUjXnMKdqqUzPF6fxdWYQBVfwQ6e9/0zyPo58HHu4KtPcOftIg4W6at0Hi6pZcvR8vY58S0/q1adeX/U97kqG51OJ/tdr5seF0GS1rboFXzFq1tLhfvPttiggsqoMBMmo4Fb5w6mwqkFX2Ww5l/68+0NQV/qngJ1LYNSGwl6m2p3mnpj0K8jhOhmWvrLnLayewRtlsrmj2/s/7naz08hWkiCLyGEEEIEb8vb3vdn3nlsX9/3t9TlWeo2Kogh3EYT3LYBTvwtTLomuONDXeGDtZF/hO/6GDa8Cis8Zne9tUi1aACkjVSzTNJGqvsr/67aIJuitUSmj2u+HSVQi2mwwZdvYOlspBpN+zPuZhVfB4trvO5/uT2/fU6cOgJm3Oq9eICr4mtfYTVFVRbCQ42My4xzV3wVu4KvNQdLeODro/rzXFUM+ajh6Fqb45Uz+lHuWtXRUVeuFiHQtGCVx5156gPmqIxY/wctVWDzWbH01rXqe2PKDWpunxCiZ2pBgN4u6isCbzcmLMDPLJCKL9FqEnwJIYQQIni7PlW3ZzwJNy6HiVd17vVoGpt15St5MMy/r+lWR0/acZbqwI9rLRs1xVBdBFvfV+0ZmrRR6rbPVHW75b+wb1nTr+k536s5gYKxYP8sACZdq29XHPV/3OGA/K1qO6Ff8OftAg66K6/CAfhkSy5WWxCtpsHyDAIjkwFYtb8YgCn9EwkLMTHYVWm1I6eCzdnlXPyfn3nt5xyqI71DxDyH+jAXZVbBV0x4KJWuVkfj7k8gZ71+cG1pUJdnszvY7Qq+RqYH+BBZkeO/L2UYnPVPOOMJFfwKIXom35V6O1qdx8+tQP+v8RUw+DJA8rB2uyRxfJHgSwghhBDBKT2oqpEMRhhxNvSe1DkDcgNp7yH6Gq2iqrG2i+K96ra+HN65FJbc4P14qiv4WvB/YHadq7SJdse6clVBBs3P92pM3+nBH3vKX1R1DwT+MJL1k6r4MsfoM886gdPp5PNteezMDaJFxuVgkar4un7WAFJiwsitqOeddVntd1Hp42D8FaoyylU9t+6w+nA3Y5BqXRyYEs24zHhsDifnPrfK/dSl41/yOlWOPR7QK75MRgMNoY1UPNQFF3wdLqnBYnMQaTbRPynK/4BKn+DrWM7qE0J0Lt8Vkjua5+q0ZYebP9733xZX/A9++ZP65ZUQrSDBlxBCCCGa53TC5/eo7YFzOy5oaq2WVDm1hNlV8WVtpOKraI+6ra/wHw4OeotjWAyMu0Rt1xSq1fz2fOm9SqXDoYb4aoKp+PIUkwEXvdGy4CssRq/68g1C7DbY+q7aHn0emCNbdj3tpNZq469f7OaWxRu54uU11FqDG8p8yNXqOCI9ltvmqQ9L/13TjsGXwQDnPgcn/9m960Chek3PCqsLJvb2e2qBMwHGXOS+n9UQD0CkWa+yyokYQqVT/zO3mNR7sb6iMKjL2+ea7zU0LQajMUBAXXpQ3cZlqgDvkv8GdV4hRA9g68Tgq7YE6j1+iVG0B5Y/DFaP9vSGWu/nD5yn//9UiFaQ4EsIIYQQ3pxOKNoLR9ersKuuHHI2wv5v1JD20x7rvGs71zXk23NQPQQ346s1mqr4aqjXh+v7/iMdYN59EJuh3492XWPxXnj1dHj7YnjrAv3xwz/oqzlO+yUkDAjuGq//BkZfADd+CyPPCe45nuJcwUxtiWrVBFj7IjzaGza+oe4PO6Pl520n5z63in+vVCFNaY2VxT83H145HE6OlqlQsW9iJAvHqIUP9hRUsbegCofDic3u4PrX1nHZiz+3uQWyvsHOKz8eYk+Bep8MTNZbaecO839vltVaIb6v+352g3qfaRVfAM7IVCZbXmDFog3UzPsLd9VdB0BdZXFQ11RVrwLChMjQwAcccVWgTbhSBXjRHfQ9JIToeo55q2OZ9/2aIn37/Wth5d/gg+v0fQ0+C9lI67Voo5DmDxFCCCHEcWXnR/D+1fp9c5Q++Hz4GZAytHOuC2D8pTDqXDi8Crb/T9/fUR/amwq+SvY3PhB+yo0w57fe+1wD0Dm0Uh8qfuRHNR8sKhk2van2Tb4eFv41+GvMnKL+a63weH17yQ1QnQ/L/uh9TO9JrT9/G1RbbOx1VS4lRIZSVtvA35ftYVL/BCb2bXzIcUFVPVa7gxCjgfS4cEJMRvomRpJVWssp/1jJX84ZhdXu5Nvdqnpq+e5CThvdzKqgTXjuu/08s3w/AGaTkd4JEe7HMhP9K+XK6xpgwjz44e8AVFrVggdRYfqHu7iIUKyEUmoP53Xn6ex2qgH3EbYgBkODuzIuMizAP/edTvU9BNB/ZlDnE0L0IB013P7QStUeP+EK7/2+wZfngPvCHep275fqZ5PB4F39JUQ7kIovIYQQQnjLXut9f+t7sPNjtT3irGN/Pb5CIyA03HtfR7c6luyHbx7QVzgEKN7TxPMCzFTSwjnfFa20YfjaUPtj/WdsMEA/j/DDN/SCTmttza9QAWFMWAjr/3gyJ41Iw2Jz8JdPdzb5vOxSVS2QER9BiEn9c3dQiv538tx3B3juu/3u+++vz27TdS7bUeDeTo8Px+TTWjg0zXsxhfJaK/SfBYteov6aZe6FPrXh9gBxrkqt8toGVh8oocypQthwW5VqQ21GjdXuOmeASomS/arl1hQGvSc3/wUKIXoWWwdVfL1+Fnx0K+Ru8t7fVPAV41EZrS2m4lvxJUQbSfAlhBBCCG/VBd73K3Og7BCERsGQkzvnmnyFRnjf77CKL1dgsfpZ+PEf8JZHi2XR3safFyiIi2okPDq0Uv2WWxsu79ECd8xc8l8Ycop+33PlLFPYsb8eFy346hWnwqRHF40h1GRgU1Y5z3+/H4fDGfB5WaWq9TQzUX+fnDlW/3CVX1lPaY0+4+b7vUV8sOEoaw6W4HQGPmdTQkP0oKuoyv8D5X+unMz84ancdbKqliyrcVVbjL2QyqRxgMofI0K9K74Aymob2JJdTgUeYarvh0gPd7y9ifNf+Ml9HZHmABVfh39Ut32m+IfIQoieryOG23v+7PQdYO+7Gq3FY8aX56iA4n3++3xHGwjRCi0OvlauXMlZZ51FRkYGBoOBDz/8MOjnrlq1ipCQEMaPH9/SlxVCCCHEsaIFMBe8ClN/oe+fcave+tfZQjyCr5BwiGi87a1NzN6VOhTvVf+AL9rTeMXXmAth0jX++32Dr6GuQfbbPlDntbl+wx3rPwy9w0XEe7emTL0RFrlWHjz/pYBPORbyK/XgCyAlJoyzx6k/n799uYclm3ICPi9bC74S9DbD8yb05j9XerdsXnNCfwYkR2F3OLn7/S1c/J+fef77Ay26RofD6R5qD3Dm2HS/Y/onR/HKNVM4cah6D1TU6W1GtRZVmRUZavIaQq8FX19tz6ey3oYdExXasPtGVnassdj4eEsuG46U8dpPh9V5A1V8HZE2RyGOax0RfHlWkXmOAdjyDqx70ftYreLL3qBWRdbUuGYYaq2O02+Fs59t90sVx58Wz/iqqalh3LhxXHfddSxatCjo55WXl3PVVVexYMECCgoKmn+CEEIIITqHtrpfXB849WH1m9eyw3DC7Z16WV48q1Rie/svfd5ewmL99z03VQ3mDXFdg8EEThVekDGh8aDItyptxq1QlQd5m+Gz36h9kcmdV4HTd4a+PeYCFSaOXnTMhwp/v6eQu97bwh/PGEGBK/hKi9X/TP58zii251Swp6CKZTvyuWBSH/djDocTo9FAdplW8aUHX0ajgVNG9WJQShQHitSHqosmZ+JwOt0rQALszg8wz60JOeV11DWov//fLxzOZdMar9iLd1dx6R86a1yzuKJ8ZnFpx2oD8wHKnDHEGWr9qyc8rsWXX/DlOd+rnwRfQhyXOiL48pyF6bDr21vf8z9WW9XR92eZNvRea3UctrDTVhQWPUuLK74WLlzIQw89xHnnndei5918881cdtllzJgxo/mDhRBCCNE5HHaozFXbcX3AFArnPAvXfArhAUKgzhLq8Q/huA6skAqL9t+n/cNcG1Dfa7T+WFOrS/rO/eo1Bmbfpba1OV8d+bU0JzoVrlsGN63QK+g6YSWte5dso7TGyl3vbWFzdjkAvTyCr6iwEP5+oWoPXLW/2L0i4668SsY+uIy739/CtqOqmmBAsv+stV/OHUzv+Aj+dcUkRmbEMmtwstfj1fUtG/q81xVMDe8Vw81zBhEb3sgqikBCpBmAWqsdi019MKxxVXz5Bl9axZdmfGY8ZbgqLhup+MopCxR8+fyeu+wQVOWCMVS1Ogohjj+2Dgi+rB7Bl2cro2dF18hzXftcFV+eqzsC1LoqvrRWx1AJvUT7OCarOr766qscPHiQt956i4ceeqjZ4y0WCxaLXipZWVnZxNFCCCGEaDfVBap6yRjScQPj20OIR1VUU2FTW/m2OvoymVWAlbfFdS3NDIGPSFShxZQbVXthn6nej8f2Cfi0Y6bvtE59+Q1HSslzzfUC+Hqn6hJIi/OughuVEUtKTBhFVRZW7S9m7rAUlu0ooNpi44MNR93HTRuQ6PcaF0zq41UldtKINO5dOJys0loWr8mi2tL84HhP+wrVqpND0ppvA44JD8FoAIcTKmobSI01uSu+fCuzYjwCtOcvn0hEqImyxa73Y21JwPMfLav12+c+7w9PwvpXocK1QEPvSVJJIcTxyt4Bw+09K748h9dX5avbG5bD7k9dx2oVX8Xe56jxCb7kZ5RoJx0+3H7fvn38/ve/56233iIkJLic7dFHHyUuLs79X2ZmZgdfpRBCCCEAqHC1Ocakd0q1T9A8fwscldz4cW3V3Eyz6F4QFqffj2kmLLzwVVjwJzjtUXU/Nh3iPP6d05kVX52sqr6BX7+rAsTYcO9/M3pWfIFqW9RmaV372jrm/f173lmX5XVMakwYSdHND+Y3Gg38Ys4gTh3VC4Bqi93r8cKqemqtjYdhWsXXkNRmQlLXa3kOrQc1lwv8K748g7CTR6YRGxFCGVrw5V/xlVNex0s/HvLbHxkWombv/PCkHnqBzPcS4njWnq2ORXvUSo752/V9WvDlsOvBV2w6hMd5P17jE3xpob5Vq/jyWchGiFbq0ODLbrdz2WWX8eCDDzJ06NCgn3fvvfdSUVHh/i87u21LTAshhBAiSIU71G1cF/+lk8mjDSzCv6qn3YTHNf14TJr3YP1xlzZ9/MC5qr3R8/p7ewxc74zB9l3EBxuOklVaS+/4CL75zRxMHoPeR2b4t9leNaO/e/twSa1XpRjAghEtq1jUgqdqi97qWFRlYdZj3zH38e+5/rV1vPzjIWx2h9fz9hWoiq+hac0HXwAJUardsaRGVVxow+2jfCq+5gxN4RdzBvLvKycRajISHRZKubPxVsf7lm7jSEmAiq9Qk2qltfrMLpP5XkIcv9qz1fHN82DTW/DRLfo+z1ZGpx0MRlWd7Q6+KtUAe63VMdL1C6yaYnA49MVeQv3b1YVojQ5tdayqqmL9+vVs2rSJ2267DQCHw4HT6SQkJIRly5Yxf/58v+eFhYURFtZ5S2cLIYQQx61tH6jbISd17nU0x3OYfWQHBl/NtS5Gp8G4S6BgO0y+DpKHtPw1Jl4FR9dBTC8YeU7rrrObqLPaeWLZHhaO6cWkfvrfm9Pp5J216hedN88ZSGpMOL89dRj/XZvFA2eNone8/2/9ByRHcdu8waw6UMymrHL3/k9um8WSTUe5bd7gFl1bjKvKrLper+5avrsAq81BYZWFb3cX8u3uQpZuOkp8hJnd+ZV8dsds9reg1REgPS6cg0U15LuCuqJqFYD5zvQyGg3cu3CE+350eAilWvAVoOLr+z1FfvsAIsNMsOszdWfkuXBoBWCAzM5taxVCdKL2rPiqDLC6rja8XpsZGp0GphB9VmjWT/C3gfqszNQRKqCvKdJDL5BWR9FuOjT4io2NZdu2bV77nn/+eZYvX84HH3zAgAEDOvLlhRBCCNESlbn6kPUxF3XutbRER36A912J0VdML4jPhIteb/1rDF4Ad+1s/fO7kb8v2/P/7N13eFRl2sfx70x67w1CQu+9F5GqgIgiKoq9d921rLu67qr7rl1XXXtblVVBXHsBEaT33juhE0ghvc+c94+TzGRIh3R+n+vKddpzzjwTj+HMPfdzP3y0NIEPlyZw4PmJjv0HUnLYdSITT3crl/Q2s97uHNGOO0e0q/R6j4zrxCN04p2F+3hhzk683K30iA2iR2wVmXrl8C/O+MouNdTx9CwygK1HnbVn3/h9D7mFNjzdrMSHVu8DWosgH5drlxTw79ai8j4HeLuTVjzU0ZadQun8sJJC+SXahvuxv3imygBLgTOg3e9Gc6ZWwyh/4gYROTfYC83MKmsdDQAryfjKPG4uA8yh6Y6Mr9xTru2je5rPH3lpzqAZgLuGOkrtqHHgKysri7179zq2ExIS2LhxI6GhocTFxfHYY49x9OhRpk+fjtVqpXv37i7nR0ZG4u3tXWa/iIiINLBjG81lVA8zmNPY3bXUDNbF9Ky71/ANc93udQ3s+NE5bKwxTwDQCP2y5bhjPTW7gNDiYX/H0sxv+ONDfctkPlXHHee3xcPNQu9WwWfct5KhjgU2O/lFNrzc3dh+zHWCpfHdopmzLdGxPWerWXy/VagP7m7V+wAZU5y9djQtF8MwHIGvPnGV993P051Thhmssp8W+Dqc6syQmPPH4byzcJ8j8BV56CezkHRoW2gzsu4+6IpI43bnYljxNmyeaW7bCsDqXfk5Z6ok8FWS8RXYwlx6VRDgb30erHwbMCC9eIISdx/9vZJaU+M7ae3atfTp04c+ffoA8NBDD9GnTx/+/ve/A3D8+HEOHTpU2SVERESkMUop/mLrTIbrNYToHtBxXN2+xukF/ie/Ddd86dxW4Kvadp/IdMmgWr7PWdT4RIa5PyrwzD6EuVkt3Da8Lf1bn/mwV/9SxeVLhjtuP+4a+Lp1uOtoheTiYYoxQdXPSmgZbL7HY2m5HE3LJSkzH3erhe4tK8/4crNayHM32xinDXU8nGrW9uoSE0jn6ECX4GHAiVXmSs+r9CFS5FwW0wsmve7cPtvhjoYBR9aWf8wR+CoeBlkS+KqobmZMT2fZgrSD5lKF7aUW1fhfv5EjR2IYRpmfTz75BIBPPvmEhQsXVnj+U089xcaNG8+wuyIiIlJnSgJfYTWrjVSbjqfn8tv2EyRl5rNkTxI/bjpGek5h1SfWJTdP57rF4lr3KyC6/vvTBBmGwVM/bHPZt2xvimP9RIYZQIoMaLgar25Wi2Mmxex8G7kFNo6cynVp0zM2qNzMrOig6gfsWhRnfB1Ly2VbcUZZp+gAvD2qnkW1wNOcSMHz1B5s6ccc+w+mmNldJcMtfT2dQTzPtOKZHiOd9cJE5BxV+t+zsw187ZoNH44p/1hJ4Ctln7kMbWsuK6rJGdjSOVFNSbDMU4XtpfbUaY0vERERaUJS95vLBgp8rdqfwrUfrqLIbrjsbxnswy8PDCfIt+ZD4GqFu7frBwS/cOf66UMhpVy7TmSyfF8Knu5WHp/Qmad+3F5uxlfkGWZ81RZ/L3dyCmxk5hfi7mYpc9zL3Y0Pb+jPzsRM/v79VvYlmQGn6Br02xn4ynNkarUOr94HvCLvEDBr6ZP22lD8/7ITLy9vDhZfJy7MDHx5luq726mSD56V10sTkXOA1QpWD7PG19kGvtb+p+JjZQJfxX9//MJh3LNmttj6TyF5t7nfYjGDYimYATUA7+Cz659IKcp3FhEROZflpcPxzea6I+OrYT4g/7T5uEvQK6y4/tPRtFw+W3WQvEJbRafWLffTghqlH8ZLCvZKpRYVzzg4rF0Yl/eLxc1q4WBKDkdOmQGbpEwz4ysqsGFn9S4Z7piVV0R6rplpGODlztT+sbx3fT8Awvy9GNY+nLYRzuLwUTXJ+CoeFpmVX8SaA+aQxdiQ6g3pmTS4m2M9zDjFkvXmJFLJWeYH2JKhoiX1xoLJxJKXZp5QknEhIue2kqyvovyzu469qOJjtnwozC31hVqp54oh98LQ+2DKB+aXR5e8Ye4vyfg6tMJcDrjl7PonUooyvkRERJqj7GQ4vBqOrjWDW2P+Xn5tjR8egO3fQZvznbMvNdAH5GV7zQygd67tS/eWQbQI9uGrtYf5yzdbeOnXXbz06y4eGN2ehy7sVL8d8zgtqGG1wg3fQ34WBLWs3740EZl5hfy2/QQdowLoGhPIvB1mEfjzO0YQ4O1Br9gg1h9KY/neFKYO8D3rGl+1xd+7eGbHgiJKYrARgV68eEWvMm3blsrSiqlBv3083ejWIpBtxzL4dZv5e4kNrl7g69rzOsE85/bidZsZO2QAOfnmB1B/L3O4ZEm2WltL8f/TgbHgWb1ZJ0WkmXP3hMLss8/4slVRhiBpJxTlgsUNguPKHm/RGx7d79z2CXGu+4ZD35vOrn8ipSjwJSIi0pzY7fDb32DlO2CUypDyDYNRj7u2tRWZQS+AhMXmssOFFdfgqEPH0nLZn5yN1QLDOoQT6G0Oa5zcpyWfrTrI1qNmLaT/rjzIH8Z2xM1adhhanTk94wug7cj6e/0mJjW7gKveW8Gek+aYPHerxZHJN6KjWR9tWPtw1h9KY9m+ZKYOaMWJzOKhjg1Y4wucGV+ZeUUUFJl9Dq5glsk2pQJfNanxBfDOtf244NVF5BfZAYgNqUFQ6rL34Ns7AUg9fpCcgiKyC8zAV0ltL8/ijK82luIZKMOU7SUixWor4ysrsfLjR9eZy5DW4FaNUgWlnz2CYjUZh9Qq3U0iIiLNyZavYMWbZtArorMzQLNphhkUK5FxDBI3uZ474i9w9Rf11tUSeYU2/vHjdgD6xYc4gl4A3h5u/HT/cHb9czwB3u6cyilk85G0+u3gpH+D1R1G/61+X7eJ+mzlQUfQy9vD6gh6/WFMB8fwwKHtzDppy/am8NCXGzmcahaRb+iML7+SoY75RWQUD3UMqiDwFRfqDFbVtN9xYb4uRfKrO9QRgF5XQ7fLzNclhU2H08ktMIPcJcX5r+gXS7i/JzeE7TDPie5Zo/6JSDNmLf6bZpxF+QC7DdIOlX+s5MuiOY+Zy4jO1btm6YwvlRGQWqaMLxERkaYo/Sj8cL9ZK8Nug4RFZkbXsuKpys97EMY+BQU58HJH8wH12RbQ+xpoPxZmTnNeq9VgmPKe+a1sPSuy2bno9SXsTzaLhP95fPkPyF7ubpzXPpzZWxNZuCuJPnEh5barE/FD4LEjTXZqdXMGbrDWU5bcot1mPa/npvTg8r6x7EvKwt/LnValAkV944Px9rCSnJXPNxvMGbx8PNyIbOAaXwHFga/s/CIsmL+vigJf7aOcNb5K6tHVRJeYQFbuN2t8taxJ4AvMGdCAKMsp1h86RbYj8GX2P9jXk5UP9MLtteVm+97X1Lh/ItJMWYtnkLWfReAr83jZoZKdLjKfQ769G05sMY97+sPIv1TvmqUzvgKizrxvIuVQ4EtERKQp+u3vsG+++VNi509w6oD5oDnsD+Y+T18Y8SezfVEurP3I/Cmt44UNEvQCs3B9SdDrn5O70791xcMsB7UJZfbWRHYcz6iv7jk10aDXin0p/OWbzSSm53Hb8DY8fEGnOg2ApecWsvFwGmDW8/J0t9IlJrBMOy93Nwa0DmXJHufMjj/ePwwvd7c661t1lNT4yswrwiiu8VVR4CsywJuv7x6Cj4f7Gf1OB7QO5eNlBwBnwKrairMhYiwpfHfwlKPGV0nGF4D74eXmzG1R3SGqW7mXEZFzkLX4701VNboqk3607L5pM8xl6Xqisf0hppoZp8r4kjqkwJeIiEhTk5sGiVvK7j91wFyO/pvrA+TQB8yhDbtnO2t5ldb7urroZbUcSjVn9esQ6c91g+MrbduiuAB4SSH06vp2wxHiw/zoW59ZYrUoLaeAIB8PLBZncMVuN/jfuiP0iQumQ1RAuecdOZXDXZ+tc8xO+NaCfbSP9OeyPrF11tfVCanY7AZtI/xoWUXB9ot7xjgCX1f2i6V9ZPnvoz6V1PNKyynEwIx8VRT4AugXf+b18CZ0j+ZP4zrRsYL/fpUKbAE4M75KCvH7ebmZfx82/Bf2/W7uDKq7/94i0gSVBL4qm5WxKgWZrtvx5znXvUt92eEXUf1r+pT6e+qvjC+pXarxJSIi0pRkJsIrnSF5l+t+X7NmEt0ug4F3uB6zWGDIPXDjjxDT2/XYyMcbdEhBSeCrdL2kipQUEE+sQeBr6Z5kHvxyE1PeXo69JDrQhHyweD+9//EbHy1NcNn//pL9PPr1Zu75fH2F57706y7ScwvpGRvE9cVBxbcX7KvT38OW4vpr/aoRZJzQw/mN/hkFf+pAkK85ZDEtt5D03CKXfbXNYrFw76j2XND1DP7/Kw58tbCkciqn0BHc9PVwg3fPg7lPOANfnv4VXUVEzkW1EfjKN+s40qIPTPkQpk53Hiud8VXybFIdLkMdlfEltUsZXyIiIk3J/oXmkMUSMb1g3LPmB+FTB81i9pZKhl0Ft4LjG831BzY22BDHEiWBr1Y1CHwlZeZTZLPj7lb193e/bXfOOrXtWAY9YoPKtLHbDSwWXDKqGoONh9N45hezOPnX649y23BzZr63F+7lxTlm4HPPySyOpeU6suFK7E/K4odNxwB49rIexIX58t3Go+w5mcVvO04wrlt0nfR56zFzGGr3lmV/z6cL9Pbgz+M789v2RK7o1ziykkoyvn4s/t1B5RlfDSbA/O8XYckADCiuR+ZnS4P0w65tvRT4EpFS3EoCX2dR46vALFGAbzj0vNL1WOnAl19Y9a/pMtRRGV9Su5TxJSIi0pQcXuVc73k13LkYWp8HoW2h3ajKg14AI/5sDnvseimEtqm6fR07XIOMr3A/L9ytFuwGJGVVPQ27YRgs2JXk2F68J6lMm5OZeQx8dh73z9iAYTSujLDPVh50rOcXmR9QjpzKcQS9SpQUky9tVUIqhgFD2obRvWUQgd4e3DikNQBvLdhba+/VbjdIy3EWON5yNB2oXuAL4O6R7fjmnmGEnEFx+LoQ4lc2yNUoA1/Fw4e8yMcX5/8LvpkHy7ZVxpeIlFYrQx2LM748/coeO9OMr9JDHX1rEDATqQYFvkRERJqKgmzY8Lm5Pul1uPStml8jugf8YRNMfrd2+3aGajLU0Wq1EBVoZn0dTy873HHr0XSu/2gVr83bTV6hjd0nshzXB1i2N7nMOYt3J5OcVcBPm4/z9fpyivU2kJyCImZvOe7Y3p+UzVXvrWDmajObx9fTjTtHmBlg3244WiaQVRJQ7FBq5sGbh7XG083K5iPpJBRPKHC2/vLNZnr/4zc2HU7jREYeSZn5WC3QtZyC9k1BkE/ZAFyjDHx5+oGH+f9MmMUMNrpbLXikHyjb1qtxDCMVkUaiJPD19W2w8Pkzu4Yj8FVOYN0l46sGNb48fc0v54bcB8FxZ9YvkQoo8CUiItIUGAZ8MAZsxdkdHcc7hyvUVFBL8wGzgR1Izmb3CfPhOT6sev0pGe544rTAV3Z+Efd+sZ4le5J5bd4e/vz1Zscwx9gQcxjgpsNp2E6rb7Wz1AyRf/12C8v2JvPG/D0898sOimz2M3tjtWDx7mSyC2zEhvjgWTykc1VCKm8u2AvA9YPjuXFIazzdraxOSGVhqayvLUfSWVic6Vby3gHC/L3o3zqk+Ppls8RqIq/QxvOzdzJr7REAft2WyIZDpwCzXpePZ8POznimgn3LBrkCvBtpZRA/M5MiHPMeHu25Db67q2w7ZXyJSGklga+CTFj43Jldo6TGV3lDqb1KF7evQcYXwKjHYdwzZ9YnkUoo8CUiItIUnEqAJLPeE8P+4Kjx05Q99eM2CorsDGwTSvvI6n04jy7O+Pp81SG+XncEwzDYdDiN6z9axcEUZ3bX9xuP8fLc3YA5nM7P043sAht7TrrORLXtmDPwlV9k59oPV/HKb7t5b/F+ft958mzf4hlbvs/MThvdOZKCcgJwA1qH0iLYh6n9zdpYC4r7ejg1h0lvLmV7cUAvNsQ1oDi8g/nte8lsimdq+ooDvLton2M7NbuAtQfMwFe/+KY5eyY4a3yVuGFIPJ2jG2nGVHEmRZjF/G/9Oi+V3041vkSkNGstfDFRUuOrNoc6itQhBb5ERESagkMrzWWrQXDBPxq2L7Ugr9DG8r0pADwzuXu1C8u3Kw6QLd2bzMNfbeKFObuY/PYy1h9Kw8vdyjf3DOWRCzs62nu5W7mwazQ9Y4MB2HgoDcMw+HbDEV6ft4fNxbMQfnLzgDKvtbVUUKy+LS0eljm0neuHhnYRfkQGeDGorVkLpU24+ftIzTbrbM3ZmujSvtVpga/zO5rXW7E/hYKiM89oW38wzWU7ITmbNQfNwNeA1qHlnNE0lB7WGO7vyT8urf69We9cAl8GPlRQ904ZXyJSmrUWslgdga9y/r54lJpspSbF7UXqkAJfIiIiTcHB5eYybnDD9qOWbDycRoHNTkSAV7WzvQDuHtGOl67oyeDiwM+7i/ZhGNA2wo8vbh9E37gQ7h7ZnnHdogjz8+T9G/oTEeBFr1bBAKw7eIq3FuzlwS838eq83WQX2PB0szK0XbijZlZJVtn2Y+kNUvD+ZGYe+5OysVjM4vTPT+mBxQIf3tCfuQ+OYMmfRxHgbQZoQouLsaflFGIYBnO2uQa+Sg91BOgSHUi4vxc5BTbWHkw94z5uO27WlfrTuE4ArD6QyrbiwvZNOeOr9EyhXu6NfLhm8RCiMNIJpVQmo5sXtOzn3FaNLxEp7fTA15n8O1dQ/DenvMCXrdC57h1c82uL1AEFvkRERBq7xC2w/XtzPW5ow/allqxJMIMuA1uH1iijxsfTjSv7t+LeUe0d+8L8PPn27mH0izeDYW5WC+9e14/Vfx3LiI5mVszQdua3zr/vPMmHSxNcrvmHsR3wdLfy53GdmffQ+fx7Wh8A5u04yZR3ljuyqerL3pNm7ZTWYX4E+Xpw9cA4dv9zAmO7RuFmtbgEZEJ8zWLsS/cm0+vpuawrzroqcXrNKqvVwvkdzIDJmQ53TM8t5HBqLgATe8QA5uemIrtB71bBZYJtTZWXeyN/TC7O+Aq3ZNDaUhzwDIiBx4+as7yWUMaXiJRWJvB1Btm/JRlf5Q2lbn0eeAZAy/4NPnO0SIlGWq1TREREADOi8P19kJ9hBr3aj2noHtWKVcWBrwGtzyw7aFCbMAK93cnIK+KJi7sQdFqAx2Kx4FbqeXtw2zACvN1JKQ5i+Xm68fZ1/bDbDUZ1jgTMoFD7yAAy85zfVm84lMYjX23iPzeVHQpZVw4km7XKWpcq+O/hVn4QpiTwBZCR55ya3sfDjWHtw8oNKg7vGM43G46WO8tlZex2A4sFthcPAW0Z7EPrcNf6Ls9c1oiHBtaQZxMJfIVZMmhTEvgK7wBuHq7FpVXjS0RKO73Gl91W87pfJcXty63xFQiP7DKzT0UaCQW+REREGqOCHNj0BWCB4xvB3RumTjc/1DZxuQU2Vh8wA1/ndajBVOeleLpb+eCG/hw+lcvk3i2r1X5050i+33gMgCHtwh3ZYKcL8Pbgin6x/G+dOWPhsr3JGIZR44BOQZGdD5bsZ8OhU1w9II6xXaOqdV5CcnHGV3g5HyhOE+rnWWZfxyh/Zt4xBN8KZlYsqcG1/VgGeYU2vD2q/sAza81hnvllB1GBXrQOM/vVt3hI40U9opm34ySvXdWbbi2CKrtMk9IyuJFnrpUEvkinjfW4uS+sOBOy9PBGZXyJSGnW054jDFvNr1FZcfvK9os0EAW+REREGhu7Df53M+ye49zX62rwP7MgUWOy7mAql7+zAoCYIG/aRZz5w/GgtmEMqkH7B8Z0YHVCKsfT87iwiiDUy1f24p+Tu9P5b3PIL7KTkVtUJqsM4GBKNg/N2sRV/VsxdUArx37DMHj4q038uMkMtC3ek8wTE7vQPz6Uri0Cy1yntITijK+21Qh8hZQT+IoN8S03IFaiZbAP4f6eJGcVsP14Bn3jqs66e/HXXaTnFpKeW8juE1lYLXDvqHYAvDmtL9kFRY66Y03dG9P68OHSBJ66pFtDd6VyJTW+LBm0wJwoguB4c1k68KUaXyJS2ulDHe1nEvgqyfjS3xdpGhT4EhERaSzy0iFpF+xb4Br0iukFo55ouH7Vkk2H07h9+jrH9oiOEfU6LK5dhD9z/nA+G4+kcV77qqdY9/ZwI8jHg/TcQk5k5pUJfBmGwWVvmzXA1h08RbtIf75ae5jU7ALmbj8BmPXG3CwWCors/P37bQC8c21fJhTXxirP/qTqZ3z5lZPVVVWNLYvFQs/YYH7feZLNh9OqDHzZ7Qap2a4zBg5rH07naDOAZ7Vamk3QC2BSrxZM6tWiobtRteKMrxi3TA4UFf/3KcmyKD1sSRlfIlJamcBXUfntKlNQyVBHkUZIgS8REZHGwDDgPxPg5Dbnvgv/Ca0GQ0xPcG/atTJ2n8jk0reWOba7xARyy3lt6r0fQb4eFQ5xLE9UoBfpuYWczMinY5TrN9ubj6S7FL6/9sOV5BW6Fgm+dlAcj1/UhY+WJvD2gr1kF9i4+/P1tI/0Jye/iFuHt+XWUr+HD5fsZ3+yOYSkZEhhZcoLHFZniF7P2CB+33mSNQdOcdOwyv87ZOYVYT9t0q+esc1nSGOTVRz4CiKDTqFukA54FP+3t5SqT+bRyIdsikj9Or2eV20XtxdphBp51U4REZFzxPGNrkGviC4w8A5oNaDJB70ANh5Kc6zfMqwNs/8wvEwgqTGKCvQGYF9SFrPWHiY9x1n4fvPRdJe2pwe9AK4dFI+3hxv3jmrPmifG0iLIvN7ek1kcS8/j/37azuriQv9Jmfk8P3snAFP6tDzj2RF9KqjtVdro4oL+c7cncjw9t9K2abllZ7Xs0TL4jPomtcjXnKnUYthp61l8L7qb95dL4KuZTDYgIrXkbIc62m1QaA7JV0apNBUKfImIiDQ0w4AVb5vrXS+FRxPg9t+bRcCrxL7igu3TBsbxt4u7NHBvqi8ywAwkPPnDNh7932b+8OUGx7EdxzMqPC8myJsXLu9Bp2hncM/X051v7x3Gn8d35v8u7ebIPPv791ux2Q2+3XCEIrtBtxaB/Ouq3mc8DLQ6BeZ7xgYzsE0ohTaDGasOVdr2VKlgX4keyvhqeG4e4FM8TDX9sLksye7S8CMRqcjpga+aFrf/5GLnuv7WSBOhoY4iIiINbf4/YMssc7375eAb2rD9qQP7k8xhEZ2i/Ou1rtfZigp0DT4u3JXkWN9+rPzA1/kdI3jj6j7lFsOPCvTm7pFmUfhJvVpw/osL2JmYydfrjvDTZnNmvmsGxZ1RXyMCvPjHJd3oF191sXqAK/rGsjohlVXFGWcVOZVjZnzFBHmTklVARICXI3NNGphfBOSectbbKcn46nk1bJwB7UY1XN9EpHE6mxpfhgGHlju33fVvgTQNCnyJiIg0pJxUWPmOuT70fuhyScP2p46UFGxvG9G0hkVEBpTNuvtp8zH2nsxiZ6IZ+BrVKYIFxQGxxyZ05s4R7ap17WBfT+4f3YFnftnB//28ncy8ouLrRdaoj1/fPYSPlx3grxO7EBNU/eGRveOCAdhyNB2b3cDNWn5AMq048NU2wo/v7h2Gp5u1SQUvmzW/CEje7dx2ZHz5wm2/NUyfRKRxO73GV0VDHQ2j7FBpW6kM4Av+T0OppclQ4EtERKQhrZ8ORbnmzI3N9CGyyGbnUKpZD6RtRNMaFlFS46u0+75wDnf09rBy07A2LN2bzKSeLbhxaOsaXf+GofF8uuIAR06ZdbZigrxpUY3i9KX1iw+lX3zNswTbRfjj5+lGdoGN3Scy6RITWG67tOKhjsE+nuX+PqQB+Z02O6myL0SkKtUZ6liQA+8Nh1aDYPLbzv22UjUfB95eN/0TqQOq8SUiItKQ9s4zl32ub5ZBL4CdiZkU2gx8PNxoUYOMpMYgLsy30uOdowMZ0TGCrU+P419X9cbbo+rC8qV5ubvx6PjOju3qzORYW9ysFnrGBgOuQzhPV1LjK7icoZvSwPxOm6FUMziKSFXKDHUsZ1bH3XMgZS9s/Nx1f+nAl5tn7fdNpI4o8CUiItJQivLhyBpzvc35DduXOjR3+wkAhncIx1rBcLrGqt1pQzOHtQ9z2S7JkvJyr1nAq7RJPWMcQyov6hF9xtc5Exf1jAHg1Xm7SUjOLrdNyVDHEF99yGl0Tg98NaMJMUSkjrid9iVGeRlfFX0RVzLU0WItO2RSpBFT4EtERKSu7V8E39wBKftc9+/5DYryzA+v4R0bpm91ZPORNJ74bgup2QXM3ZYIwLhu9RvUqQ2nZ3B9dusg3r++n2O7a0zA6afUmMVi4acHzuOZy7pz9cAzK2x/pq4dGEe/+BAKiuws3VN+1pcyvhqxMkMdlfElIlUoU+OrnOL2pbPCbKWOl2R8KdtLmhjV+BIREalLB5bC9OKC9YdXwdTpZj2v/Yvg61vN/W1HNqthjmk5Bdz26VpOZuazKzGTnYmZeLhZGNOlZkXbG4sAL3cy880Hf4vFQtcWzlpYHaLOPvAFEBngzbWD4mvlWjVhtVro0yqYdQdPkZCcU26bkoyvYGV8NT7ewa7bHqrxJSJVKDPUsbyMr1LBscIccCv+d0+BL2milPElIiJSV07uhC+udm6fOgDvj4RV78HMa8xsr7ghcME/GqqHZ+3V33Yz+pWF3PbpWn7YdAyAp37YxsnMfADWHDgFwEU9Ypps4CTA2/VDQstgH7q3DCQ2xIdexTWymrLW4WZdsQMp5Q91PJpmFt4P92+a//2aNa/TAq/K+BKRqlSnuH3pL+O+uAoSlpjrJUMdTx8uKdLIKeNLRESkLhgG/PwwFGRC/DAY+zTM/hMc2wCzHzXbxA+D675pslkaB1OyeeP3PdgN2J+UzbwdJ/h2/REW7ErCajFrQqVkm98O3zCkdcN29iw8MKYDf/lmCxN7mPWwLBYLX989FMMoOxSyKWpTSeArKTOf/Unm/uYQ5Gt2vErPxGlRjS8RqVp1itsX5TvXDy2HTy+Gp9KV8SVNlgJfIiIidWHr13BwqZmBcdm7EBwHN8+GTy6Go2vND6yXvdckg14pWfl8tDSB3ScysRswsHUoLUN8+HbDURYUzw5476j2jOkSxZytifSPD6FffEgD9/rMTe3fig5RAXSNcQYZzqaYfWMTXzxz5eHUHIpsdtzdrNjtBov3JHEiIw+AztEBhPjpg06j410q8OXu3ayGTItIHSkT+CqnxlfpwFdpyviSJkqBLxERkdqWkwpz/2auD3/IDHoBePjArXPNrC+/cAhu1XB9PAt//HIjS/YkO7bvHd2ewW1D8faw8vW6o4zrHs0fx3bEzWqhd6vghutoLbFaLU06cFeVFkE+eLpbKSiycywtj7gwX/6zLIF//rzD0WZw27BKriANpnTGVxMMootIAzi9uH15Qx1tFQW+ijO+rAp8SdOiwJeIiEhtKsgx62FkHoOQNjD0AdfjVjeI7d8wfasFB5KzXYJeAEPbheHhZuW5KT355+QeWC3mcEBpGqxWC52iAthyNJ3/rjxAUmY+32085tJmUJvQBuqdVKp0xpdFpXtFpBqqU9y+vIwvw9BQR2my9C+kiIice9IOw5fXwcxrIfdU7V3XMOC7u+DIavAOgmkzm1UWxqGUHP72/VaXff3iQ/Bwcz5OuFktCno1QQ+M6QDAB0sSygS9AAYq8NU4efo710uGIImIVKY6xe1LAlyl5Z7SUEdpspTxJSIi55bCXLNI66kD5nbqfrPAfGDM2V97xw+w/XtzCMC0mRDZ+eyv2QDsdoPtxzPoHB2Ae3FQKzE9jzH/WkihzQDgT+M6sWRPEv+c3KMhuyq1ZGyXSNqE+5GQXP7MjmH+KpreKJUeslTeB1URkdOdPkyxuhlf2UnK+JImSxlfIiJy7sg4Zg5DLAl6AZzcDt/dba7bimDtxzDnsTPLnlj6mrk8748QP/QsO9twZm9N5OI3lnLvF+sd+xbuOukIeo3tEsW9o9oz844htI/0r+gy0oRYLBXXYxvWXvW9mgRlfIlIdZxe46u6ga+sEwp8SZOljC8RETk3FOTA9Eshebe5fflHEN4B3jsfDq2ALf+D7++FInMWOzpcAO1GV3y9rJPw80PQdhQMuNUc5pi0yzzW86q6fS91bP6OEwD8uu0EC3aeZFTnSEddr9vOa8OfJzTNTDapXK/YIL7dcBSA/9zUnx4tg/lkeQK3nte2gXsm1VLecCURkdNVa6hjeYGvk+azDmioozQ5yvgSEZFzw6LnzaCXTwhM+xJ6XAFRPcDDzwx2zX7UGfQCSNlX8bUKsuHtIbDjR/jlEXNfZiIUZoPFDYLj6/a91LFCu+FYv/XTNby3aB+L9yQBMKFHjEtNL2k+urcMcqx3iQkkIsCLP43rTKifvtkXEWk2qlXcvpyh01knwV5S40v/LkjToidXERFp/jKOw6r3zPXJ70Cn8ea61QpR3cz1nBRz2WmiuUxNMLPEvr0btv/gvJbdDr8+DjnFMxsadshJhZS95nZwHLg37QfC42m5gFmo3m7Ac7N3kplXRMcof3rFBlVxtjRVPWOD6RMXzMhOEUQHNp9JGUREpJQzzvjSUEdpuhT4EhGR5m/eU2Y2V6tB0HG867Ho7s71sPbQbpS5fioBNn1h/sy63szyMgz45jZY94nrNZJ3Q+o+5zWauOPpZubbF7cNok9cMABD24Xx+W2DHcXupfnxdLfy7T3D+OTmgZqZU0SkuSpT46uobJvyanwVZGlWR2myVONLRESatzUfweaZgAXGPQenf6CP6e1c73QRhLYx11P3Q3Kc89h/p0DmMUg7ZM6INPEVcwbHffNh1o3OLK+wdnX5buqczW5wIsMMfMWF+TLj9sEkZebTKtS3gXsmIiIiZ63MUEd72TblBb4Kc5XxJU2WAl8iItJ8HVlrFqAHGPYHiO1Xtk2vq83ZHoNaQs+rIf2wuf/UAUjc4mx3eKVzfdRj0O9GOLnDDHxlJTqPNfGMr+SsfIrsBm5WC5EB3rhZLQp6iTRmvmHmUG2rMjBEpBrOdKhjYY4CX9JkKfAlIiLN1/I3zGW3KTD2qfLbuHuZgawSwXFmgfqiPDi4zNzXbjQcWgUdx5k/Paaa+8NPC3J1HA/dLqvVt1DfjhXX94oK8MLNquFuIo3e9d/B3L/C6L83dE9EpCk40+L2hbka6ihNlgJfIiLSPGUcM2ddBBj+UNkhjhVx84D2Y2HPr8XbnnDNLDMYZj2tvlWPqXB4tRlY6zS+7LWaoJ2JmQDEBPs0cE9EpFpiesKNPzZ0L0SkqXBTxpecexT4EhGRpsswYPm/ITfNLEq/7VszGBU/BDbNMB/mWg2G6B41u+6IR52Br743VPzNpncgTHn/rN5CY2IYBp+vOgjAmC6RDdwbERERqXVlMr7KK25fUcZXSeBLGV/StCjwJSIiTdfuX+G34uE9S/9lLtdPN4vYb/jc3O57fc2vG9sfLv/ITP/vObV2+toE7D6RxdajGXi6W7l6QFzVJ4iIiEjTUp2hjuVmfJUe6qiML2laFPgSEZGGZRjmQ9fpqfdVyUuH3/9Zdr+9CGb/yVz38IOuk8+sXz2uOLPzmrDtx9MB6NMqmFA/PdSKiIg0O2WK25c3q6M5uzO9roE2w+G7uzXUUZo0a9VNRERE6khRAbw9GN47H/Kzqn+eYcBnl8OJLebD17SZENEFJv4Lht7vbNf1UvDyr/1+N1N7Tpj/DTpE6XcmIiLSLNWkuH3vaRDVzVx3Geqo/BlpWnTHiohIwzmyBpJ2musLnoHxzzmPZSZCTgoEtoT/Tja3RzwK/W+BpF3muQDTZpjF6DtNMLcLc2H795B22Gwr1bbnZHHgKzKggXsiIiIidcLq5rpdXo2vkqGO7t7g4WuuF+ZoqKM0WQp8iYhIw0lY5Fxf9S50HAcxveFUAsy6AdIOmRlcxzaYbRY+D54BsO5jc7vDhWbQqzQPH7hlLmQcNWt1SbXtdQS+lPElIiLSLJUZ6lhJxpebp/lcBWaJid1znPtFmhAFvkREpP6dOgi7foGV75jb/lGQdQKmX1q27fI3nOtZJ+Cb25zbJVlepwuMMX+kSoZhkJFXhN1ucDAlG4D2GuooIiLSPNWkuL27lzPjCyD3lLnUrI7SxCjwJSIi9SsrCT6+CDKOmNtWD7j2K5j/D9g7HzCqvobVHdpfAN3PvQL0NfHT5mO8OGcXblYLH9zQj/aRAdjtBlarhZyCIrzc3bjn83X8uu2E45z2kf5E+Hs1YK9FRESkzlSruH1x4Kt0xldpyviSJkaBLxERqT+2Qpj3lDPoFdLGrOsV0wuu+xryMiD9MLwz1PW8oFYQ3hH2zTe3/5YMFku9dr0p2Xg4jd93nuTtBXspspuBxDd/38v9Yzpw/YeryC20kZFXhM3uGmT093LnrWv6YtHvVkREpHkqk/FVTo2volIZX+7eZY8r8CVNjAJfIiJSP46sgw9HO7dv+RXiBru28Q4E724w6C6z5leJsU9BdE9zOu2Rf1HQC8grtPHV2sOE+HlSUGQnv8hOTJA3i3Yn8fGyA452EQFeJGXm893GY3y38Vi51wr0dqdbiyCeuqQbnaJV2F5ERKTZOj3wdXKHGehyL872ttvBXlLE3st85nLzcg5/BA11lCZHgS8REakbJ7ZBwhLodRX4hMDSfzmPhXeCVoMqPnf88zDuOdjylTmzY/fLzQev2+fXfb8bsbnbEll/KA0PNwtvLtiLUcmo0MFtQ7miXysu69OSaz5YyaqE1DJtJvduwV0j29E5OrAOey0iIiKNxumzOu74AT6/Am780dy2FTiPlQTDSge9QBlf0uQo8CUiIrUvLx2mT4bsk/D7/0FEJzi6zjzmHQzjn608a8tiMX96XVUfvW0SMvMKue+LDRTYXGtxhPt70jk6EDerhRMZeYT5e3LNwHgm9nQW93/xip5c/O+lZOYXERngxclM8wH2n5f1wN9LjwIiIiLnjNMzvgASFjvXi/Kc6+4V1PxU4EuaGD3tiog0hAPLICgWQuIbuid1Y8m/zKAXQEGWM+jV+WK4+vOG61cTtmRPsiPo1S7Cj0AfDy7r05IbhrSu8tz4MD++v28YabmFeFitTH57GSM7RijoJSIicq5x84BJr8Mvj5bN5ALnzI3uPpUEvjTUUZoWPfGKiNS3kzvgk4vM9SfTmke9KlsRLHzODHb1vxW2f2fuH/88LH8TCrPhsveh/dgG7WZTNn+HGUi87bw2PHFx1xqf3zbC33mth0YQ5q9va0VERM5J/W6CtEOw5JWyx3KLSyP4hlV8flFBxcdEGiEFvkRE6tuxDc71o+sgtn/D9aW2bPwMlrxsrq+fbi6tHtDnOuh7o7nt6dswfWsGDMNg8Z4kAEZ3jjzr67UO9zvra4iIiEgTZnErf39OSeArpOJzc5Jrvz8idcja0B0QETnnZJ10rn84BrZ91zD9OLkTfv0r7PzZXC9t7zx4rQe80hm2fuPcf3yTOUzTVmrq68I8WPRi2evHDQavADPgpaDXWTmQkkNSZj6eblb6xlfyICoiIiJSHacXuS+RU0XGl7sPdBxfN30SqSPK+BIRqW9ph1y3v7sbQttCTE/nvqICWPOhub/9WHCrgz/Xi56Hbd/CijcBC0x+G3LTYM9c2L/A2e5/t0B2MkR1cw7RHHA7TCzO8Fr7H8g4CoEt4aaf4Nu74fBK6HN97ff5HLU6IQWA3q2C8fao4EFVREREpLoqzPgynznwCS17zCsQHt4Jnsocl6ZFgS8RkfpWEvjqeyMcXAYpe+E/48ygUVEBFOUWZ2M9ZrYLiDHbDn+o4iKjZyJxS6kNwwzAlRbWHmJ6wdavYfafwDOg1LmbzWXyHlj0grk+4s9moO6WOZCfAd5BtdfXc9zCXeYwx4FtynkIFREREampijK+yqvxZXUHexHEDVHQS5okBb5EROpbSeCr+xQY+xTMugEOLIEPRgMWwHC2dfOEzONmdlZ4B+hxRe30oSgfUhPM9Qe3wdLXYM0H5uud9yB4+puvFRAD0T1hwTNQkOk8P/M4GIaZDZaXBi37Qe9rzGMWi4JetWj2luPM3pqIxQIXdI1q6O6IiIhIc1DhUMfijC/fUl+23b4A1n0CI/9S590SqQsKfImI1Ie8DNg0E7Z9A8m7zH3BceZDxZQP4I2+UJiDS9AL4P71MPcJc5bEk9trrz/Je8CwgVeQOURx4svQc6oZ8Io6bcbA8/4InS82Z/7xCYaVb0NmopmtlrgZPHzh6hma2rqWLd+XzM0fryG/yA7AHcPb0qtVcMN2SkRERJqHKovbl8r4iukJF/+r7vskUkcU+BIRqWup++Gzy81laYGxxcsYuOQN2DTDHFrYoo+ZSdX+AghuZRaJ3/4dJO2qvT4lFRezj+xsZmgBtBpYcfvw9nDZO+ZQzJVvg60AlhQ/APW4EgKUiVRb8otspGQV8MCMjY6g19gukfxpXKcG7pmIiIg0G6dnfBmG+UxYWY0vkSZKgS8RkbqUtNssCJ+dZAa6ek+DtMNmwMnd09muxxWuwxgf3mXOiAjmEEeA5N1lr5+fCYdXQ7vRzgBWdZzcYS4jOtfs/bh7gm+4OY31vvnmvpIhjnLWZqw+xDM/7yAr35w1s2WwDy9f2YsBrUNwd9NEzCIiIlJLrKeFAmwFZi3Z3FPmtq8CX9J81PgpevHixUyaNIkWLVpgsVj47rvvKm3/zTffcMEFFxAREUFgYCBDhgzh119/PdP+iog0LUv/ZQa9onrA7fNh9BMw5T0OdL6DjLzCis/zDXUOHQwvzvRJ3Q+24nMyE+Hr2+ClDvDZFPN1jqyDgyuq1y9HxleXmr+ngGjnulcgtOxf82tIGTkFRTz5/TZH0MtigTev6cOQdmEKeomIiEjtspz2bFGUby7Lq/El0sTVOOMrOzubXr16ccsttzBlypQq2y9evJgLLriAZ599luDgYD7++GMmTZrEqlWr6NOnzxl1WkSkSbAVwq7Z5vqE5x0Bo4Mp2Yx8eSFtI/z4/eGRVV8nsCV4+EFhNvxnvJk1lnEctnzlbDP/H8A/zHWvQGjZF9y9IaKTWaze6mE+0PgV12soyfg608DXia3meuvh4Kbk4dqwfG8KBTY7Ph5u3H5+W1qH+dInLqShuyUiIiLN0elDHW0F5jK/eDIjr8D67Y9IHarxp5UJEyYwYcKEard/7bXXXLafffZZvv/+e3788UcFvkSkebLbYdELsHeeOeOhb5g5/XOxhbuSANiflE1+kQ0v9wqKi5awWqHdKNj5Exxda/5UJj8D9i8013fPMYdbZh4zZ5O8ZxV4BzrrjUWcQeCr9DeEHS+s+flSxqnsAp7+aRsAl/dryUMXdGzgHomIiEizdnpx+5KMr5LRBW6eiDQX9f41vd1uJzMzk9DQilMn8/Pzyc/Pd2xnZGTUR9dERGpHwkJY9Lxzu9c0l2/V7IZz5sYfNx1ncu8WVQ9lmzrdzLJa9T5s/My5f9Lr0G0KbP8eivLMhxV7EfiEmMMhF/wTds92tl8/HZa/ARjmjI7+kTV/f60Gwp65Zm2I3tfV/HxxYbMb3PTxag6n5gIwposmChAREZE6Vibjq/jzt72o+Lgy+qX5qPe7+eWXXyYrK4upU6dW2Oa5557j6aefrsdeiYjUoi3/M5edL4YRj0J0T5fDx9PzHOuPfLWJhbtO8uY1fSu/ptXNnPHxohfNGR4LsgAL9L3RLAbV9/ryz8s4Aus+cW4vet75QBPapmYF8Uv0v9X8FrDnVRrmWAtmrD7EpiPpeLpb+efk7ozsGNHQXRIREZHm7vTAVlG+ObOjYTO3S2rNijQD9Vot94svvuDpp59m1qxZREZWnGXw2GOPkZ6e7vg5fPhwPfZSROQsFOTAjh/N9SH3msGq04JLR9NyXbZ/2nycnzYfq971Pf3gzsVmba1Jr1UduOowznW7JOgFMOjO6r3m6XxDYdgfXIvcyxn737ojADw6rhNT+7fCcibBSBEREZGaKK+4va3UxEvK+JJmpN7u5pkzZ3Lbbbfx1VdfMXbs2Erbenl54eXlVU89ExGpRdu+MWtsBcdDq8H8vvMED365ifgwX16+shcdowI4flrgC+Bv321lcNswwv2r8bcvrB3c9FP1+tP6vPL3X/U5dLm4eteQOnM4NYeNh9OwWOCSXi0aujsiIiJyrjg98GUrcP2CVIEvaUbqJeNrxowZ3HzzzcyYMYOJEyfWx0uKiDSMtf8xl/1vxo6F537ZSXpuIZuPpPPAjA1sP5bB+kNpjuZPTupKl5hATuUU8sGS/S6XMgyDnIIijFI1wWrMOxC6Xw6e/uawyBKx/c/8mnLGbHaDQpsdgEMpOUz7YCUAA+JDiQz0bsiuiYiIyLmkdJALzIwve6mMLw11lGakxmHcrKws9u7d69hOSEhg48aNhIaGEhcXx2OPPcbRo0eZPn06YA5vvPHGG3n99dcZNGgQiYmJAPj4+BAUFFRLb0NEpBHIPAFH12Fg4aYNHVj16xzyCs0gh9UCOxMzuejfSxzNV/91DJEB3sSG+HL79LW8t2g/+05msfdkFsG+nuQV2tiZmMnzU3pw9cC4M+/XZe+bDzKZx2HzlxDeQcMU69meE5k89eM21hw4hY+HGx/fPIA/ztzIkVO5hPl58ucJnRq6iyIiInIusRW4bhflg93m3FbGlzQjNb6b165dy6hRoxzbDz30EAA33ngjn3zyCcePH+fQoUOO4++//z5FRUXce++93HvvvY79Je1FRJqNhMUAZIV0ZdFRC2AGve4f3R6rxcLr8/c4mgb5eBDuZw5rHN05ktZhvhxIyWHejpNmg5QcR9tFu5POLvDl5m7+hLaFe1aCV+CZX0tqzG43uH/GBnYmZgJQUGRnytvLAYgN8eGbu4cq20tERETqV+l6XmDO6ujYZyk766NIE1bjwNfIkSMrHXZzejBr4cKFNX0JEZGmaf9CAPb49XPsahPux72j2nPkVI4j8NUlJpAXL++J1WoWMXezWvjPTQN4bd4eCm12/L3c+aq44DnA4VPOINhZC21Te9eSKhmGwbuL97EzMRMvdyuvX92HP321icx8c3jBk5O6KeglIiIi9a/cjK/i4Y/K9pJmRne0iEhtKCqA3XMAWGbvDsCIjhG8dEVPvD3caB8ZwJC2YWw6ksY71/aldbify+ltI/z597Q+ju27R7YjM6+IS99axqGUWgx8Sb36YdMxXpyzC4AHxnRgfPdo2kX48dKvu4gJ8mZsl4pnOBYRERGpM6cHvmwFzhpfqu8lzYwCXyIitWH3bMhJBv9ovk1rB+Rzx/ltXbJ5/nPTAHILbYT6eVZ5ubYR/mQXZwVl5BWRnltIkI8eQpqaz1YeBOC6wXHcM7IdAB2iAnj/Bk0uICIiIg2ovIwvW0nGl545pXmpl1kdRUSavY0zAMjtOpX9qfkAdGvhWkvLx9OtWkGvEn5e7oQVtz+cqqyvpmb7sQzWHDiF1QL3jeqAxWJp6C6JiIiImNqMcN12Geqo+l7SvCjwJSJSlWMb4cc/wMIXoCDb9VhBDqyfbmZ8AYu9zck/urUIJNi3+kGuirQK9QXgSG3W+ZI6VWiz8/3Go9z26RoAxnePJjpIdbxERESkEYntD7f/Du1Gm9u7Z0Nh8fOmhjpKM6OhjiIilUncAv8ZD0W55rabBwx/CHJS4ZOL4eQ2Z9vgeL49EgjkMqZLVK28fFyoLxsPpzF9xUFGd47C013fVzRmhmFww0erWbE/BYAwP0+euqRbA/dKREREpBwt+0FgS3N93+/gFWCuq7i9NDP6BCUiUplNM51BL4Dt35nLvfNcg16A0f0KlhUHPMZ0rp2i5TcObY2PhxvL96Uwf8eJWrmm1J0Fu046gl73j27PD/efR2SAsr1ERESkkXL3cq5v/95cKvAlzYwCXyLSvOyaA9/cCWmHKm93YCkkLDbXk3abszKW5+Ayczn+ebC4wfFNkJoAxzY429zwA1z8Ksd73kNmXhEebha6xASWf70a6hcfwtiuZvbYsfS8Wrmm1J2Plx0A4I7z2/LwhZ1oGezTsB0SERERqYylVD0vr+LnVwW+pJnRHS0iTVvGcfDwAZ9gsBWatbiyEmHr1xA/1KzP1eVimPy22f73Z2Dxi+a6xQpjn4Lf/g6dJsLVn0PpAuT5mWagC6DLJNg1GxIWwY4fnIGvy96DtiOg7Qh27TwJQNtw/1odklhS4D41O7/WrnkuOJ6eS1ZeER2izLT9nIIikjLzSc8t5GBKDgdTsjEMaBfpz6hOkfh41qyQq91u8P2mo3SODqRLTCCGYbDpcBoAk3u3rO23IyIiIlL7TiU4131DIT9DNb6k2VHgS0SarrTD8PZgCG0Ddy6BnT+ZQS8Ae6EZpALY+AWMfgKS9ziDXgCG3Qx6Aez6GT6/Ei59CwKK63MdXG62CY6HoFjoeql5zZJzAFr0cazuOpEJQMfogFp9myG+JYGvCrLSpIy8QhuXvrmMk5n5xAR5k51fREZeUYXtu7cM5OlLuvOfZQkE+XgQ4O3OIxd2wsPNit1uYLHgMitjkc3Oo//bzDcbjtI+0p95D40gKTOfjLwirBZoF+lXH29TRERE5OykHXau55vPslgV+JLmRYEvEWm6Ns+EgiyzAP3Twc79Qx+AwBaQdcKsxZW4BZa/CSe2Vn69vb/B17eaQxezEmHNR+b+DheYyy6T4OeHnO19wyCsvWNzd6L5sNApyr8W3pxTqL8CX9Vhsxt8vCyBOVsTWXvwlGP/8VJDRL09rAR6exAX6kt8mBmcmrs9ka1HM7j8neUu1+sSHUjP2CAufXMZF3SN4sELOnI8PY+YIG+e/nEb83aYGX57T2aRkVfInpNZALQO88PLXdOAi4iISBNwwdPwxVRzPS/dXFr1HCPNiwJfItJ07fyl7L4WfWDEo85ZaQJiYPajsPItZ5v71pkZXFu/hp8eNANbXS6B7+6GA0vg3fPg5HbAMNt3u8xc+kfCoLvMul9dL4UO4xwPBja7wbpDZrClZGhdbXEOdVTgqzIvzNnJ+4v3u+y7fnA8k/u0IMjHg6hAbwK8y36D+fW6MB7+alOZ/T9tPsaWo+lk5hfxzYajfLPhqMtxDzcLnm5Wsgts7DyeyZ7ijL/2kbUb+BQRERGpMx3HwaTXzXIh9uLseA11lGZGgS8RaZqW/RuOrXfdN/Zp6H+zM+gF0O8ms87Xpi/Mbd8wCC/O0upzLXS9BDz8wGo1hzX+cL/rbI0BLSBuiHN7wgvldueXLcc5mJJDoLc7Q9qFnfXbKy20OPCVosBXuQzD4PuNx/hwiRn0uvP8tuxLyiYpM48/ju1AmL9Xpedf3i+WVqG+rNyfwhX9YsnKL+LCVxc7MrpKWCxgFMdC+8eH8NQl3Xht3m7m7TjJrZ+scUxooMCXiIiINCm+4a7bKm4vzYzuaBFpegrzYMEz5vrYp8Bug/hhED+kbFt3L7jsHTMza8N/YdgfXI+XDpL1nmYWvP/2DnO743jz+tVI95611qyPcMt5bQgsJ6vobCjjq2L5RTZu+s8aVuxPAeDyvrE8dlGXGl9nYJtQBrYJdWwP7xDOkj3JAAR4ufP57YOID/PDbjfYn5xF37gQLBZz9s55O06SmV/E6gOpAPRqFXz2b0xERESkvnicNgu1Al/SzOiOFpGm5/BKKMozhzEO+6PrTIwVmfQ69L0BWvarvF2PK2Hr/yDzOFz+EXiVn72TlV/E1e+vYFi7cP4yoTMbi2fzu6BrVM3eSzWUZHyl5RRSZLPj7lZ7M0Y2dUv3JDuCXn8c24H7RrWv4ozqef/6/rw+fw+HT+UwtX8resYGO47183MGyIa0DeON3/c6tsd0juTCOrgHREREROqM52mT8ijwJc2M7mgRaXr2LzSXbUdVL+gFZtZWq4HVaGeFa7+qstmahFS2Hs1g69EMvl5/hMy8IrzcrXSs5fpeAMG+no5hdqdyCokIqHzo3rlk8e4kAKYNbMUfx3astev6eLrxlwmdq2w3tH04P91/HhEBXqxKSOWCLlEusz+KiIiINHoevq7bqvElzYzSBkSkabEVwvYfzPW2IxqsGxl5hY715CxzCGL7SH886iAby81qIdjHfAA5F4Y7pmTls/ZAKkZJQa0KGIbB4uLhiCM6RtZH18rVvWUQUYHeXNKrBT6emgVJREREmpjTA19WBb6keVHGl4g0LWv/A6n7zCL1nSY0WDfScgrL7KuLbK8SrUJ9OZWTzku/7uS5KT0dWV+FNjvH0/KIC/Ot4gpNw5ytx3lg5kYKiuyE+XkSG+rL57cNwt+r7D9X01ccJCE5G093K0Pb1+6EAiIiIiLnDM/TA1/6Ik+aF2V8iUjTsuNHczn8EfAOarBunMoxM6+mDYxjxu2DGd4hnHtHtauz17u3uHbVvB0nufiNJRTa7AC8MHsn57+0gJ83H6+z165rn608yPQVB3j1t93c/fl6CorM95aSXcCmw2n8tj2RNQdSGf3yQsfMjWk5BbwwZycAj03oXOsTCoiIiIicM04vbq+hjtLMKONLRJqWtIPmsmXfen9pwzAc9ZtKMr5CfD0Y0i6MIe3qNuPowq5R3D68DR8sSeBERj5rDqSSkJzNh0sTALj3i/X0jB2FzW7QOtwsUGqzG7hZK643VWSzc6yBs8USkrN54rutlbZZuS+VL9duAuCfP+/Ay8ONBTtPklNgo2tMIDcNbV0PPRURERFppjxU3F6aN2V8iUjTYSuC9KPmenDcWV0qJSufpMx8th5Np88/5vLuon0Vti202Xnqh230/sdvrD90CjAzjgBCfD3Pqh/VZbFY+OvErlzUIxqAP321mb9+6xowGv7iAib+ewlJmfn8uOkYnZ6YzZXvLudwak651/zXb7s5/6UF/LDpWJ33vzzbj2Vw92frXPbdNLQ1m5680GXfl2sPu2z/7but/L7zJAB3jWynYvIiIiIiZ8Pd0zXYpRpf0swolCsiTUfGUTBs4OYJ/tFnfJm8QhsX/XsJBUV23KxWTuUU8vzsndwxvC3W0zKkEtPzuOr9FRxMMYNHX609Qt+4EE4VZ3wF+dbvg8Gw9uH8siWRo2m55R7PLrAx4Jl5ju01B07x4JcbefvavuQV2h3ZXYZh8PZCM9j3wIwNXNKrRd13vpT5O064DGsEmNy7BU9O6orFYmFouzCW70up8PzYEB/uHNGOST1j6qO7IiIiIs2bhy/kZ5jrbgoTSPOijC8RaTpKhjkGtQLrmf35KrLZ+X3nSU5k5HMqp5DkrHzHsbaP/8LqhFSX9p+vOugIegEs3p2EYRik5ZYMdayfjK8S57UPL7Pvgxv60zLYp8x+bw8rXu5W1h48xcBn53P+Swsc7zchOdul7daj6XXT4XKsOZDKPaWCXp5uVpb/ZTSvXd3Hkb311jV9+fjmAY5z+sQF8/yUHgBc2S+WpX8ezfWD45XtJSIiIlIbSs/sqKGO0szojhaRpiPtkLk8i2GOD87axI+VDO2bvfU4A9uEOrY3HEoD4C8TOvOvubs5mpbL/uRsx1DH4HrO+IoL9aVlsI8j42vhIyNpHe5H//gQjqblcs/n6/HxcOOeUe0Y0TGC1+bt4ZPlBxznbz6SxujOUSzZk+xy3Qe/3MgP952Hj6c5i49hGBxPzyMmyPuMg0vL9ibz9sK9+Hi48/zlPdh+LINl+5L5ZNkB8ovsjOkcyVOXdCOnwEaL0wJ3IX6ejOoUyUMXdCQxI4/HL+qCn6cbHaMD6NGy4SY1EBEREWmWShe411BHaWYU+BKRpiPJnMWPkPgKm+QV2jienkebcL8yx3ILbC5Br0m9WnBR92iigryZ8vZyAA6UyoSy2w02HU4DYHiHcBbtSmLF/hRW7EtxKW5fnywWC+e1D+fLtYfx8XAjLtT8di7Ez5MQP08W/WkkhoFjyOagNqEuga8jp8yA2c5EM5V92sA45u84wZ6TWUx6cykvXN6DvnEhPPXDNj5dcZAuMYH836Xd6BMXUmmh/PI88d1WR2ZZ/3+ecDk2omMEb17T1xFoq8gDYzq4bPeNC6lRH0RERESkGjxLPTtbK38+E2lqFPgSkcZv3+9waBWseMvcbtEHcNapigv1xdvDjf7xIfz9h238uOkYd5zflscmdHbJVlqV4KwZFejtzpOTuhLu7wXAjNsHM+2DlewvFfjal5RFZn4RPh5udIoKYECbUFbsT+GpH7ZRZDcACPKp36GOACM6RfDl2sP0iA0qU5PMYrFQOkGrf+tQl+P7k8z3d6i44H2/+BDGdI7ktulr2Xsyi8vfWeHSfsfxDK54dwUtg3346f7zCPGr3vs9lJJTZjhlRIAXw9qFcWG3aMZ1i65xIE1ERERE6kjpjC83ZXxJ86LAl4g0Psl74PAq6Hk17J4NX17nPNbnevMHWJ2Qyku/7nIcGtslink7zMyi9xfvZ9neZDLzihhdPKSuZHjflL4t+b9Lu+Pn5fwT2DbC/JbrcGoO+UU2vNzdWHPAnMGxZ2wQ7m5WBhYHkUqCXlD/Qx0BJnSP5qUretIvvursp4gAL9ysFmzFfS4J7JUEvuJCfRnYJpRHx3fipV93YRS/NYsF7hrRjoMp2Y5i+l+sPsTQdmH8vvMkl/RqQYeogApfd9GeJAB6tQomPaeAnAIb3907rMyQRhERERFpBFTjS5ox3dEi0rgU5sJ/p0D6Ifj+XtdjHSfApNfB6obdbrC4OLhSoiToVWLbMXM43yfLD3Df6PZsOGQGskZ0jHAJegFEBnjhbrVQZDfo93/zWPbn0SzfZwbKhrQLA8wC66W1DffDw63+5wixWCxc2b9Vtdv/+sfz+XzVQT5edoB9J7OYvuIAh1PNIY8lQyXvGdmeaQPi+Ms3m2kd7sd9o9oT4G0G9WatOcyjX292CTJuOpLO9FsGurzO1qPpJGflk1tg463f9wJwYdcobj2vDXbDwNdT/+SIiIiINEpepb7QVI0vaWb0KUREGpflb5hBr9ICYuDWuRAY65jN8ar3Vzgysk43rlsUW46kk5xVQIHNnDnwly3H2ZmYCUC3FoFlzrFYLLQO92PvySyy8ovo9Y+5jmND2pqBLz8vd64dFMe6g6d4/vKejqBRY9c+0p/7RrXn42UHOJqWy9+/3waAh5uFyAAvR7sQP0/eu75/mfMv7dOCj5cfYMfxDMe+zUfSMAzDMZR0ztZE7vpsXZnXvXZQHN4eqhMhIiIi0qh5BzvX3RQmkOZFd7SINB7pR2DJv8z10HYQ0hr6XAetzwP/SEez/UlZLkGvaQNbsfFwuiMwc9PQNnSJCcAwYNbawzw3e6cj2OPtYaVNuH+5L3/n+W350/82u+zzdLfSu1Sm1zOX9aiFN1r/wvy96BMX7JilEqDQZpSpEVYeL3c3vr1nKKsSUgnz8+TSt5aRllPIsOd/Z1TnSDLzivh1WyIA8WG+eLhZGdw2lD+O7Uiwb/3XQBMRERGRGvIuNWu2hjpKM6M7WkQaj9+ehKJciBsCN8/GpUp7Kb/vPOlYH98tmmcv68HBlBze+H0vV/aPZXBxhhbA1P6t+HzVIUdNq3YR/hUWVb+yfyviw/yY+p6zwPvfJnbBy715ZCxd1b+VS+CrbTkzX1bE28ONER0jAGhTnBl3LD2Pz1c5s/PGdoni3ev64t4Awz9FRERE5Cz4BDvXNdRRmhkFvkSk4RTlg73InD758GrY+j/AAhNeqDDoBTiyi/52cVduPa8NAK3D/Xhlaq8ybUP8PJl+y0BGvrwQoMrhiX3iggnwciczv4h5D51P+8iKC7g3NZP7tGRVQirRQd4UFNmZ0rflGV2ndH20S3q1oE24H+0i/bm4R0y1MshEREREpJFRxpc0Y7qjRaRh5GfBh2Mh7SB0HAfbvjX3974WYsoGsEos3p3EmgOn8HCzML57dLVeqnW4Hx/fNIB//babO85vW2lbDzcr39wzlMz8omYV9AIza+vVq3qf9XUeHNuBuz5bx/9d2r1GRfZFREREpJFSjS9pxnRHi0j9yzwB398DSTvM7ZKgF8DQ+yo99b8rDwJw/eDWtAz2qfZLjuocyajOkVU3BDpENa+AV20b2SmSHf8Y7yhsLyIiIiJNnMtQR4UJpHnRHS0i9SszEf4zDk4dKHuswziI7FLp6QnJ2QCMrmYQS+qGgl4iIiIizYjLUEfV+JLmRYEvEalfi182g17B8XDlxxDSBtw8ITsJAiofumgYBkdOmUXqW4VWP9tLREREREQq4TLUUYEvaV4U+BKR+nVsg7kc+yS07Ofc7+Vf5alJWfnkFdqxWqBFDYY5ioiIiIhIJUpnfFk0Q7c0L7qjRaT+2O2QtNNcj+pe49MPp5rZXjFBPni46c+XiIiIiEitKF3jqyivwbohUhf0yVGkMbLbYPv3kJ3c0D2pXemHoSDLHNoYWvnsiuU5nJoLaJijiIiIiEitcvd2rhdkN1w/ROqAhjqK1AVbkTlTYcu+ENau+ucV5sLMa2Df7+Z225Ew+m/m8MA+14OHd6WnN3ont5vL8I41rh1gGAY/bT4GQKsQ39rumYiIiIjIuav0xEUFWQ3XD5E6oMCXSG3Lz4Lv7oYdP5jbEZ1h/PPQblT57YvyzWLvYe1h9xxn0Atg/0LzB+DgchhyL/iGVpwtVZANFrfGGyA7ucNcRnSu8ak/bDrGvB0nAegQVXU9MBEREREROQN+EQ3dA5FapcCXSG05dQDW/xc2fgGZx5z7k3bCN7fDw7vBWs7o4rl/g9XvVX5tixW2fWP+eAXBfavBNwyOrofYAeZ1T+6AjydAYR4MfwhGPFqrb69WpOw1lxGdanzqL1uOAzC8Qzg3Dm1di50SERERERGumQX7F0HPqxq6JyK1SoEvkdoy8zo4scVcD4qDiI6wd565nZ0En14M8cOgz3UQEu88b8/cste6Za45RHLl29BxPGSdgB//ADkpkJ8Os/8M4R1g8UvmEMiJr8DMayH3lHn+gmcgOB56NbJ/tFL2mcuaDP8EUrLyWbrHrHf2x7Ed8XJ3q+2eiYiIiIic2zqOM39EmhkFvkRqQ9phZ9Dropeh7w1gdTfrfCXvgUXPw8Fl5s+y12HM32HwPVCQCacSzPOu/w6WvAJeAc4srjF/d75GuzFwaAV8djls/865f8N/4fgmSN0H/tHmkMpNM2Dj540w8FWc8RXWvtqnbD2azsVvLAXAw81Cz9igKs4QERERERERMSnwJVIbSjK7Wg2Cgbc79/e4wlx2ngj75sOeeXBwKcz9KyRugT7XmseD4syAVUV1wAA8faH9GLjiP/C/m12PJW42lyMeNbOpNs0ws8QqkrIPFr3obF8fctMgp3iWyipmdPzfuiMs3p3EjUNb8+evNzv2j+4ciYebJqMVERERERGR6lHgS+RsndwB854019uPLb9NTE/zZ9gfYd0n8NODsHmm+QPQolf1X6/7FDOLbOGz0P9WM2Ns3wLodbU57DF1v9kuM9EMNvkEl73GF1PN7KuUvXD7fDiy1pxRss3wsm3z0s0C/P6R1e9jeVKLhzn6R5tZbRX4fuNRHvlqE2AWtAdzkpnnLuvBuG7RZ9cHEREREREROaco8CVytuY9bQaHAmLMwFNlLBbofzPs/Bn2/ubc32ZEzV5zxKPQaYJZJN7qbr6+b6h5rCRAlZcGL8TDVZ9Bl0nOc7OSnEMOj66FnFT4cIy53Wmied0+15mBMDdP+OhCyDgGD2wAv/Ca9bO0I2vNZSXDHFfsS3EEvUp0bxnIXy/qypB2YWf+2iIiIiIiInJOUuBL5GzkZ8G+3831q7+AwBgA7HaDudtP0K1FIK1CfcueN+wBc3hkVHe44OmaB74sFjODrERJ0AvAJwTcvMCWb25/cyf8tVTga8f3rtea95RzfdfP5k/CItjylWu7Qyuhy8U162eJwjyzthlUeI0Dydnc8d+1FNoMJnSPZlKvFuw4nsG9o9rj7aFi9iIiIiIiIlJzCnyJnI19880AU0hrvj4ewdKlG3lsQmdenbeHGasP0Ss2iPdv6E9kgBcWi8V5Xpvz4cFtEBAN1loO6lgs4B8F6YfMbcMGh1ZBbqqZzXVwhWv79Z+WvcbpQS+AE9tcg1aFeZB2EMI6wG9/A09/6Hu9+dpuHq7nHloBGUex+Ubw2IG+9OAgEf5e5BfZCPXz5JNlB5i/8yQAfeOCefWq3nh7uHFRj5iz+EWIiIiIiIjIuU6BL5GzsfoDc9nlEh7+n1mE/dsNRx2HNx1JZ9Cz8/nTuE7cO+q0IX5BLeuuX96BkF68bhjwnwvN9Vt+hcOrzPVOE83srsr0mApbZpnric4i8+SkwicXw8ltENEZknaa+xc9D+GdzKGYnSeCh4+5P8Os1XXYsx2zNiYza2NyhS/5zGU9lOElIiIiIiIitULTo4mcqaPr4cASsLqT1+c2l0NRgV4u2y/9uotDKTn117f8DOd6yZBHgP+Mg/TDYHGDIfeUf2508RDKVoPh8g/gxp/M7Z0/wYdj4cvr4d99zKAXOINeJZJ3wde3wr/7mrNHAmQeNw9ZnEMy+8WH0C8+xOXUy/q0pEtMYI3eqoiIiIiIiEhFlPElDcMwYP7T5qyDE1+p/eF+9eHgMnPZYRz7C50BnKv6t+LxiV34dWsij37tzJKatfYwj4zrVD99y0uv/HiL3tBqUKntPuYskP5RcMP3sOpd6DXNPBbd3SxybyuAI2tcr9Pzatg9Gzx8YcCtENgSErfChv9C5jFY/gZMes28NnDCMH9P/5zcnesGxwOw/tApvNyttA33x9tDsXgRERERERGpPQp8ScNY/DIsfdVc7zYZ2o40h89t+R/0uMK1WHtjVTIzYlRXEpKzAegTF8wLV5gZU1f2jyUy0ItDqTn8/fttLNmTVK3A18mMPOwGRAZ4YbVaqmxfri6TYMNnrvs8fM0i+gHRMOhOsw5X54vNTK6xT0NsfzMTzMMbRv7FeZ5PCFzzJax6D3bPce7vfDFMeQ9shWDYwb1UlluHsfDfy2DbtzDhRUfG11FbMADh/p6Opn3jXLO+RERERERERGqLAl9S/3bNhgX/dG5Pv9QMjix5BbJOmEGSsU/W3etv+R+c2AoDbq+4zlZRAXx3N8QNhoG3l98muTjwFdaehOQsANqG+zsOWywWRnaK5ERGHn//fhubj6ZzKruAED9Pl8usPZDKF6sOMbR9OBbgsW+3UFBkx81q4aELOpatDVYFu93AcuE/sUR0MWtrrXzLPHD5h2bdrdImvw1pj5lZXZVpN9r8yUwEq4dZ96vHVPPY6YXsoTjAFmP+t9zxgyPj61BBAABh/l5lzxERERERERGpZQp8Sf0yDJj3lLneapCz0PrsR51t9sytu8DXyR3wzR3mTIebv4L715kZTqfb/CVs/Z/5UzrwlbwXCnMgpqcz4yusA/t2mhlfbSP8ylwqKtCbTlEB7DqRyaLdSUzu4xpse2XublbsT+GbUkXxAWx2g5d+3cWKfSkU2Ox4e7iRmJ5Lp+hA/n11b8cskYZhYLFYSM0u4Pbpa1l38BT+Xu48MfESrh7XCsI7wPFN0P4Cx7UX7jrJQ7M28cqVvRjVuYqgV2kB0eZy8N2Vt7O6Qf9bYMEzZnZfdhIAe/PM+l1hpwX/REREREREROqCCupI/TAMc6jcc63MYuhuXjBtJnS6yBxKV7pp1snyr3FoJfxnAiTtPrM+HFlnZpcZNnM744hZnL48J3eU3bfkX/Bmf3h/JPzvFsgys5hSvFvx6zZzvWdsULmXG9ctCoAfNx1z2W8YBtuOmfW4PN2ttI/0Z2r/WDY9eSHDO4QDsHRvMqsTUlm8O4ndJ7L4cdMxFu5KYu62RHo89SsDnpnH/B0neGjWRtYdPAVAVn4RX68/AhYL9L/ZrLPl7gw23fTxGlKzC3hw1saqfmtnbuAd4BUESTsgx5zF8UC+mfEVHqCMLxEREREREal7yviS+rHjB9esrk7jzTpe02aY20UFPPXdRv6+5UKs2SdhxjRz9sGbfgbv4mDSf8aZy1nXw72rKn89w4D1n4JfhHN4388PmUMpvYPNYu77F5jDLjtcUPb84ppUJX3D3bO4ZpZhBs62fm0e8/Tn0/WnyCmw0TM2iPPah5fbnUt6t+Dfv+9l/s6T3Pv5ev49rQ9uVgsnMvLJyCvCzWph85MX4u3hLPL/76v78N+VB7EAcWG+FBTZeWvBXg6k5HD79LUU2Q2zq8Ctn641u+Nu5YHR7Xl57m6Op+c5ssFKS8lyzvKYmVdU+e/xbPgEw1X/hemXOHYlE4Snm5UAL/3pERERERERkbqnjC+pHwmLneuh7WDI/a7H3T35ZG0SB41Ic3vXL5C4BXb8VPZaSTsrf61v7oSng+HHP8CsG2DfAnhvBBzfaB6/c7FzqN7uX80gWQnDMINa275x7svPAFsRpB0s+1oDbmVVQioA1w2KLxNkKtE+MoCBrc2C/T9vOc6KfSkA7EzMAKBNuJ9L0AsgxM+TB8Z04P4xHbi0d0uu7N+KWXcNoWWwjyPoBdA5OsCxftt5bbisbywAR07l0vOpuSzbm+xy3fk7nRl1NrtBem5huX2uFW1HwB0LwTuY7Kj+FOFOmL9nhb8nERERERERkdqkwJfUnswT8P29cHR92WPHNprLyz+CB9ZDqwE8+f1Wbvt0DXmFNvYlmcXhtxltXM87uNxcFuVTLblpsHmmc9teBP+d7Ax6tR4OIfHQ5nxw9zGHO57Y6mz/80PmMMbS8tIh/ZB5LQD/KDNr7JG92Mc8zbZjZvCqRwXDHEt8dtsghrQNA+D+Ges5nJrDT5vNzLLSwavKRAZ4M//hEYzubAYIx3WL4vv7hnH94HjGdI7k7pHtiAzwoiSulJlfxMOzNrlcY8OhUy7b24v7fyYy8wo5lJJDQZGdxPQ8HvxyIy/M2UlWfqlMshZ94MFtrB4xHYAwf9X3EhERERERkfqh8UZSexY8Yw4H3PAZ/PmAs3aXrdDM3gIzCAIkZebz6Qozg6rz3+Y4LvFu0cVc7LbSec39C8xsq9/+7vpa2cngV86wwoPLnOvdLoNt37oeH3SXufTwgbYjYfds2DUHwjvCoRWwfnrZa+alQU5xsCiiC9z4oznc0T+Cg8nZZOUX4eVupUOkf9lzS/F0t/LIuI5c/s4KTuUUMvzFBY5jQ9qFVXpuad4ebrx9bV9+2HiMUZ0j8XJ34/8muxaoj/D34mSmGSxMyy1wObbpcLrL9rZj6ZW+fkGR3dH/09326VpHxltpiel5vHpVb8d2kbsv7ywx74EWQT6VvDsRERERERGR2qOMLzl7Oanw8USzplaJ13rCxxeZx5J2gi3fLHQe2haANQfKBkvC/b3YarTlL4W3sdZSHMjJOArf3gGr3nVt/FI7+OkhWPKK6/79i8xl/1vhio/hkjdh7NPw0E74+ynocrGzbafx5nLzTPjlT2bhe3uR2ccL/s/ZLi8dUveZ62HtwD/CMbvhlqNmEKlzTCDublX/79Q3LoQHxnRw2TdtYBxXD4ir8tzSvD3cmDqgFREVFIn393bGtD2sVnYmZrBiXwq5BTZ2ncgE4NpB5ms++8sOBjwzj4vfWOIIcpUwDINrP1zJ0OfnlxkSmZyVX27QC2D21uNkl8r6Wp2QyuqEVPw83cq8fxEREREREZG6osCXnL3V78PBpa778jPM7Kv10+HwanNfi96UjMFbXSpg0jrMl9ev7s28h85nYOtQZtpGc0Xu43xrG2Y2KCkkf7q1H8H8f0BmonPf4eKi922Gm6/V93o4748QGAPW0273rpeCbzik7HUN2rUdCcMegPji189Lh5TiwFdx4K7Eol1JAPSuYphjCYvFwkMXdGRizxjHvscv6oybtXZrXmWVKlqfmV/ElLeXM+2DlVz07yXY7AYRAV6M7WLONGk3zAy8rUcz2H48gyKbM/i15sAp1hw4RXJWAZsOp7m8xsr9Zp2y6EBvFjwyki9uH8Syv4ymdZgveYV2fig1g+Xx9DwA+sSF0L1l9X5XIiIiIiIiImdLgS+pme3fw5fXw+E15nZhnhn4KnH+o67tU/c5g1FxgwE4nJrD7K1mbat/T+vD7w+P5NLeLQn29aR3XLDj1K9sIxzrhk8o9xfcx4C8t1hj7+j6GiU1xWxFzsL30T2rfi8+IXDxv1z3Wd2h7w0UFNnZnFwcAMpLh9T95npYO0fT7Pwix/u4pHeLql+vlD+P60ynqAD+fnFXArw9anRudWTkuWZn5RTYAEhIzgbgyn6x5QagJr+1jFs+XUtCcjY3f7yaqe+tcBzbX1yHrcTy4gL9F/WIoU24H0PbhdMy2Icr+pnF9Z/8YRtbjpgZccnFM0mGq76XiIiIiIiI1CMFvqT6dv5szpK44wf4bAok7YKdP0FOCgTGwt9SYPRfXc9ZPx02f2mutxoEwOPfbuFERj7xYb6M7hyJtVS20wVdoxzry+3deNd6FcaA2/mh/6f8aB9KEiH8t+hC19c4Vhz4St0PRXkUufnw10VZHEvLdS2yXp6ul8Klb0NwHEz9L/zlELTow3cbj7Ino3iWxdJDHUtlfC3YdZKcAhttwv3oGxdSvd9hsbgwX3598HxuOa9N1Y3PwHNTepS7f0rflrxyZS/+NK5ThcMkF+9OYtTLC1lQnM1WYm+pwFdeoY05W81Mu+EdXGut3TmiHaM7R1JQZOeV33YBzsBXRa8pIiIiIiIiUhdU3F6qb+MXzvX8DPj5YbPIPECfa8Gt+Ha69mtY8E84tsHl9I8PhfP6F3NJyzGzkT66cQD+Xq63oGsAycLzOZeyLDGcJXuSHXs3Ga7DDVn8EvSYCie3AbC1sAWfrz7C56uPEO7vyYtX9CQzr4iRHSMJ8i0nu6rPteZPKYdScggz/MyNnBQ4ZRbiJ9SZ8bUr0ayVNbhtKBZL7Q5VPFuX9YllQOtQFu5K4onvzFkrn72sB9cMcq0ldvfIdsxYfYgJ3aOZsfpwmeu8e10/diZm8Nq8Pfy46Tj3jepAVn4haw+cIjW7gBZB3mUCXx5uVp6c1JWFu06ycFcS249lkJxlFtgP91fgS0REREREROqPAl9SPYW5sO93c33yu/DdXXBgiblt9YDepQJHHcaaP++cBye2gIcvCW2v4em5RxxNwvw8aV/OLIhuVgv/mtqLOVsT8XS38tPm4y5BL4CDRlSZ83hrgGN1p72VYz05q4BbPlnreM2uLQLJKbDh6+nGu9f1w8+r/P8FUnMK8MAXAOP4FiyGDdx9IMBZm2t/kjlssG145bM5NpTYEF+uHRTHrsRMViekMr57dJk2fx7fmT+P78zvO084Al/xYb4cTMnhvlHtGd89mhbB3rw2bw/puYUMfm6+y/nXDo4vt6h/fJgf47pFM3trIj9sOkZSZslQRwW+REREREREpP4o8CXVc2ApFOaYQxp7XW0GwbbMgpjeMPYpCIlnf1IWf/12K9cPieeiHjFw009QkAVBsXzy/VbgoONy0wZWPIvhlL6xTOkby8bDafy02ayh9fhFnQn392Jw2zCufn8lI0+9wmOjWjIu6DDM/pPL+esMswZY95aB5Bfa2XPSHKKXkl3gEkSbvuIgd49sR3lOZRfgY5iBL0fmWmhblwL5+4vrZbWN8Kvy19dQLBYL/ze5e5XtOkYFONbnPng+GblFjnpc7SP98fawkldoL3PeVQNaldlXYmLPGGZvTWTO1uN4e5jDRsM11FFERERERETqkQJfUj0HimdtbDfKnC1x8jsw/jnwcw5z+2DJflbsT2HF/hQ+v20Qw9qHg08wABuLi5w/flFnCm0GNw5tXeVL9m4VzItX9CTYx4MLuzmzlcZ3j+b9xTnc+budiT3782bva7AUD8Nc0O0Zvl4Xz4Tu0bxzXT8A7HaDto//4ji/XYQf+5KyeX/xPm45rzVe7m4ur5uWU8DOxEz8MQNalrxTACR5tuSxT9cSF+rL4xd1JiHZDKi1jWicGV81ERviy6e3DCTA2x0vdzciApy/E19Pd2bcPph1B0/x0q+7yC8yA2BT+rSsNINrVKdIvNytHEjJceyLUMaXiIiIiIiI1CMFvqR6Di43l/HDzKWbu0vQa+vRdJcaUdd+uIqr+rfi6Uu7YbHAjmMZAEzoHkOrUN9qv+zU/mUzijpHO7OTft58nPtvfYhORQVY+t/M7LUB2DniksFktVq4ZVgb/rMsgTvOb8uj4zpx3gsLSMzIY8nuZMaWKqj/+aqDPP3DdgpsdjpaXTO5FiYFMC/9BABFdjt5hXY83Cy0CvGp9vtpzEZ0jKjwWJ+4EPrEhXDVgFYYwI+bjnFxz8pnsvTzcmdy75Z8udZ5X4QHaFZHERERERERqT+a1VGqVpDtnDkxfmiZw6sTUrn4jaVl9n+59jA/bDzG1qPpFNjshPp5ElsLQaJOpQJfAOM/2s2feQBan8fO4oLzpQNfAH8a14n3ru/Hn8Z1wt3NyoQeZgbZT5uPOdrY7QYvzN5Jgc3MaDpsuAaCNuWGOdanrzCHbbaL8C+3xlVzFeDtQaC3B9cOiifIp5yJAk5z76j2Ltuhvgp8iYiIiIiISP2p8Sf2xYsXM2nSJFq0aIHFYuG7776r8pyFCxfSt29fvLy8aN++PZ988skZdFUazIbPwV5EYWAckz8/zB3T1zJn63EMw8AwDP712y5H05uGtiYq0DmcbWVCCt9uOArAsPbhtTL7YXlF8WetPUKhze4IfHVvGehy3MfTjXHdovEoDlJd3NMsUv/dxmN8vCwBgISUbDLyigBoEeTNAcO1GPyeQtei+l1iAnnpil5n/X6as7gwX96Y1gdvDyu9WgWfU0FCERERERERaXg1HuqYnZ1Nr169uOWWW5gyZUqV7RMSEpg4cSJ33XUXn3/+OfPnz+e2224jJiaGcePGnVGnpZ4UFcDWr2H+0wB863M5Gw+mA+nM3X6CKX1bEhHgxcr9qXi4WZj74AjiQ32Z0D2aP365kePpeczbfgKb3QDgqnKGLZ4JL3c3npjYhbcX7iM1u8Cxf9X+VAqK7AR4uxNXxXDKvnEh3HZeGz5cmsBzs3eSnV/Ey3N3A9A/PoQZdwzmineWk5IUQJjFDKYlGNHEhvjg6WYlt9DGf28dqFkKq2FSrxaM6BSBl7uCXiIiIiIiIlK/ahz4mjBhAhMmTKh2+3fffZc2bdrwyiuvANClSxeWLl3Kq6++qsBXY/f1LbDjRwAKw7vy5OG+AAxpG8bKhBS+WX/U0fTP4zvTJtysiTWobRi/PzySXk/PdWRQ9WgZxNB2YdSW24a35cr+rbjkzaUcLC6e/vX6IwB0axFYZWaZxWLhrxO7sPloOqsTUh1BL4DuLYPwcLMS4O1BEc4i7ycJZlSkP+9e3w+73cwik+oJ9K56WKSIiIiIiIhIbavzFIwVK1YwduxYl33jxo1jxYoVFZ6Tn59PRkaGy09zsnP1r6z611QOvTCY3St+aujulM8wYN9Cc73/rbzT/j1y7W6ObKjXr+5D23A/ogO9+etFXbj1vDYup/t4uvF/k7txWZ+WvHJlL2bcMRir9eyHOZYW5OPBoj+NYlw3cwhiyZDK7i2CqnW+xWLhsQmdy+wvKfLu53V6YMtC63A/vNzdFPQSERERERERaQLqfFbHxMREoqJcayNFRUWRkZFBbm4uPj5li50/99xzPP3003XdtQaTdXwvgzJ+BWD2L6+x0b0XUwe0wm43KLTb8XJvBEGV9MNQkEkR7vxfwXXMWGEGlW4eZga4LunVgkt6VT6r31UD4rhqQFydd7VjVAC/bjNnW/T2sDKue3QVZzj1iQvhqUldefqn7Tx8QUf6xoUwpDgzzc/LnaX27lzutpRsq1lXrHWYX2WXExEREREREZFGpM4DX2fiscce46GHHnJsZ2Rk0KpV7dSHagzCel5I8t7phGfupLUlkYu/3cKK/Sks3HWSYF9PLuwWxYiOEQxtF17u+YZhsP14BsG+nrQMPvtZEh1S9sF3d0PfG7H7hGEF9tpj+HT1cQDiw3y5sFtU5ddoAOO7R/PV2iNM7BnDwxd2xNezZrf1TcPacPXAOLw9XAOO/l7u/F/h9cS3iuejrCGQQ63MSikiIiIiIiIi9aPOA1/R0dGcOHHCmVGhXQAAIwZJREFUZd+JEycIDAwsN9sLwMvLCy+v5ls0vE2bDnDzTPh3b9q7ncBeYHMM0zuVU8h7i/bz3qL97H/2onKHB36x+hB//XYrAC9e0ZPRnSNJzy2kXUTZ2Q6rw2Y3+G1bIuHf3Up/2wZyTuwnu/3FRAC7jVgu7d2CYB8P7hzRzjErYmPSrUUQKx8fc1bXOD3oBWbGVxoB/BxzL8vXHwUKiQ2pvGi+iIiIiIiIiDQedR74GjJkCL/88ovLvt9++40hQ4bU9Us3bsFxYPXAw17A2xdHsSDRi1lrj7g0+fPXm/nbpK7k5NvYkZhBRm4hRTaDF+fscrR5fd4e/vnTdnILbcx9cISjwHx1/XHmBr7beIyx1nV86LkBAN+CJHy3f2w2iOzC61f3Obv32kT5e5n/e5zMyCc9txCAlsr4EhEREREREWkyahz4ysrKYu/evY7thIQENm7cSGhoKHFxcTz22GMcPXqU6dOnA3DXXXfx5ptv8uijj3LLLbfw+++/M2vWLH7++efaexdNkdUNQttC8i4mxGQx4byBXD+4NZPeXOpo8tW6I/y24wQ2m0FmfpHL6d4eVvIK7RxNy3Xsm7nmEI9N6FLtLqRmF/D9pmP4kcvfPD4DIMfig69hXjPL8Ma3x6SzeZdNml9xAftdJzIBs5h+STBMRERERERERBq/Gn+KX7t2LaNGjXJsl9TiuvHGG/nkk084fvw4hw4dchxv06YNP//8Mw8++CCvv/46sbGxfPjhh4wbN64Wut/EhXeA5F2QvBfajaZHbBCf3DyAtJxCnvllB0mZ+aTlFDqad4zyJyuviFB/T/42sStfrz/CrLVH6NUqmE2H03hv0X6+XneU6CAvbhnWhsFtw/hyzWEOp+YQE+zNzuOZ9GsdQu/YYF78dRebjqThaRTwgc9bxBsnICAG25TP2fn9U8zznUhk7wlc3r/ui9M3Vn7FQa69J7MAareemoiIiIiIiIjUOYthGEZDd6IqGRkZBAUFkZ6eTmBgYEN3p/bMeRxWvgVD74cL/1nm8Naj6fxnaQIhfp7cP7o9wb6eLsfzi2wcTMmhTbgfE/+9hN0nsmrchdc93uRSt+Xg7g03/Qyx/c/47TQ3c7Ymctdn6xzbF3SN4oMb9PsRERERERERaUg1iRNp3FZDCiieITHrZLmHu7cM4l9X9a7wdC93NzpGBQDwywPDOZiaQ16hjR83HeejpfsptBkMahNK77hgcvJtzN6aSHJWPgARAV74uFsZm1Mc2LnyUwW9TtMi2NtlWxlfIiIiIiIiIk2LAl8NyT/aXGYmnvWl3N2sjlkdu7UI4g9jOlBQZCfI18PR5ulLuvHzluO4Wy2M7hIJeRl4vWwGwmhz/ln3obk5PdBV04kDRERERERERKRhKfDVkPwjzWXWiVq/tI+nGz7FxdlLWK0WJvVqYW7YbZBTHHDzDgZP31rvQ1MX6ueJj4cbuYU2QIEvERERERERkabG2tAdOKcFFGd81UHgq1LbvoVnYmDhc+Z2YMv6ff0mwmKxEFNquKMCXyIiIiIiIiJNiwJfDcm/uMZX7ikoyq/710s7BDmpsOJtsOXD9u/N/YEt6v61myhLqfUWqvElIiIiIiIi0qRoqGND8gkBN0+wFZhZX8FxdfdaaYfgtR4Q0RkMu+sxBb4qVGhzTnrqZrVU0lJEREREREREGhtlfDUki8WZ9ZVZx8Md984zl0k7IXm36zEFvirUNy4YAHcFvURERERERESaHGV8NTT/SEg/DFmJMPsv4O4JF/yj9l8n66TrtsUNDLNoe5kMMHF44uKuBHh7cPXAVg3dFRERERERERGpIWV8NbSg4oDK5i9h1Tuw7HWzDldlMhPhxz/CpplgryJolX4EDiyDkztc98cNgU4TwWKFrpPPtPfNXri/F/83uTvdWgQ1dFdEREREREREpIaU8dXQYvvD9u9gx4/OfZmJ4Bta8Tmbv4R1H5s/uWnQagBkHIMuk8q2nXUjHF1bdn+n8TDgdrOwfmDM2b4LEREREREREZFGRxlfDa3VoLL7frjPzNKqSMYx53rCYvhgNHx5HSSdVrvLbis/6NV6OAy6Gzy8FfQSERERERERkWZLga+GFtOr7L6j6+CTiyo+J6tUIfxdPzvXj21wbZd+2Lnu7gPhHeHB7XD9t+CmZD8RERERERERad4U/Who7l5mra09c8EvAjKPVX3O6YXqS5zc5rqdss9cRnSG2xeYs0h6+Jxdf0VEREREREREmghlfDUGV34MD26DPte67rcVld8+M7H8/ScqCHyFtgNPXwW9REREREREROScosBXY+DuBQFREBDtuj87qfz2FWV8nR74Si0OfIW1O7v+iYiIiIiIiIg0QRrq2Jj4R7luZ51wLT6/5F/g4QsFma7trB5gL4TM45CVBP4R5v7kPeZSgS8REREREREROQcp46sx8Qp03S5dxD5lH8x/Gub82dz28HUe63qJWbge4Nh65/6kneYyonPt91VEREREREREpJFT4KsxaT0c+t7g3C6p5fX7P+GNvq5t/SPh5jnQaxpMeBFa9jP3H11nLvPSIeOoua7Al4iIiIiIiIicgxT4akysVrjkDWfwK2UP2O2w+KWybf2jIX4IXPYu+IU7A1/bvwe7DU4WZ3sFtACf4HrpvoiIiIiIiIhIY6IaX41RSa2v5W8AlvLbtBrouh3b31wm7YTv74O4QeZ2pLK9REREREREROTcpIyvxiiolXN9+b/Lb9Npgut2TG8YcJu5vmkG7PnNXI/sWuvdExERERERERFpChT4aoy6T4GW/StvE3taxpfFAhNfMeuEYcDOn8z9oW3rpIsiIiIiIiIiIo2dAl+NkVcAXP5B+cf6XAc3/gRuFYxS7XGl63ZwXO32TURERERERESkiVCNr8YqON512y/CHAJ58Wvg5lHxeVHdXbdLD5sUERERERERETmHKPDVWFndXLcf3m3O+liVsNOGNgbF1l6fRERERERERESaEA11bMxKZneM6V29oBeAT4jrtpd/rXZJRERERERERKSpUOCrMbt6BnS/HKbNaOieiIiIiIiIiIg0ORrq2JjF9oMr/tPQvRARERERERERaZKU8dUcjX/eXA5/uGH7ISIiIiIiIiLSgJTx1RwNvBPajICITg3dExERERERERGRBqPAV3NktUJU14buhYiIiIiIiIhIg9JQRxERERERERERaZYU+BIRERERERERkWZJgS8REREREREREWmWFPgSEREREREREZFmSYEvERERERERERFplhT4EhERERERERGRZkmBLxERERERERERaZYU+BIRERERERERkWZJgS8REREREREREWmWFPgSEREREREREZFmSYEvERERERERERFplhT4EhERERERERGRZkmBLxERERERERERaZYU+BIRERERERERkWbJvaE7UB2GYQCQkZHRwD0REREREREREZGGVBIfKokXVaZJBL4yMzMBaNWqVQP3REREREREREREGoPMzEyCgoIqbWMxqhMea2B2u51jx44REBCAxWJp6O7UioyMDFq1asXhw4cJDAxs6O6I1IjuX2nqdA9LU6d7WJo63cPSlOn+laauOdzDhmGQmZlJixYtsForr+LVJDK+rFYrsbGxDd2NOhEYGNhkbzQR3b/S1OkelqZO97A0dbqHpSnT/StNXVO/h6vK9Cqh4vYiIiIiIiIiItIsKfAlIiIiIiIiIiLNkgJfDcTLy4snn3wSLy+vhu6KSI3p/pWmTvewNHW6h6Wp0z0sTZnuX2nqzrV7uEkUtxcREREREREREakpZXyJiIiIiIiIiEizpMCXiIiIiIiIiIg0Swp8iYiIiIiIiIhIs6TAl4iIiIiIiIiINEvNPvD13HPPMWDAAAICAoiMjGTy5Mns2rXLpU1eXh733nsvYWFh+Pv7c/nll3PixAmXNg888AD9+vXDy8uL3r17l/tahmHw8ssv07FjR7y8vGjZsiXPPPNMlX386quv6Ny5M97e3vTo0YNffvnF5fg333zDhRdeSFhYGBaLhY0bN1brvaempnLttdcSGBhIcHAwt956K1lZWeW23bt3LwEBAQQHB1fr2lI/Gvv9u23bNi6//HJat26NxWLhtddeK7fdW2+9RevWrfH29mbQoEGsXr26yvf+zDPPMHToUHx9fSu8L9esWcOYMWMIDg4mJCSEcePGsWnTpiqvLfWnvu7hp556CovFUubHz8+vyj5WdX8mJiZy/fXXEx0djZ+fH3379uXrr7+u8rqHDh1i4sSJ+Pr6EhkZyZ/+9CeKiorKbbts2TLc3d0r/P9TGk59/h3+9ddfGTx4MAEBAURERHD55Zdz4MCBKvtY1XPETTfdVOb/jfHjx1d6zU2bNjFt2jRatWqFj48PXbp04fXXX3dp880333DBBRcQERFBYGAgQ4YM4ddff62yv1J/6vP+nTVrFr1798bX15f4+HheeumlavWxqvv3qaeeonPnzvj5+RESEsLYsWNZtWpVldetqs95eXncdNNN9OjRA3d3dyZPnlyt/kr9auz3cHWehavzHk534MABbr31Vtq0aYOPjw/t2rXjySefpKCgwNFm165djBo1iqioKLy9vWnbti1PPPEEhYWFVfZb5FzT7ANfixYt4t5772XlypX89ttvFBYWcuGFF5Kdne1o8+CDD/Ljjz/y1VdfsWjRIo4dO8aUKVPKXOuWW27hqquuqvC1/vCHP/Dhhx/y8ssvs3PnTn744QcGDhxYaf+WL1/OtGnTuPXWW9mwYQOTJ09m8uTJbN261dEmOzub8847jxdeeKFG7/3aa69l27Zt/Pbbb/z0008sXryYO+64o0y7wsJCpk2bxvDhw2t0fal7jf3+zcnJoW3btjz//PNER0eX2+bLL7/koYce4sknn2T9+vX06tWLcePGcfLkyUqvXVBQwJVXXsndd99d7vGsrCzGjx9PXFwcq1atYunSpQQEBDBu3Dj9g9+I1Nc9/Mgjj3D8+HGXn65du3LllVdW2r/q3J833HADu3bt4ocffmDLli1MmTKFqVOnsmHDhgqva7PZmDhxIgUFBSxfvpxPP/2UTz75hL///e9l2qalpXHDDTcwZsyYSvsqDaO+7uGEhAQuvfRSRo8ezcaNG/n1119JTk4u9zqlVec5AmD8+PEu/3/MmDGj0uuuW7eOyMhIPvvsM7Zt28Zf//pXHnvsMd58801Hm8WLF3PBBRfwyy+/sG7dOkaNGsWkSZMq/X9D6ld93b+zZ8/m2muv5a677mLr1q28/fbbvPrqqy73S3mqc/927NiRN998ky1btrB06VJat27NhRdeSFJSUpXvv7I+22w2fHx8eOCBBxg7dmyV15KG0djv4eo8C1fnPZxu586d2O123nvvPbZt28arr77Ku+++y+OPP+5o4+HhwQ033MDcuXPZtWsXr732Gh988AFPPvlkpX0WOScZ55iTJ08agLFo0SLDMAwjLS3N8PDwML766itHmx07dhiAsWLFijLnP/nkk0avXr3K7N++fbvh7u5u7Ny5s0b9mTp1qjFx4kSXfYMGDTLuvPPOMm0TEhIMwNiwYUOV192+fbsBGGvWrHHsmz17tmGxWIyjR4+6tH300UeN6667zvj444+NoKCgGvVf6ldju39Li4+PN1599dUy+wcOHGjce++9jm2bzWa0aNHCeO6556p13YruyzVr1hiAcejQIce+zZs3G4CxZ8+eGvdf6kdd3cOn27hxowEYixcvrrRdde5PPz8/Y/r06S7nhYaGGh988EGF1/3ll18Mq9VqJCYmOva98847RmBgoJGfn+/S9qqrrjKeeOKJar83aVh1dQ9/9dVXhru7u2Gz2Rz7fvjhB8NisRgFBQUV9qc6zxE33nijcemll1b3LVbonnvuMUaNGlVpm65duxpPP/30Wb+W1I26un+nTZtmXHHFFS77/v3vfxuxsbGG3W6vsD81eQ4ukZ6ebgDGvHnzKmxTnT6XVlv/j0jda2z3cGkVPQtX9R6q68UXXzTatGlTaZsHH3zQOO+882p0XZFzQbPP+Dpdeno6AKGhoYD5jWZhYaHLNz2dO3cmLi6OFStWVPu6P/74I23btuWnn36iTZs2tG7dmttuu43U1NRKz1uxYkWZb5nGjRtXo9eu6LrBwcH079/fsW/s2LFYrVaX9PDff/+dr776irfeeuusXk/qR2O7f6tSUFDAunXrXPpntVoZO3bsWd/jnTp1IiwsjI8++oiCggJyc3P56KOP6NKlC61btz6ra0vdqat7+HQffvghHTt2rDSTtbr359ChQ/nyyy9JTU3Fbrczc+ZM8vLyGDlyZIXXXrFiBT169CAqKsqxb9y4cWRkZLBt2zbHvo8//pj9+/fr29kmpK7u4X79+mG1Wvn444+x2Wykp6fz3//+l7Fjx+Lh4VHhedV9jli4cCGRkZF06tSJu+++m5SUlGr3rUR6errjfZfHbreTmZlZaRtpWHV1/+bn5+Pt7e2yz8fHhyNHjnDw4MEKz6vpc3BBQQHvv/8+QUFB9OrVq9r9k+ajsd3DZ+L091CT8yo7Z+/evcyZM4cRI0acVf9EmqNzKvBlt9v54x//yLBhw+jevTtg1m7x9PQsU0MoKiqKxMTEal97//79HDx4kK+++orp06fzySefsG7dOq644opKz0tMTHT5YHQmr13RdSMjI132ubu7Exoa6rh2SkoKN910E5988gmBgYFn9XpS9xrj/VuV5ORkbDZbndzjAQEBLFy4kM8++wwfHx/8/f2ZM2cOs2fPxt3d/ayuLXWjLu/h0vLy8vj888+59dZbK21X3ftz1qxZFBYWEhYWhpeXF3feeSfffvst7du3r/DaFf1tLzkGsGfPHv7yl7/w2Wef6Z5tIuryHm7Tpg1z587l8ccfx8vLi+DgYI4cOcKsWbMqPa86zxHjx49n+vTpzJ8/nxdeeIFFixYxYcIEbDZbtfu3fPlyvvzyy3JLJpR4+eWXycrKYurUqdW+rtSfurx/x40bxzfffMP8+fOx2+3s3r2bV155BYDjx49XeF51n4N/+ukn/P398fb25tVXX+W3334jPDy82v2T5qEx3sO18R6qY+/evbzxxhvceeedZY4NHToUb29vOnTowPDhw/nHP/5Ra/0VaS7OqcDXvffey9atW5k5c2atX9tut5Ofn8/06dMZPnw4I0eO5KOPPmLBggXs2rWLQ4cO4e/v7/h59tlna+2177rrLpdrV9ftt9/ONddcw/nnn19rfZG6o/vXVW5uLrfeeivDhg1j5cqVLFu2jO7duzNx4kRyc3NrrX9Se+ryHi7t22+/JTMzkxtvvNGxb8mSJS732eeff17t6/3tb38jLS2NefPmsXbtWh566CGmTp3Kli1bAJgwYYLjut26davWNW02G9dccw1PP/00HTt2rNkblAZTl/dwYmIit99+OzfeeCNr1qxh0aJFeHp6csUVV2AYxln9Hb766qu55JJL6NGjB5MnT+ann35izZo1LFy4EKj6Ht66dSuXXnopTz75JBdeeGG5r/HFF1/w9NNPM2vWrDJfvEnjUJf37+233859993HxRdfjKenJ4MHD+bqq68GzEzas32OGDVqFBs3bmT58uWMHz+eqVOnOmoxnsnfYGmamvI9XKK891DVs/DRo0cZP348V155JbfffnuZ419++SXr16/niy++4Oeff+bll18+o76JNGfnzFfM9913n6PAe2xsrGN/dHQ0BQUFpKWluXxTcOLEiQoLFJYnJiYGd3d3lw8wXbp0AcyZvUr+wS5RkqYaHR1dZtaRmr72P/7xDx555BGXfdHR0WWKhxcVFZGamuq49u+//84PP/zg+ONoGAZ2ux13d3fef/99brnllmr3QepWY71/qxIeHo6bm1ul93h59291fPHFFxw4cIAVK1ZgtVod+0JCQvj+++8dDyvSONT1PVzahx9+yMUXX+ySRdC/f3+XezgqKgovL68q7899+/bx5ptvsnXrVscHql69erFkyRLeeust3n33XT788ENHsLVkSFp0dHSZ2SFLXic6OprMzEzWrl3Lhg0buO+++wAzAG0YBu7u7sydO5fRo0ef0fuXulHX9/Bbb71FUFAQL774omPfZ599RqtWrVi1alWZe/hsniPatm1LeHg4e/fuZcyYMeXewyW2b9/OmDFjuOOOO3jiiSfKvd7MmTO57bbb+Oqrr1QkvJGq6/vXYrHwwgsv8Oyzz5KYmEhERATz588HzPstJCTkrO5fPz8/2rdvT/v27Rk8eDAdOnTgo48+4rHHHqv0/pXmo7Hew7XxHip7Fj527BijRo1i6NChvP/+++W2adWqFQBdu3bFZrNxxx138PDDD+Pm5lbjPoo0V80+8GUYBvfffz/ffvstCxcupE2bNi7H+/Xrh4eHB/Pnz+fyyy8HcGS4DBkypNqvM2zYMIqKiti3bx/t2rUDYPfu3QDEx8fj7u5e7rCYIUOGMH/+fP74xz869v322281eu3IyMgy364OGTKEtLQ01q1bR79+/QAz0GW32xk0aBBg1lUoPczh+++/54UXXmD58uW0bNmy2q8vdaex379V8fT0pF+/fsyfP98xTbjdbmf+/PmOD/vl3b/VkZOTg9VqxWKxOPaVbNvt9hpfT+pGfd3DJRISEliwYAE//PCDy34fH59y7+Gq7s+cnBwAR3C1hJubm+M+K+/v5ZAhQ3jmmWc4efKk4/7+7bffCAwMpGvXrnh4eDgyxkq8/fbb/P777/zvf/8r83uShlNf93DJ37TSSj60lHwpVVvPEUeOHCElJYWYmBig/HsYYNu2bYwePZobb7yRZ555ptw2M2bM4JZbbmHmzJlMnDix0vco9a++/wa7ubk57qcZM2YwZMgQIiIiAGr1ObgkUx0qvn+leWjs93BtvIeKnoWPHj3KqFGj6NevHx9//HGZfyPKY7fbKSwsxG63K/AlUlpDVdWvL3fffbcRFBRkLFy40Dh+/LjjJycnx9HmrrvuMuLi4ozff//dWLt2rTFkyBBjyJAhLtfZs2ePsWHDBuPOO+80OnbsaGzYsMHYsGGDY3Yum81m9O3b1zj//PON9evXG2vXrjUGDRpkXHDBBZX2b9myZYa7u7vx8ssvGzt27DCefPJJw8PDw9iyZYujTUpKirFhwwbj559/NgBj5syZxoYNG4zjx49Xeu3x48cbffr0MVatWmUsXbrU6NChgzFt2rQK22tWx8ansd+/+fn5jmvFxMQYjzzyiLFhwwaXWRVnzpxpeHl5GZ988omxfft244477jCCg4NdZrsrz8GDB40NGzYYTz/9tOHv7+94nczMTMMwzBl7vLy8jLvvvtvYvn27sXXrVuO6664zgoKCjGPHjtXo9yx1p77u4RJPPPGE0aJFC6OoqKha/avq/iwoKDDat29vDB8+3Fi1apWxd+9e4+WXXzYsFovx888/V3jdoqIio3v37saFF15obNy40ZgzZ44RERFhPPbYYxWeo1kdG6f6uofnz59vWCwW4+mnnzZ2795trFu3zhg3bpwRHx/v8lqnq+o5IjMz03jkkUeMFStWGAkJCca8efOMvn37Gh06dDDy8vIqvO6WLVuMiIgI47rrrnN53ydPnnS0+fzzzw13d3fjrbfecmmTlpZ2Rr9rqX31df8mJSUZ77zzjrFjxw5jw4YNxgMPPGB4e3sbq1atqrR/Vd2/WVlZxmOPPWasWLHCOHDggLF27Vrj5ptvNry8vIytW7dWeu3q/Luxbds2Y8OGDcakSZOMkSNHOtpI49HY7+HqPAtX5z2c7siRI0b79u2NMWPGGEeOHHE5r8Rnn31mfPnll8b27duNffv2GV9++aXRokUL49prr63R71jkXNDsA19AuT8ff/yxo01ubq5xzz33GCEhIYavr69x2WWXlQkqjRgxotzrJCQkONocPXrUmDJliuHv729ERUUZN910k5GSklJlH2fNmmV07NjR8PT0NLp161bmw9THH39c7ms/+eSTlV43JSXFmDZtmuHv728EBgYaN998syNoUB4Fvhqfxn7/JiQklHvdESNGuLR74403jLi4OMPT09MYOHCgsXLlyirf+4033ljutRcsWOBoM3fuXGPYsGFGUFCQERISYowePbrcqaul4dTnPWyz2YzY2Fjj8ccfr1Efq7o/d+/ebUyZMsWIjIw0fH19jZ49exrTp0+v8roHDhwwJkyYYPj4+Bjh4eHGww8/bBQWFlbYXoGvxqk+7+EZM2YYffr0Mfz8/IyIiAjjkksuMXbs2FFlHyt7jsjJyTEuvPBCIyIiwvDw8DDi4+ON22+/vcovH5588sly+xsfH1/le7rxxhur7LPUj/q6f5OSkozBgwcbfn5+hq+vrzFmzJhq/VtvGJXfv7m5ucZll11mtGjRwvD09DRiYmKMSy65xFi9enWV163O/3Px8fHltpHGo7Hfw9V5Fq7OezhdRZ//St+fM2fONPr27Wv4+/sbfn5+RteuXY1nn33WyM3NrdbvVuRcYjEMw0BERERERERERKSZOadmdRQRERERERERkXOHAl8iIiIiIiIiItIsKfAlIiIiIiIiIiLNkgJfIiIiIiIiIiLSLCnwJSIiIiIiIiIizZICXyIiIiIiIiIi0iwp8CUiIiIiIiIi8v/t3T1oVNsexuF3DteEQCKaED+IiQQLcRoRFREiMaBEBEsbERUUsbAwYEAQQUkxARUUG0vxq1FBwTRiMSksBBUCCioKIY0gaBSTgCOOpxDCDfec8mRy5zxPN3uxNuvf/tjDoi4JXwAAC8T27dtz4sSJWh8DAKBuCF8AAP+HyuVyCoVCvnz5UuujAAAsWMIXAAAAAHVJ+AIAqIHp6ekcOHAgzc3NWblyZS5evDhn/caNG9m0aVNaWlqyYsWK7Nu3Lx8/fkySjI+Pp6+vL0mydOnSFAqFHDp0KElSrVZTKpXS3d2dpqamrF+/Pnfv3p3X2QAAFgrhCwCgBgYHBzM6OpoHDx7k0aNHKZfLefHixez6jx8/MjQ0lLGxsdy/fz/j4+OzcauzszP37t1Lkrx58yYfPnzI5cuXkySlUinXr1/P1atX8+rVqwwMDGT//v0ZHR2d9xkBAGqt8OvXr1+1PgQAwL/J1NRU2tracvPmzezduzdJ8vnz56xatSpHjx7NpUuX/mfPs2fPsnnz5nz79i3Nzc0pl8vp6+vL5ORklixZkiT5/v17Wltb8/jx42zdunV275EjRzIzM5Pbt2/Px3gAAAvGf2p9AACAf5v379+nUqlky5Yts89aW1uzdu3a2d/Pnz/P2bNnMzY2lsnJyVSr1STJxMREisXiX7733bt3mZmZyc6dO+c8r1Qq2bBhwz8wCQDAwiZ8AQAsMNPT0+nv709/f39u3bqV9vb2TExMpL+/P5VK5W/3TU1NJUlGRkbS0dExZ62xsfEfPTMAwEIkfAEAzLM1a9Zk0aJFefr0abq6upIkk5OTefv2bXp7e/P69et8+vQpw8PD6ezsTPL7r47/raGhIUny8+fP2WfFYjGNjY2ZmJhIb2/vPE0DALBwCV8AAPOsubk5hw8fzuDgYNra2rJs2bKcPn06f/zx+96hrq6uNDQ05MqVKzl27FhevnyZoaGhOe9YvXp1CoVCHj58mN27d6epqSktLS05efJkBgYGUq1W09PTk69fv+bJkydZvHhxDh48WItxAQBqxq2OAAA1cP78+Wzbti179uzJjh070tPTk40bNyZJ2tvbc+3atdy5cyfFYjHDw8O5cOHCnP0dHR05d+5cTp06leXLl+f48eNJkqGhoZw5cyalUinr1q3Lrl27MjIyku7u7nmfEQCg1tzqCAAAAEBd8sUXAAAAAHVJ+AIAAACgLglfAAAAANQl4QsAAACAuiR8AQAAAFCXhC8AAAAA6pLwBQAAAEBdEr4AAAAAqEvCFwAAAAB1SfgCAAAAoC4JXwAAAADUJeELAAAAgLr0JxBX2GwDrTChAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "\n",
        "\n",
        "# print(\"==============Compare to DJIA===========\")\n",
        "# %matplotlib inline\n",
        "# # S&P 500: ^GSPC\n",
        "# # Dow Jones Index: ^DJI\n",
        "# # NASDAQ 100: ^NDX\n",
        "# backtest_plot(df_account_value,\n",
        "#               baseline_ticker = '^DJI',\n",
        "#               baseline_start = df_account_value.loc[0,'date'],\n",
        "#               baseline_end = df_account_value.loc[len(df_account_value)-1,'date'])\n",
        "df.to_csv(\"df.csv\")\n",
        "df_result_ensemble = pd.DataFrame({'date': df_account_value['date'], 'ensemble': df_account_value['account_value']})\n",
        "df_result_ensemble = df_result_ensemble.set_index('date')\n",
        "\n",
        "print(\"df_result_ensemble.columns: \", df_result_ensemble.columns)\n",
        "\n",
        "# df_result_ensemble.drop(df_result_ensemble.columns[0], axis = 1)\n",
        "print(\"df_trade_date: \", df_trade_date)\n",
        "# df_result_ensemble['date'] = df_trade_date['datadate']\n",
        "# df_result_ensemble['account_value'] = df_account_value['account_value']\n",
        "df_result_ensemble.to_csv(\"df_result_ensemble.csv\")\n",
        "print(\"df_result_ensemble: \", df_result_ensemble)\n",
        "print(\"==============Compare to DJIA===========\")\n",
        "result = pd.DataFrame()\n",
        "# result = pd.merge(result, df_result_ensemble, left_index=True, right_index=True)\n",
        "# result = pd.merge(result, df_dji, left_index=True, right_index=True)\n",
        "result = pd.merge(df_result_ensemble, df_dji, left_index=True, right_index=True)\n",
        "print(\"result: \", result)\n",
        "result.columns = ['ensemble', 'dji']\n",
        "\n",
        "%matplotlib inline\n",
        "plt.rcParams[\"figure.figsize\"] = (15,5)\n",
        "plt.figure();\n",
        "result.plot();"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "result.to_csv('result.csv')\n",
        "files.download('result.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "me-Y1t5RZPOy",
        "outputId": "7dc1cf21-09d0-448b-ddd1-8636ccd44c75"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_62f6e10b-28b0-45ae-a75b-dab10b97b09f\", \"result.csv\", 57828)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oBQx4bVQFi-a"
      },
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    },
    "pycharm": {
      "stem_cell": {
        "cell_type": "raw",
        "metadata": {
          "collapsed": false
        },
        "source": []
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}